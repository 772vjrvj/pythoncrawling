import json
import random
import re
import threading
import time
from urllib.parse import urlparse, unquote

import pandas as pd
import pyautogui  # í˜„ì¬ ëª¨ë‹ˆí„° í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì‚¬ìš©
import requests
from bs4 import BeautifulSoup

from src.workers.api_base_worker import BaseApiWorker


class ApiNaverPlaceSetLoadWorker(BaseApiWorker):

    # ì´ˆê¸°í™”
    def __init__(self):
        super().__init__()
        self.cookies = None
        self.keyword = None
        self.base_login_url = "https://nid.naver.com/nidlogin.login"
        self.base_main_url   = "https://map.naver.com"

        self.running = True  # ì‹¤í–‰ ìƒíƒœ í”Œë˜ê·¸ ì¶”ê°€
        self.driver = None

        self.total_cnt = 0
        self.total_pages = 0
        self.current_page = 0
        self.current_cnt = 0
        self.before_pro_value = 0

    # ì´ˆê¸°í™”
    def init(self):
        # í˜„ì¬ ëª¨ë‹ˆí„° í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
        screen_width, screen_height = pyautogui.size()

        # ì°½ í¬ê¸°ë¥¼ ë„ˆë¹„ ì ˆë°˜, ë†’ì´ ì „ì²´ë¡œ ì„¤ì •
        self.driver.set_window_size(screen_width // 2, screen_height)

        # ì°½ ìœ„ì¹˜ë¥¼ ì™¼ìª½ ìƒë‹¨ì— ë°°ì¹˜
        self.driver.set_window_position(0, 0)

        # ë¡œê·¸ì¸ ì—´ê¸°
        self.driver.get(self.base_login_url)

    # í”„ë¡œê·¸ë¨ ì‹¤í–‰
    def main(self):
        result_list = []
        self.wait_for_user_confirmation()
        self.wait_for_select_confirmation()

        self.log_func("í¬ë¡¤ë§ ì‚¬ì´íŠ¸ ì¸ì¦ì— ì„±ê³µí•˜ì˜€ìŠµë‹ˆë‹¤.")
        self.log_func(f"ì „ì²´ íšŒì‚¬ìˆ˜ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
        all_ids_list = self.total_cnt_cal()
        self.log_func(f"ì „ì²´ ì—…ì²´ìˆ˜ {self.total_cnt} ê°œ")
        self.log_func(f"ì „ì²´ í˜ì´ì§€ìˆ˜ {self.total_pages} ê°œ")

        csv_filename = self.file_driver.get_csv_filename("ë„¤ì´ë²„í”Œë ˆì´ìŠ¤")

        columns = ["ì—…ì²´ëª…", "ì£¼ì†Œ(ì§€ë²ˆ)", "ì£¼ì†Œ(ë„ë¡œëª…)", "ì „í™”ë²ˆí˜¸", "ê°€ìƒì „í™”ë²ˆí˜¸", "ê²€ìƒ‰ì–´"]

        df = pd.DataFrame(columns=columns)
        df.to_csv(csv_filename, index=False, encoding="utf-8-sig")


        for index, place_id in enumerate(all_ids_list, start=1):
            if not self.running:  # ì‹¤í–‰ ìƒíƒœ í™•ì¸
                self.log_func("í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break

            obj = self.fetch_place_info(place_id)
            result_list.append(obj)
            if index % 5 == 0:
                self.excel_driver.append_to_csv(csv_filename, result_list, columns)

            self.current_cnt = self.current_cnt + 1

            pro_value = (self.current_cnt / self.total_cnt) * 1000000
            self.progress_signal.emit(self.before_pro_value, pro_value)
            self.before_pro_value = pro_value

            self.log_func(f"í˜„ì¬ í˜ì´ì§€ {self.current_cnt}/{self.total_cnt} : {obj}")
            time.sleep(random.uniform(2, 3))


        if result_list:
            self.excel_driver.append_to_csv(csv_filename, result_list, columns)

    # ë¡œê·¸ì¸ í™•ì¸
    def wait_for_user_confirmation(self):
        self.log_func("í¬ë¡¤ë§ ì‚¬ì´íŠ¸ ì¸ì¦ì„ ì‹œë„ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")

        event = threading.Event()  # OK ë²„íŠ¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°í•  ì´ë²¤íŠ¸ ê°ì²´

        # ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ ì°½ ìš”ì²­
        self.msg_signal.emit("ë¡œê·¸ì¸ í›„  í›„ OKë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”", "info", event)

        # ì‚¬ìš©ìê°€ OKë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°
        self.log_func("ğŸ“¢ ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ì¤‘...")
        event.wait()  # ì‚¬ìš©ìê°€ OKë¥¼ ëˆ„ë¥´ë©´ í•´ì œë¨

        cookies = {cookie['name']: cookie['value'] for cookie in self.driver.get_cookies()}

        # ì¿ í‚¤ ì¤‘ NID_AUT ë˜ëŠ” NID_SES ì¿ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸ (ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ìƒì„±ë˜ëŠ” ì¿ í‚¤)
        if 'NID_AUT' in cookies and 'NID_SES' in cookies:
            self.cookies = cookies  # ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ì¿ í‚¤ ì €ì¥

        for name, value in self.cookies.items():
            self.sess.cookies.set(name, value)

        # ì‚¬ìš©ìê°€ OKë¥¼ ëˆŒë €ì„ ê²½ìš° ì‹¤í–‰
        self.log_func("âœ… ì‚¬ìš©ìê°€ í™•ì¸ ë²„íŠ¼ì„ ëˆŒë €ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—… ì§„í–‰ ì¤‘...")

        self.driver.get(self.base_main_url)

        time.sleep(2)  # ì˜ˆì œìš©

        self.log_func("ğŸš€ ì‘ì—… ì™„ë£Œ!")

    # ê²€ìƒ‰ì–´ í™•ì¸
    def wait_for_select_confirmation(self):
        """ì‚¬ìš©ìê°€ í™•ì¸(alert) ì°½ì—ì„œ OKë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°"""
        event = threading.Event()  # OK ë²„íŠ¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°í•  ì´ë²¤íŠ¸ ê°ì²´

        # ì‚¬ìš©ìì—ê²Œ ë©”ì‹œì§€ ì°½ ìš”ì²­
        self.msg_signal.emit("ê²€ìƒ‰ì°½ì— í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í›„ì— OKë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”(ì•„ë˜ ëª©ë¡ì´ ë‚˜ì˜¤ëŠ”ê±¸ í™•ì¸í•˜ì„¸ìš”)", "info", event)

        # ì‚¬ìš©ìê°€ OKë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°
        self.log_func("ğŸ“¢ ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ì¤‘...")
        event.wait()  # ì‚¬ìš©ìê°€ OKë¥¼ ëˆ„ë¥´ë©´ í•´ì œë¨

        # ì‚¬ìš©ìê°€ OKë¥¼ ëˆŒë €ì„ ê²½ìš° ì‹¤í–‰
        self.log_func("âœ… í™•ì¸ ë²„íŠ¼ì„ ëˆŒë €ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—… ì§„í–‰ ì¤‘...")

        current_url = self.driver.current_url
        parsed = urlparse(current_url)
        path = parsed.path  # ì˜ˆ: /p/search/%EB%A7%9D%ED%8F%AC%EC%97%AD%20%EA%B0%88%EB%B9%84
        keyword_encoded = path.split("/p/search/")[-1]  # ì¸ì½”ë”©ëœ í‚¤ì›Œë“œ ì¶”ì¶œ
        self.keyword = unquote(keyword_encoded)  # ë””ì½”ë”©

        self.log_func(f"ğŸ” í‚¤ì›Œë“œ: {self.keyword}")

        time.sleep(2)  # ì˜ˆì œìš©

        self.log_func("ğŸš€ ì‘ì—… ì™„ë£Œ!")

    # ì „ì²´ ê°¯ìˆ˜ ì¡°íšŒ
    def total_cnt_cal(self):
        try:
            page = 1
            all_ids = set()

            # í‚¤ì›Œë“œì— ë§¤í•‘ë˜ëŠ” ì•„ì´ë”” ìˆ˜ì§‘
            while True:
                time.sleep(random.uniform(1, 2))

                if not self.running:  # ì‹¤í–‰ ìƒíƒœ í™•ì¸
                    self.log_func("í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break

                result = self.fetch_search_results(page)
                if not result:
                    break

                place_list = result.get("result", {}).get("place", {}).get("list", [])
                ids_this_page = [place.get("id") for place in place_list if place.get("id")]

                self.log_func(f"í˜ì´ì§€: {page}, ëª©ë¡: {ids_this_page}")

                if not ids_this_page:
                    break

                all_ids.update(ids_this_page)
                page += 1

            all_ids_list = list(all_ids)
            self.total_cnt = len(all_ids_list)
            self.total_pages = page
            return all_ids_list

        except Exception as e:
            print(f"Error calculating total count: {e}")
            return None

    # ëª©ë¡ì¡°íšŒ
    def fetch_search_results(self, page):
        try:
            url = f"https://map.naver.com/p/api/search/allSearch?query={self.keyword}&type=all&searchCoord=&boundary=&page={page}"
            headers = {
                'Referer': 'https://map.naver.com/',  # âœ… ë°˜ë“œì‹œ í•„ìš”
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'
            }
            response = self.sess.get(url, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

    # ìƒì„¸ì¡°íšŒ
    def fetch_place_info(self, place_id):
        result = {
            "ì—…ì²´ëª…": "",
            "ì£¼ì†Œ(ì§€ë²ˆ)": "",
            "ì£¼ì†Œ(ë„ë¡œëª…)": "",
            "ì „í™”ë²ˆí˜¸": "",
            "ê°€ìƒì „í™”ë²ˆí˜¸": "",
            "ê²€ìƒ‰ì–´": "",
        }

        try:
            url = f"https://m.place.naver.com/place/{place_id}"
            headers = {
                'authority': 'm.place.naver.com',
                'method': 'GET',
                'scheme': 'https',
                'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'accept-encoding': 'gzip, deflate, br, zstd',
                'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                'priority': 'u=0, i',
                'sec-ch-ua': '"Not/A)Brand";v="99", "Google Chrome";v="127", "Chromium";v="127"',
                'cookie': 'NAC=OsXJBQA7C4Wj; NNB=FOXBS434SDKGM; ASID=da9384ec00000191d00facf700000072; NFS=2; NACT=1; nid_inf=391290400; NID_AUT=BKWCh2nwSx87OqhQiU7fA53ABVeIM0NVMvSL50BLM9CsrtH2hS3M5nj4JkmZmLa5; NID_SES=AAABrK7oOJ3oxSpt990kiHxmKrg4harLTIhsTFL4RNy721y0kPWFyndoU2cAObU+KJUscFZV7gaVh8lMUyj/pIpfJPAb2Kt9Acnx2/0GP0qd95hsxnijuZU4yCTu+37rUwjcJoQI217JYznF8kRHVg9+yuCQJ4hDtP3/TSENNHeX4zw9RudCmqQoLp9HEUZjzmzRNII8lXg2c+XmDMg13hTxaFnF+6wDkb6dtzRGKK7VrV5bTPiL0/taU0rS3zytdz984pGZieeS74tG7KdSx+IO9WAQ8bNU99Vgk7QiQ4lA17VHmCtxHa1BXXsj3/hJG3J1S6/9WQjuxWqmGPnW2g0tHtcFMqqN0AaF9/fdEoFrY9YKJ3S8M06MyDSBqMuigP3mul7VFGM37qKxpnz/lvnDZ4SDNY32EKYnStMUssjPxr7pnuF+cGubpwM5DNK8/X4FewZRiOT6J1hUjGpPFOuq8hvCqOj1rqjHNcqlxziFSC42w4N/FoNEVn9SaAXvBh1L75nTcm3wXGMKzMxygVCZPc99dsO+XUhpbusDOlN62HGLNJwPteOhKo7ZyQb4k5YWXA==; NID_JKL=CNZkLlqEX2rtTV3YMO64OWCpmUjIqDGQwtQED8C+LlE=; BUC=50ImD0ovxSThrenHO4dcb-MPmonlTPAc0WgfuSDYqZk=',
                'sec-ch-ua-mobile': '?0',
                'sec-ch-ua-platform': '"Windows"',
                'sec-fetch-dest': 'document',
                'sec-fetch-mode': 'navigate',
                'sec-fetch-site': 'none',
                'referer': '',
                'sec-fetch-user': '?1',
                'upgrade-insecure-requests': '1',
                'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'
            }
            response = self.sess.get(url, headers=headers)
            response.encoding = 'utf-8'

            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                script_tag = soup.find('script', string=re.compile('window.__APOLLO_STATE__'))

                if script_tag:
                    json_text = re.search(r'window\.__APOLLO_STATE__\s*=\s*(\{.*\});', script_tag.string)
                    if json_text:
                        data = json.loads(json_text.group(1))
                        name = data.get(f"PlaceDetailBase:{place_id}", {}).get("name", "")
                        address = data.get(f"PlaceDetailBase:{place_id}", {}).get("address", "")
                        roadAddress = data.get(f"PlaceDetailBase:{place_id}", {}).get("roadAddress", "")
                        phone = data.get(f"PlaceDetailBase:{place_id}", {}).get("phone", "")
                        virtualPhone = data.get(f"PlaceDetailBase:{place_id}", {}).get("virtualPhone", "")

                        result["ì—…ì²´ëª…"] = name
                        result["ì£¼ì†Œ(ì§€ë²ˆ)"] = address
                        result["ì£¼ì†Œ(ë„ë¡œëª…)"] = roadAddress
                        result["ì „í™”ë²ˆí˜¸"] = phone
                        result["ê°€ìƒì „í™”ë²ˆí˜¸"] = virtualPhone
                        result["ê²€ìƒ‰ì–´"] = self.keyword

        except requests.exceptions.RequestException as e:
            self.log_func(f"Failed to fetch data for Place ID: {place_id}. Error: {e}")
        except Exception as e:
            self.log_func(f"Error processing data for Place ID: {place_id}: {e}")
        finally:
            return result