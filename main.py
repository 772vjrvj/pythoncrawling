import os
import urllib.request
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import re
import urllib.request
from selenium.webdriver.common.by import By
from selenium.common.exceptions import WebDriverException
import time
from bs4 import BeautifulSoup
from selenium.webdriver.common.action_chains import ActionChains



# ë“œë¼ì´ë²„ ì„¸íŒ… í¬ë¡¬
def setup_driver():
    chrome_options = Options()

    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--incognito")
    chrome_options.add_argument("--window-size=1080,750")
    chrome_options.add_argument("--remote-debugging-port=9222")
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    chrome_options.add_argument(f'user-agent={user_agent}')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
              get: () => undefined
            })
        '''
    })
    return driver


def open_facebook(driver):
    """Navigate to Facebook's main page."""
    driver.get("https://www.facebook.com/")
    print("ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”...")
    input()


def navigate_to_page(driver, page_url):
    """Navigate to a specific Facebook page."""
    driver.get(page_url)
    time.sleep(2)


def extract_caption(driver, feed_unit):
    """Extract caption text with emojis in correct order using BeautifulSoup."""
    try:
        # story_message_element ì°¾ê¸°
        story_message_element = feed_unit.find_element(By.CSS_SELECTOR, '[data-ad-rendering-role="story_message"]')

        # 'ë” ë³´ê¸°' ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
        try:
            # 'ë” ë³´ê¸°' ë²„íŠ¼ ëŒ€ê¸° ë° ì°¾ê¸°
            more_button = WebDriverWait(feed_unit, 10).until(
                EC.presence_of_element_located((By.XPATH,
                                                './/div[contains(@class, "x1i10hfl") and contains(@class, "xjbqb8w") and @role="button" and text()="ë” ë³´ê¸°"]'
                                                ))
            )

            # 'ë” ë³´ê¸°' ë²„íŠ¼ ìŠ¤í¬ë¡¤ë¡œ ê°€ì‹œì„± í™•ë³´
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", more_button)

            # ê°•ì œ í´ë¦­ ì‹œë„
            try:
                ActionChains(driver).move_to_element(more_button).click().perform()
                print("'ë” ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì„±ê³µ!")
            except Exception as e:
                print("'ë” ë³´ê¸°' ê¸°ë³¸ í´ë¦­ ì‹¤íŒ¨, JavaScriptë¡œ í´ë¦­ ì‹œë„:", e)
                driver.execute_script("arguments[0].click();", more_button)

        except Exception as e:
            print("'ë” ë³´ê¸°' ë²„íŠ¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)

        # story_message_elementì˜ innerHTML ì¶”ì¶œ
        caption_html = story_message_element.get_attribute("innerHTML")

        # HTMLì´ ë¹„ì—ˆëŠ”ì§€ í™•ì¸
        if not caption_html:
            print("ìº¡ì…˜ HTMLì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return None

        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = BeautifulSoup(caption_html, 'html.parser')

        # ìˆœì°¨ì ìœ¼ë¡œ ìš”ì†Œë¥¼ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ ì¡°í•©
        final_text = ""
        for element in soup.descendants:
            if element.name == 'img':  # ì´ëª¨ì§€ <img> íƒœê·¸ ì²˜ë¦¬
                emoji_alt = element.get('alt', '')  # <img alt="ğŸ’•">
                final_text += emoji_alt
            elif element.name in ['br', 'div']:  # ì¤„ë°”ê¿ˆ íƒœê·¸ ì²˜ë¦¬
                final_text += '\n'
            elif element.string:  # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                final_text += element.string.strip()

        # ê²°ê³¼ í…ìŠ¤íŠ¸ ë°˜í™˜
        return final_text.strip()

    except Exception as e:
        print("ìº¡ì…˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return None


def click_first_image(driver, feed_unit):
    """Click the first image within a specific feed unit."""
    try:

        if not feed_unit:
            print('feed_unitì´ Noneì…ë‹ˆë‹¤.')
            return

        print('1111111111111111111=====')
        # Explicit Waitë¡œ ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ ëŒ€ê¸°
        image_container = WebDriverWait(feed_unit, 10).until(
            EC.presence_of_element_located(
                (By.CSS_SELECTOR, 'div.x1n2onr6[style*="padding-top: calc(83.3333%);"]')
            )
        )
        print('2222222222222222222=====')

        # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ë§í¬ ì°¾ê¸°
        first_image_link = WebDriverWait(image_container, 10).until(
            EC.element_to_be_clickable((By.TAG_NAME, 'a'))
        )
        print('33333333333333333333=====')

        # ìŠ¤í¬ë¡¤ë¡œ ê°€ì‹œì„± í™•ë³´
        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", first_image_link)
        time.sleep(1)
        # ê¸°ë³¸ í´ë¦­
        try:
            first_image_link.click()
        except Exception as e:
            print("ê¸°ë³¸ í´ë¦­ ì‹¤íŒ¨, JavaScriptë¡œ í´ë¦­ ì‹œë„:", e)
            driver.execute_script("arguments[0].click();", first_image_link)

        # í´ë¦­ í›„ ëŒ€ê¸°
        time.sleep(2)

    except Exception as e:
        print("ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ í´ë¦­í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)


def extract_image_sources(driver):
    """Extract image sources and handle 'ë‹¤ìŒ ì‚¬ì§„' button clicks."""
    img_list = []
    try:
        while True:
            img_element = WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'img[data-visualcompletion="media-vc-image"]'))
            )
            img_src = img_element.get_attribute("src")
            if img_src in img_list:
                # ì¤‘ë³µëœ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í•œ ê²½ìš° ì‚¬ì§„ ë·°ì–´ ë‹«ê¸°
                try:
                    close_button = driver.find_element(By.CSS_SELECTOR, 'div[aria-label="ë‹«ê¸°"]')
                    close_button.click()
                    time.sleep(1)  # ë‹«ëŠ” ë™ì‘ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                except Exception as close_error:
                    print("ë‹«ê¸° ë²„íŠ¼ì„ í´ë¦­í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", close_error)
                break  # ì¤‘ë³µëœ ì´ë¯¸ì§€ê°€ ë°œê²¬ë˜ë©´ ë£¨í”„ ì¢…ë£Œ
            img_list.append(img_src)

            # Click 'Next Photo' button
            next_button = driver.find_element(By.CSS_SELECTOR, 'div[aria-label="ë‹¤ìŒ ì‚¬ì§„"]')
            next_button.click()
            time.sleep(2)
    except Exception as e:
        print("ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
    return img_list


def extract_date(feed_unit):
    """Extract the date from the designated 'a' tag inside the specified div element."""
    try:
        # ëŒ€ê¸° í›„ ì§€ì •ëœ class ì´ë¦„ì„ ê°€ì§„ div ìš”ì†Œ ì°¾ê¸°
        date_container = WebDriverWait(feed_unit, 5).until(
            EC.presence_of_element_located(
                (By.CSS_SELECTOR, 'div.html-div.xdj266r.x11i5rnm.xat24cr.x1mh8g0r.xexx8yu.x4uap5.x18d9i69.xkhd6sd.x1q0g3np')
            )
        )

        # div ìš”ì†Œ ì•ˆì—ì„œ a íƒœê·¸ ì°¾ê¸°
        date_link = date_container.find_element(By.TAG_NAME, 'a')

        # a íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        date_text = date_link.text

        # "ë…„"ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì•ì— "2024ë…„ " ì¶”ê°€
        if "ë…„" not in date_text:
            date_text = f"2024ë…„ {date_text}"

        return date_text
    except Exception as e:
        print("ë‚ ì§œë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return None


def sanitize_folder_name(folder_name):
    """í´ë” ì´ë¦„ì—ì„œ Windows ê¸ˆì§€ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
    return re.sub(r'[\\/:*?"<>|]', '_', folder_name)


def download_with_retry(url, save_path, retries=3, delay=2):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œë¥¼ ì¬ì‹œë„í•©ë‹ˆë‹¤."""
    for attempt in range(retries):
        try:
            urllib.request.urlretrieve(url, save_path)
            return True
        except Exception as e:
            print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retries}): {e}")
            time.sleep(delay)
    return False


def create_folder_and_save_files(date, caption, img_list):
    """teps4u í´ë”ë¥¼ ìƒì„±í•˜ê³  ìº¡ì…˜ ì €ì¥ ë° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        # í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ ì¤‘ì¸ í˜„ì¬ ë””ë ‰í„°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ teps4u í´ë” ì„¤ì •
        base_path = os.getcwd()
        teps4u_path = os.path.join(base_path, "teps4u")
        os.makedirs(teps4u_path, exist_ok=True)

        # ë‚ ì§œë³„ í´ë” ìƒì„±
        folder_path = os.path.join(teps4u_path, sanitize_folder_name(date))
        os.makedirs(folder_path, exist_ok=True)

        # ìº¡ì…˜ ì €ì¥
        caption_file_path = os.path.join(folder_path, "caption.txt")
        with open(caption_file_path, "w", encoding="utf-8") as f:
            f.write(caption[:10000])  # ìº¡ì…˜ ê¸¸ì´ ì œí•œ (ì˜ˆ: 10000ì)

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        for idx, img_url in enumerate(img_list):
            img_path = os.path.join(folder_path, f"image_{idx + 1}.jpg")
            if not download_with_retry(img_url, img_path):
                print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í¬ê¸°: {img_url}")

        print(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {folder_path}")
    except Exception as e:
        print("íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)


def process_feed_unit(driver, feed_unit):
    """Process a single feed unit."""
    try:

        date = extract_date(feed_unit)
        caption = extract_caption(driver, feed_unit)
        click_first_image(driver, feed_unit)
        img_list = extract_image_sources(driver)

        obj = {
            'ë‚ ì§œ': date,
            'caption': caption,
            'ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸': img_list
        }
        print(f'obj : {obj}')
        create_folder_and_save_files(date, caption, img_list)

    except Exception as e:
        print("í”¼ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)


def main():
    driver = setup_driver()
    try:
        open_facebook(driver)
        navigate_to_page(driver, "https://www.facebook.com/teps4u/")

        """ìŠ¤í¬ë¡¤í•˜ë©´ì„œ í”¼ë“œì˜ ì´ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒˆë¡œìš´ í”¼ë“œ ë¡œë“œë¥¼ í™•ì¸í•˜ê³  ì²˜ë¦¬."""
        previous_feed_count = 0  # ì´ì „ í”¼ë“œ ê°œìˆ˜ë¥¼ ì¶”ì 

        while True:
            try:
                # ìŠ¤í¬ë¡¤í•˜ì—¬ ìƒˆë¡œìš´ ì½˜í…ì¸  ë¡œë“œ ì‹œë„
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.5)

                # í˜„ì¬ ë·°ì— í‘œì‹œëœ ëª¨ë“  í”¼ë“œ ê°€ì ¸ì˜¤ê¸°
                feed_units = driver.find_elements(By.CSS_SELECTOR, '[data-pagelet^="TimelineFeedUnit_"]')
                current_feed_count = len(feed_units)

                # í”¼ë“œ ê°œìˆ˜ê°€ ì´ì „ê³¼ ê°™ìœ¼ë©´ ì¤‘ì§€
                if current_feed_count == previous_feed_count:
                    print("ë” ì´ìƒ ìƒˆë¡œìš´ í”¼ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break

                # ìƒˆë¡œìš´ í”¼ë“œ ì²˜ë¦¬
                for feed_unit in feed_units[previous_feed_count:]:
                    try:
                        process_feed_unit(driver, feed_unit)
                    except Exception as e:
                        print(f"í”¼ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

                # í˜„ì¬ í”¼ë“œ ê°œìˆ˜ë¥¼ ì´ì „ í”¼ë“œ ê°œìˆ˜ë¡œ ì—…ë°ì´íŠ¸
                previous_feed_count = current_feed_count

            except WebDriverException as e:
                print(f"ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
            except Exception as e:
                print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

        print("ìŠ¤í¬ë¡¤ ë° ì²˜ë¦¬ ì™„ë£Œ.")

    finally:
        driver.quit()


if __name__ == "__main__":
    main()
