import os
import pandas as pd

# ê²½ë¡œ ì„¤ì •
base_path = r"D:\GIT\pythoncrawling\kmong\ko\prism_research"
excel_path = os.path.join(base_path, "prism_data_work.xlsx")
output_excel = os.path.join(base_path, "prism_data_work_ê²°ê³¼.xlsx")

# ì—‘ì…€ íŒŒì¼ í™•ì¸
if not os.path.exists(excel_path):
    print(f"ì—‘ì…€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {excel_path}")
    exit()

# ì—‘ì…€ íŒŒì¼ ì½ê¸° (Sheet1)
df = pd.read_excel(excel_path, sheet_name="Sheet1")

# 'ì‚¬ì—…ëª…'ê³¼ 'ê³¼ì œëª…'ì´ ëª¨ë‘ ë™ì¼í•œ ë°ì´í„° ì°¾ê¸°
duplicate_rows = df[df.duplicated(subset=["ì‚¬ì—…ëª…", "ê³¼ì œëª…"], keep=False)]

# 'ì‚¬ì—…ëª…'ê³¼ 'ê³¼ì œëª…'ì´ ë™ì¼í•œ ë°ì´í„° ì¤‘ ì²« ë²ˆì§¸ë§Œ ìœ ì§€
# ì¤‘ë³µë˜ì§€ ì•Šì€ ë°ì´í„° (1ê°œë§Œ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
non_duplicated_rows = df.groupby(["ì‚¬ì—…ëª…", "ê³¼ì œëª…"]).filter(lambda x: len(x) == 1)

# ì¤‘ë³µëœ ë°ì´í„° ì¤‘ ì²« ë²ˆì§¸ í–‰ë§Œ ìœ ì§€
unique_rows = pd.concat([
    df[df.duplicated(subset=["ì‚¬ì—…ëª…", "ê³¼ì œëª…"], keep="first") == False],
    non_duplicated_rows
])
# ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
with pd.ExcelWriter(output_excel, engine="xlsxwriter") as writer:
    duplicate_rows.to_excel(writer, sheet_name="ì¤‘ë³µ", index=False)
    unique_rows.to_excel(writer, sheet_name="ì¤‘ë³µì œê±°", index=False)

print(f"ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_excel}")
print("ë¹„êµ ì‘ì—… ì™„ë£Œ! ğŸš€")
