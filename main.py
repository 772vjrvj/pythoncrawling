import requests
from bs4 import BeautifulSoup
import json
import re
import time
import random
import os
import pandas as pd
import datetime
import tkinter as tk
from tkinter import ttk, messagebox
from datetime import timedelta
import threading
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

# ì „ì—­ ë³€ìˆ˜ ì¶”ê°€
stop_event = threading.Event()
search_thread = None
time_val = 5
global_naver_cookies = {}  # ë„¤ì´ë²„ ë¡œê·¸ì¸ ì¿ í‚¤ë¥¼ ì €ì¥
global_server_cookies = {}  # ë‹¤ë¥¸ ì„œë²„ ë¡œê·¸ì¸ ì¿ í‚¤ë¥¼ ì €ì¥
URL = "http://vjrvj.cafe24.com"
login_server_check = ''

def fetch_search_results(query, page):
    try:
        url = f"https://map.naver.com/p/api/search/allSearch?query={query}&type=all&searchCoord=&boundary=&page={page}"
        headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Cache-Control': 'max-age=0',
            'Priority': 'u=0, i',
            'Sec-Ch-Ua': '"Not/A)Brand";v="8", "Chromium";v="126", "Google Chrome";v="126"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Sec-Fetch-Dest': 'document',
            'referer': '',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch search results: {e}")
    return None


def download_image(image_url, save_path):
    try:
        img_data = requests.get(image_url).content
        with open(save_path, 'wb') as handler:
            handler.write(img_data)
    except Exception as e:
        print(f"Failed to download {image_url}: {e}")


def fetch_reviews(place_id):
    try:
        url = "https://api.place.naver.com/place/graphql"
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9',
            'Origin': f'https://m.place.naver.com',
            'Referer': f'https://m.place.naver.com/place/{place_id}/home'
        }

        payload = [
            {
                "operationName": "getVisitorReviews",
                "variables": {
                    "input": {
                        "businessId": place_id,
                        "businessType": "place",
                        "size": 7,
                        "page": 1,
                        "includeContent": True,
                        "cidList": ["222412", "222415", "222446", "1004920"]
                    }
                },
                "query": """
                query getVisitorReviews($input: VisitorReviewsInput) {
                  visitorReviews(input: $input) {
                    items {
                      id
                      rating
                      author {
                        nickname
                        imageUrl
                      }
                      body
                      created
                      tags
                      media {
                        type
                        thumbnail
                      }
                    }
                    total
                  }
                }"""
            },
            {
                "operationName": "getVisitorReviewStats",
                "variables": {
                    "businessType": "place",
                    "id": place_id
                },
                "query": """
                query getVisitorReviewStats($id: String, $businessType: String = "place") {
                  visitorReviewStats(input: {businessId: $id, businessType: $businessType}) {
                    id
                    name
                    review {
                      avgRating
                      totalCount
                    }
                    analysis {
                      votedKeyword {
                        totalCount
                        reviewCount
                        userCount
                        details {
                          code
                          iconUrl
                          displayName
                          count
                        }
                      }
                    }
                  }
                }"""
            }
        ]

        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()

        review_data = response.json()

        if review_data and len(review_data) > 1:
            visitor_reviews_data = review_data[0].get("data", {}).get("visitorReviews", {})
            visitor_reviews = visitor_reviews_data.get("items", []) if visitor_reviews_data else []

            analysis_data = review_data[1].get("data", {}).get("visitorReviewStats", {})
            voted_keyword_data = analysis_data.get("analysis", {}) if analysis_data else {}

            # ì—¬ê¸°ì„œ votedKeywordê°€ Noneì¼ ë•Œë¥¼ ì¶”ê°€ë¡œ ì²˜ë¦¬
            voted_keyword_details = (
                voted_keyword_data.get("votedKeyword", {}).get("details", [])
                if voted_keyword_data.get("votedKeyword") is not None
                else []
            )

            return {
                "reviews": visitor_reviews,
                "stats": voted_keyword_details
            }
        else:
            print(f"No review data available for Place ID: {place_id}")
            return {"reviews": [], "stats": []}

    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch reviews for Place ID: {place_id}. Error: {e}")
        return {"reviews": [], "stats": []}
    except Exception as e:
        print(f"Error while processing data for Place ID: {place_id}: {e}")
        return {"reviews": [], "stats": []}


def fetch_place_info(place_id):
    try:
        url = f"https://m.place.naver.com/place/{place_id}"

        headers = {
            'authority': 'm.place.naver.com',
            'method': 'GET',
            'scheme': 'https',
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'accept-encoding': 'gzip, deflate, br, zstd',
            'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'priority': 'u=0, i',
            'sec-ch-ua': '"Not/A)Brand";v="99", "Google Chrome";v="127", "Chromium";v="127"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-ch-ua-platform-version': '"10.0.0"',
            'sec-fetch-dest': 'document',
            'sec-fetch-mode': 'navigate',
            'sec-fetch-site': 'none',
            'sec-fetch-user': '?1',
            'upgrade-insecure-requests': '1',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'
        }

        response = requests.get(url, headers=headers)
        response.encoding = 'utf-8'

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', string=re.compile('window.__APOLLO_STATE__'))

            if script_tag:
                json_text = re.search(r'window\.__APOLLO_STATE__\s*=\s*(\{.*\});', script_tag.string)
                if json_text:
                    data = json.loads(json_text.group(1))

                    address = data.get(f"PlaceDetailBase:{place_id}", {}).get("roadAddress", "")
                    name = data.get(f"PlaceDetailBase:{place_id}", {}).get("name", "")
                    virtualPhone = data.get(f"PlaceDetailBase:{place_id}", {}).get("virtualPhone", "")

                    prices = []
                    for key, value in data.items():
                        if key.startswith(f"Menu:{place_id}"):
                            prices.append(value)

                    facilities = []
                    for key, value in data.items():
                        if key.startswith("InformationFacilities:"):
                            facilities.append(value)


                    root_query = data.get("ROOT_QUERY", {})
                    place_detail_key = f'placeDetail({{"input":{{"checkRedirect":true,"deviceType":"pc","id":"{place_id}","isNx":false}}}})'

                    information = root_query.get(place_detail_key, {}).get('description({"source":["shopWindow","jto"]})', "")

                    business_hours = root_query.get(place_detail_key, {}).get('businessHours({"source":["tpirates","jto","shopWindow"]})', [])

                    new_business_hours = root_query.get(place_detail_key, {}).get('newBusinessHours', [])

                    url = f"https://m.place.naver.com/place/{place_id}/home"
                    map_url = f"https://map.naver.com/p/entry/place/{place_id}"

                    result = {
                        "ì•„ì´ë””": place_id,
                        "ì´ë¦„": name,
                        "ì£¼ì†Œ": address,
                        "ê°€ìƒë²ˆí˜¸": virtualPhone,
                        "ê¸ˆì•¡": prices,
                        "í¸ì˜": facilities,
                        "ì˜ì—…ì‹œê°„": business_hours,
                        "ìƒˆë¡œìš´ ì˜ì—…ì‹œê°„": new_business_hours,
                        "ì •ë³´": information,
                        "URL": url,
                        "ì§€ë„": map_url
                    }

                    return result

    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch data for Place ID: {place_id}. Error: {e}")
    except Exception as e:
        print(f"Error processing data for Place ID: {place_id}: {e}")
    return None


def fetch_photos(place_id):
    url = "https://api.place.naver.com/graphql"
    headers = {
        'Content-Type': 'application/json',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate, br, zstd',
        'Accept-Language': 'ko-KR,ko;q=0.9',
        'Origin': 'https://m.place.naver.com',
        'Referer': f'https://m.place.naver.com/place/{place_id}/home'
    }
    payload = [
        {
            "operationName": "getPhotoViewerItems",
            "variables": {
                "input": {
                    "businessId": place_id,
                    "businessType": "restaurant",
                    "cursors": [
                        {"id": "biz"},
                        {"id": "cp0"},
                        {"id": "visitorReview"},
                        {"id": "clip"},
                        {"id": "imgSas"}
                    ],
                    "excludeAuthorIds": [],
                    "excludeSection": [],
                    "excludeClipIds": [],
                    "dateRange": ""
                }
            },
            "query": """
            query getPhotoViewerItems($input: PhotoViewerInput) {
              photoViewer(input: $input) {
                cursors {
                  id
                  startIndex
                  hasNext
                  lastCursor
                  __typename
                }
                photos {
                  viewId
                  originalUrl
                  width
                  height
                  title
                  text
                  desc
                  link
                  date
                  photoType
                  mediaType
                  option {
                    channelName
                    dateString
                    playCount
                    likeCount
                    __typename
                  }
                  to
                  relation
                  logId
                  author {
                    id
                    nickname
                    from
                    imageUrl
                    objectId
                    url
                    borderImageUrl
                    __typename
                  }
                  votedKeywords {
                    code
                    iconUrl
                    iconCode
                    displayName
                    __typename
                  }
                  visitCount
                  originType
                  isFollowing
                  businessName
                  rating
                  externalLink {
                    title
                    url
                    __typename
                  }
                  sourceTitle
                  moment {
                    channelId
                    contentId
                    momentId
                    gdid
                    blogRelation
                    statAllowYn
                    category
                    docNo
                    __typename
                  }
                  video {
                    videoId
                    videoUrl
                    trailerUrl
                    __typename
                  }
                  music {
                    artists
                    title
                    __typename
                  }
                  clip {
                    viewerHash
                    __typename
                  }
                  __typename
                }
                __typename
              }
            }
            """
        }
    ]
    image_urls = []
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        data = response.json()

        # ì›í•˜ëŠ” ë°ì´í„° ì¶”ì¶œ ì˜ˆì‹œ (originalUrlë§Œ ì¶”ì¶œ)
        photos = data[0].get('data', {}).get('photoViewer', {}).get('photos', [])
        for photo in photos:
            image_urls.append(photo.get('originalUrl'))

        return image_urls[:5]

    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
        return image_urls


def fetch_link_url(place_id):
    url = "https://me2do.naver.com/common/requestJsonpV2"
    headers = {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "connection": "keep-alive",
        "host": "me2do.naver.com",
        "referer": f"https://pcmap.place.naver.com/{place_id}/home?from=map&fromPanelNum=1&additionalHeight=76&timestamp=202410090914",
        "sec-ch-ua": '"Google Chrome";v="129", "Not=A?Brand";v="8", "Chromium";v="129"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "sec-fetch-dest": "script",
        "sec-fetch-mode": "no-cors",
        "sec-fetch-site": "same-site",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"
    }
    params = {
        "_callback": "window.spi_9197316230",
        "svcCode": "0022",
        "url": f"https://m.place.naver.com/share?id={place_id}&tabsPath=%2Fhome&appMode=detail"
    }
    link_url = ""
    try:
        # GET ìš”ì²­ ë³´ë‚´ê¸°
        response = requests.get(url, headers=headers, params=params)

        # ì‘ë‹µ ë‚´ìš©ì—ì„œ ì½œë°± í•¨ìˆ˜ ì œê±° (JSON ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)
        jsonp_data = response.text
        json_data = re.search(r'window\.spi_9197316230\((.*)\)', jsonp_data).group(1)

        # ì¶”ì¶œëœ JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        data = json.loads(json_data)

        # í•„ìš”í•œ 'url' ê°’ ì¶œë ¥
        print(data['result']['url'])
        link_url = data['result']['url']
        return link_url

    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
        return link_url

def extract_information(information):
    try:
        return f"â„¹ï¸ {information}".strip() if information else ""
    except Exception:
        return ""


def format_address(address):
    try:
        return f"ğŸ“ {address}".strip() if address else ""
    except Exception:
        return ""


def format_phone_number(virtual_number, name=''):
    try:
        if virtual_number:
            formatted_phone = (f"ğŸ“ ì „í™”ë²ˆí˜¸\n"
                               f"{virtual_number}\n"
                               f"â€˜{name}â€™(ìœ¼)ë¡œ ì—°ê²°ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ì½œ ë²ˆí˜¸ì…ë‹ˆë‹¤.\n"
                               f"ì—…ì²´ ì „í™”ë²ˆí˜¸ {virtual_number}".strip())
            return formatted_phone
        return ""
    except Exception:
        return ""


def format_price(prices):
    formatted_prices = []
    try:
        for price_info in prices:
            name = price_info.get('name', '')
            price = price_info.get('price', '')
            if name and price:
                try:
                    formatted_price = f"{int(price):,}ì›"
                    formatted_prices.append(f"- {name} {formatted_price}")
                except ValueError:
                    continue
    except Exception:
        return ""
    return "ğŸ’µ ê¸ˆì•¡\n" + '\n'.join(formatted_prices).strip() if formatted_prices else ""


def format_facilities(facilities):
    try:
        facility_names = [facility.get('name', '') for facility in facilities]
        return "ğŸ·ï¸ í¸ì˜\n" + ', '.join(facility_names).strip() if facility_names else ""
    except Exception:
        return ""


def format_business_hours(business_hours):
    formatted_hours = []
    try:
        for hour in business_hours:
            day = hour.get('day', '')
            start_time = hour.get('startTime', '')
            end_time = hour.get('endTime', '')
            if day and start_time and end_time:
                formatted_hours.append(f"{day} {start_time} - {end_time}")
    except Exception:
        return ""
    return "â° ì˜ì—…ì‹œê°„\n" + '\n'.join(formatted_hours).strip() if formatted_hours else ""


def format_new_business_hours(new_business_hours):
    formatted_hours = []
    try:
        if new_business_hours:
            for item in new_business_hours:
                status_description = item.get('businessStatusDescription', {})
                status = status_description.get('status', '')
                description = status_description.get('description', '')

                if status:
                    formatted_hours.append(status)
                if description:
                    formatted_hours.append(description)

                for info in item.get('businessHours', []):
                    day = info.get('day', '')
                    business_hours = info.get('businessHours', {})
                    start_time = business_hours.get('start', '')
                    end_time = business_hours.get('end', '')

                    break_hours = info.get('breakHours', [])
                    break_times = [f"{bh.get('start', '')} - {bh.get('end', '')}" for bh in break_hours]
                    break_times_str = ', '.join(break_times) + ' ë¸Œë ˆì´í¬íƒ€ì„' if break_times else ''

                    if day:
                        formatted_hours.append(day)
                    if start_time and end_time:
                        formatted_hours.append(f"{start_time} - {end_time}")
                    if break_times_str:
                        formatted_hours.append(break_times_str)
    except Exception:
        return ""
    return "â° ì˜ì—…ì‹œê°„\n" + '\n'.join(formatted_hours).strip() if formatted_hours else ""


def format_review_analysis(review_analysis):
    formatted_items = []
    try:
        top_items = review_analysis[:7]
        for item in top_items:
            count = item.get('count', 0)
            display_name = item.get('displayName', '')
            if count and display_name:
                if count == 1:
                    formatted_items.append(f"- 1ëª…ì˜ ë°©ë¬¸ìê°€ \"{display_name}\"ë¼ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.")
                else:
                    formatted_items.append(f"- {count}ëª…ì˜ ë°©ë¬¸ìë¶„ë“¤ì´ \"{display_name}\"ë¼ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.")
    except Exception:
        return ""
    return "â­ ë°©ë¬¸ì í›„ê¸°\n" + '\n'.join(formatted_items).strip() if formatted_items else ""


def print_place_info(place_info):
    try:
        # ê° í•­ëª©ì„ í¬ë§·
        formatted_address = format_address(place_info.get("ì£¼ì†Œ", ""))
        formatted_phone = format_phone_number(place_info.get("ê°€ìƒë²ˆí˜¸", ""), place_info.get("ì´ë¦„", ""))
        formatted_price = format_price(place_info.get("ê¸ˆì•¡", []))
        formatted_facilities = format_facilities(place_info.get("í¸ì˜", []))
        # formatted_business_hours = format_business_hours(place_info.get("ì˜ì—…ì‹œê°„", []))
        formatted_new_business_hours = format_new_business_hours(place_info.get("ìƒˆë¡œìš´ ì˜ì—…ì‹œê°„", []))
        formatted_information = extract_information(place_info.get("ì •ë³´", []))
        formatted_reviews = format_review_analysis(place_info.get("ë¦¬ë·° ë¶„ì„", []))
        map_url = place_info.get("ì§€ë„", "")

        # ìœ íš¨í•œ í•­ëª©ë§Œì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        sections = [
            formatted_address,
            formatted_new_business_hours,
            # formatted_business_hours,
            formatted_phone,
            formatted_price,
            formatted_facilities,
            formatted_information,
            formatted_reviews,
            f"ğŸ—ºï¸ ì§€ë„\n{formatted_address}" if formatted_address else ""
        ]

        # ìœ íš¨í•œ í•­ëª©ì„ í•©ì¹˜ê³ , ê° í•­ëª© ì‚¬ì´ì— 3ê°œì˜ ì—”í„°ë¥¼ ì¶”ê°€
        content = "\n\n\n\n".join(section for section in sections if section)

        return content.strip()  # ì•ë’¤ ê³µë°± ì œê±°
    except Exception:
        return ""


def new_print(text, level="INFO"):
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    formatted_text = f"[{timestamp}] [{level}] {text}"
    print(formatted_text)
    log_text_widget.insert(tk.END, f"{formatted_text}\n")
    log_text_widget.see(tk.END)


def main(query, total_queries, current_query_index, total_locs, locs_index, check):
    try:
        page = 1
        results = []
        all_ids = set()
        all_ids_list = []
        total_count = 0

        # í‚¤ì›Œë“œì— ë§¤í•‘ë˜ëŠ” ì•„ì´ë”” ìˆ˜ì§‘
        new_print(f"í¬ë¡¤ë§ ì‹œì‘")
        while True:
            if stop_event.is_set():
                return

            result = fetch_search_results(query, page)
            if not result:
                break

            place_list = result.get("result", {}).get("place", {}).get("list", [])
            ids_this_page = [place.get("id") for place in place_list if place.get("id")]

            new_print(f"ì „êµ­ : {locs_index}/{total_locs}, í‚¤ì›Œë“œ : {current_query_index}/{total_queries}, í˜ì´ì§€ : {page}, ê²€ìƒ‰ì–´ : {query}==============================================")
            new_print(f"í˜ì´ì§€ : {page}, ëª©ë¡ : {ids_this_page}")

            if not ids_this_page:
                break

            all_ids.update(ids_this_page)
            page += 1
            time.sleep(random.uniform(1, 2))

        if not stop_event.is_set():
            all_ids_list = list(all_ids)
            total_count = len(all_ids_list)
            new_print(f"ì „êµ­ : {locs_index}/{total_locs}, í‚¤ì›Œë“œ : {current_query_index}/{total_queries}, ì „ì²´ : {total_count}, ê²€ìƒ‰ì–´ : {query}==============================================")

        for idx, place_id in enumerate(all_ids_list, start=1):
            if stop_event.is_set():
                return

            place_info = fetch_place_info(place_id)
            if place_info:
                reviews_info = fetch_reviews(place_id)
                place_info["ë¦¬ë·°"] = reviews_info.get("reviews", [])
                place_info["ë¦¬ë·° ë¶„ì„"] = reviews_info.get("stats", [])
                place_info["ê³µìœ  URL"] = fetch_link_url(place_id)
                name = place_info["ì´ë¦„"]
                image_urls = fetch_photos(place_id)
                os.makedirs(f'images/{query}/{idx}. {name}', exist_ok=True)
                for i, image_url in enumerate(image_urls, start=1):
                    download_image(image_url, f'images/{query}/{idx}. {name}/{name}_{i}.jpg')
                place_info['ì´ë¯¸ì§€ URLs'] = image_urls
                results.append(place_info)

                new_print(f"ë²ˆí˜¸ : {idx}, ì´ë¦„ : {place_info['ì´ë¦„']}")
                time.sleep(random.uniform(1, 2))

        if not stop_event.is_set():
            query_no_spaces = query.replace(" ", "")
            save_to_excel(results, query_no_spaces)

    except Exception as e:
        print(f"Unexpected error: {e}")




def save_to_excel(results, query_no_spaces, mode='w'):
    new_print(f"ì—‘ì…€ ì €ì¥ ì‹œì‘...")
    blogs = []
    for result in results:
        blog = {}
        blog["ì•„ì´ë””"] = result["ì•„ì´ë””"]
        blog["ì´ë¦„"] = result["ì´ë¦„"]
        blog["ë¸”ë¡œê·¸ ì œëª©"] = f"{query_no_spaces} / {result['ì´ë¦„']} / ìš´ì˜ì‹œê°„ ê°€ê²© ì£¼ì°¨ë¦¬ë·°"
        blog["ë¸”ë¡œê·¸ ê²Œì‹œê¸€"] = print_place_info(result)
        # ì´ë¯¸ì§€ ë§í¬ì™€ ë¸”ë¡œê·¸ ê²Œì‹œê¸€ ìƒì„±
        image_urls = result.get("ì´ë¯¸ì§€ URLs", [])
        image_links = "\n".join(image_urls[:5])
        blog["ì£¼ì†Œ"] = result["ì£¼ì†Œ"]
        blog["ì´ë¯¸ì§€"] = image_links
        blog["ì •ë³´ URL"] = result["URL"]
        blog["ì§€ë„ URL"] = result["ì§€ë„"]
        blog["ê³µìœ  URL"] = result["ê³µìœ  URL"]

        print(blog["ë¸”ë¡œê·¸ ê²Œì‹œê¸€"])
        blogs.append(blog)

    # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ êµ¬í•˜ê¸°
    now = datetime.datetime.now()
    timestamp = now.strftime("%Y%m%d%H%M")

    # íŒŒì¼ ì´ë¦„ì— í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ ì¶”ê°€, íŒŒì¼ ì´ë¦„ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    file_name = sanitize_filename(f'naver_place_{timestamp}.xlsx')
    try:
        if mode == 'a':
            existing_df = pd.read_excel(file_name)
            new_df = pd.DataFrame(blogs)
            df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            df = pd.DataFrame(blogs)
        df.to_excel(file_name, index=False)
    except FileNotFoundError:
        df = pd.DataFrame(blogs)
        df.to_excel(file_name, index=False)

    new_print(f"ì—‘ì…€ ì €ì¥ {file_name}")
    # ë©”ì‹œì§€ë°•ìŠ¤ í‘œì‹œ


def sanitize_filename(name):
    # íŒŒì¼ ì´ë¦„ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.
    return re.sub(r'[\\/*?:"<>|]', "", name)




def run_main(querys):
    global checkbox_var

    locs = [
        { 'ì‹œë„' : 'ì „ë¶' , 'ì‹œêµ°êµ¬' : 'ë¬´ì£¼êµ°' , 'ìë©´ë™' : 'ë¬´ì£¼ì' },
        { 'ì‹œë„' : 'ì„œìš¸' , 'ì‹œêµ°êµ¬' : 'ì¢…ë¡œêµ¬' , 'ìë©´ë™' : 'ì²­ìš´ë™' }
    ]

    try:
        query_list = [q.strip() for q in querys.split(",")]
        total_queries = len(query_list)
        total_locs = len(locs)

        if checkbox_var:
            for index, loc in enumerate(locs, start=1):
                if stop_event.is_set():
                    break
                name = f'{loc["ì‹œë„"]} {loc["ì‹œêµ°êµ¬"]} {loc["ìë©´ë™"]} '
                for idx, query in enumerate(query_list, start=1):
                    if stop_event.is_set():
                        break
                    full_name = name + query
                    new_print(f"ì „êµ­ : {index}/{total_locs}, í‚¤ì›Œë“œ : {idx}/{total_queries}, ê²€ìƒ‰ì–´ : {full_name}==============================================")
                    main(query, total_queries, idx, total_locs, index, checkbox_var)
        else:
            for ix, qr in enumerate(query_list, start=1):
                if stop_event.is_set():
                    break
                new_print(f"ì „êµ­ : 0/0, í‚¤ì›Œë“œ : {ix}/{total_queries}, ê²€ìƒ‰ì–´ : {qr}==============================================")
                main(qr, total_queries, ix, 0, 0, checkbox_var)

        if not stop_event.is_set():
            messagebox.showwarning("ê²½ê³ ", "í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            search_button.config(bg="lightgreen", fg="black", text="ê²€ìƒ‰")

    except Exception as e:
        new_print(f"Unexpected error in thread: {e}", "ERROR")


# ê²€ìƒ‰ ë²„íŠ¼
def on_search():
    global search_thread, stop_event
    query = search_entry.get().strip()
    if query:
        if search_thread and search_thread.is_alive():
            # ì¤‘ì§€ ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ ì‘ì—… ì¤‘ì§€
            new_print("í¬ë¡¤ë§ ì¤‘ì§€")
            stop_event.set()  # ì´ë²¤íŠ¸ ì„¤ì •
            search_button.config(bg="lightgreen", fg="black", text="ê²€ìƒ‰")
            messagebox.showwarning("ê²½ê³ ", "í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            # ì‹œì‘ ë²„íŠ¼ í´ë¦­ ì‹œ ëª¨ë“  ì§„í–‰ë¥  ì´ˆê¸°í™”
            stop_event.clear()  # ì´ë²¤íŠ¸ ì´ˆê¸°í™”
            log_text_widget.delete('1.0', tk.END)  # ë¡œê·¸ ì´ˆê¸°í™”
            search_button.config(bg="red", fg="white", text="ì¤‘ì§€")
            search_thread = threading.Thread(target=run_main, args=(query,))
            search_thread.start()
    else:
        messagebox.showwarning("ê²½ê³ ", "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


# ì—¬ê¸°ì— main í•¨ìˆ˜ì™€ ê¸°íƒ€ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ í¬í•¨ì‹œí‚¤ì„¸ìš”.
def start_app():
    global root, search_entry, search_button, log_text_widget, checkbox_var

    root = tk.Tk()
    root.title("ë„¤ì´ë²„ ë¸”ë¡œê·¸ í”„ë¡œê·¸ë¨")
    root.geometry("700x600")  # í¬ê¸° ì¡°ì •

    # ì²´í¬ë°•ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ rootê°€ ë¨¼ì € ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    checkbox_var = tk.BooleanVar()  # ì²´í¬ë°•ìŠ¤ì˜ ìƒíƒœë¥¼ ì €ì¥í•  ë³€ìˆ˜

    font_large = ('Helvetica', 10)  # í°íŠ¸ í¬ê¸°

    # ì˜µì…˜ í”„ë ˆì„
    option_frame = tk.Frame(root)
    option_frame.pack(fill=tk.X, padx=10, pady=10)

    # ê²€ìƒ‰ì–´ ì…ë ¥ í”„ë ˆì„
    search_frame = tk.Frame(root)
    search_frame.pack(pady=20)

    # ê²€ìƒ‰ì–´ ë ˆì´ë¸”
    search_label = tk.Label(search_frame, text="ê²€ìƒ‰ì–´:", font=font_large)
    search_label.grid(row=0, column=0, padx=5, pady=5, sticky='w')

    # ê²€ìƒ‰ì–´ ì…ë ¥ í•„ë“œ
    search_entry = tk.Entry(search_frame, font=font_large, width=25)
    search_entry.grid(row=0, column=1, padx=5, pady=5, sticky='ew')

    # ê²€ìƒ‰ ë²„íŠ¼
    search_button = tk.Button(search_frame, text="ê²€ìƒ‰", font=font_large, bg="lightgreen", command=on_search)
    search_button.grid(row=0, column=2, padx=5, pady=5)

    # ì•ˆë‚´ ë¬¸êµ¬
    guide_label = tk.Label(search_frame, text="* ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš” *", font=font_large, fg="red")
    guide_label.grid(row=1, column=0, columnspan=3, padx=5, pady=5)

    # ì²´í¬ë°•ìŠ¤ ìƒì„±
    checkbox = tk.Checkbutton(search_frame, text="ì „êµ­ ì„ íƒ", font=font_large, variable=checkbox_var)
    checkbox.grid(row=2, column=0, columnspan=3, padx=5, pady=5)

    # ê²€ìƒ‰ í”„ë ˆì„ì˜ ì—´ ë¹„ìœ¨ ì„¤ì •
    search_frame.columnconfigure(1, weight=1)

    # ë¡œê·¸ í™”ë©´
    log_label = tk.Label(root, text="ë¡œê·¸ í™”ë©´", font=font_large)
    log_label.pack(fill=tk.X, padx=10)

    log_frame = tk.Frame(root)
    log_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

    x_scrollbar = tk.Scrollbar(log_frame, orient=tk.HORIZONTAL)
    x_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)

    y_scrollbar = tk.Scrollbar(log_frame, orient=tk.VERTICAL)
    y_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

    log_text_widget = tk.Text(log_frame, wrap=tk.NONE, height=10, font=font_large, xscrollcommand=x_scrollbar.set, yscrollcommand=y_scrollbar.set)
    log_text_widget.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

    x_scrollbar.config(command=log_text_widget.xview)
    y_scrollbar.config(command=log_text_widget.yview)

    root.mainloop()


# ì…€ë ˆë‹ˆì›€ ì„¸íŒ…
def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1080,750")
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    chrome_options.add_argument(f'user-agent={user_agent}')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
              get: () => undefined
            })
        '''
    })
    return driver


# ë„¤ì´ë²„ ë¡œê·¸ì¸ ì°½ í•¨ìˆ˜
def naver_login_window():
    def on_naver_login():
        global global_naver_cookies  # ë„¤ì´ë²„ ì¿ í‚¤ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©

        driver = setup_driver()
        driver.get("https://nid.naver.com/nidlogin.login")  # ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™

        # ë¡œê·¸ì¸ ì—¬ë¶€ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬
        logged_in = False
        max_wait_time = 300  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        start_time = time.time()

        while not logged_in:
            # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¿ í‚¤ í™•ì¸
            time.sleep(1)
            elapsed_time = time.time() - start_time

            # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ì‹œ while ë£¨í”„ ì¢…ë£Œ
            if elapsed_time > max_wait_time:
                messagebox.showwarning("ê²½ê³ ", "ë¡œê·¸ì¸ ì‹¤íŒ¨: 300ì´ˆ ë‚´ì— ë¡œê·¸ì¸í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                break

            cookies = {cookie['name']: cookie['value'] for cookie in driver.get_cookies()}

            # ì¿ í‚¤ ì¤‘ NID_AUT ë˜ëŠ” NID_SES ì¿ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸ (ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ìƒì„±ë˜ëŠ” ì¿ í‚¤)
            if 'NID_AUT' in cookies and 'NID_SES' in cookies:
                logged_in = True
                global_naver_cookies = cookies  # ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ì¿ í‚¤ ì €ì¥
                messagebox.showinfo("ë¡œê·¸ì¸ ì„±ê³µ", "ì •ìƒ ë¡œê·¸ì¸ ë˜ì—ˆìŠµë‹ˆë‹¤.")

        driver.quit()  # ì‘ì—…ì´ ëë‚œ í›„ ë“œë¼ì´ë²„ ì¢…ë£Œ
        naver_login_root.destroy()
        start_app()

    # ë„¤ì´ë²„ ë¡œê·¸ì¸ ì°½ ìƒì„±
    naver_login_root = tk.Tk()
    naver_login_root.title("ë„¤ì´ë²„ ë¡œê·¸ì¸")

    # ì°½ í¬ê¸° ì„¤ì •
    naver_login_root.geometry("300x150")  # ì°½ í¬ê¸°
    screen_width = naver_login_root.winfo_screenwidth()  # í™”ë©´ ë„ˆë¹„
    screen_height = naver_login_root.winfo_screenheight()  # í™”ë©´ ë†’ì´
    window_width = 300  # ì°½ ë„ˆë¹„
    window_height = 150  # ì°½ ë†’ì´

    # ì°½ì„ í™”ë©´ì˜ ê°€ìš´ë°ë¡œ ë°°ì¹˜
    position_top = int(screen_height / 2 - window_height / 2)
    position_left = int(screen_width / 2 - window_width / 2)
    naver_login_root.geometry(f'{window_width}x{window_height}+{position_left}+{position_top}')

    # ë„¤ì´ë²„ ë¡œê·¸ì¸ ë²„íŠ¼
    naver_login_button = tk.Button(naver_login_root, text="ë„¤ì´ë²„ ë¡œê·¸ì¸", command=on_naver_login)
    naver_login_button.pack(pady=30)

    naver_login_root.mainloop()


# ì„œë²„ ë¡œê·¸ì¸ í•¨ìˆ˜ (ë„¤ì´ë²„ì™€ ë‹¤ë¥¸ ì„œë²„ êµ¬ë¶„)
def login_to_server(username, password, session):
    global global_server_cookies
    url = f"{URL}/auth/login"
    payload = {
        "username": username,
        "password": password
    }
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    try:
        # JSON í˜•ì‹ìœ¼ë¡œ ì„œë²„ì— POST ìš”ì²­ìœ¼ë¡œ ë¡œê·¸ì¸ ì‹œë„
        response = session.post(url, json=payload, headers=headers)  # í—¤ë” ì¶”ê°€

        # ìš”ì²­ì´ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
        if response.status_code == 200:
            print("Login successful")
            print("Response data:", response.json())

            # ì„¸ì…˜ ê´€ë¦¬ë¡œ ì¿ í‚¤ëŠ” ìë™ ì²˜ë¦¬
            print("Cookies after login:", session.cookies)
            global_server_cookies = session.cookies.get_dict()
            print("Cookies:", global_server_cookies)
            return True
        else:
            print("Login failed with status code:", response.status_code)
            print("Error message:", response.text)
            return False
    except Exception as e:
        print("An error occurred during login:", e)
        return False


# ì„¸ì…˜ì²´í¬
def check_session(session, server_type="server"):
    global login_server_check
    cookies = global_server_cookies if server_type == "server" else global_naver_cookies
    url = f"{URL}/session/check-me"
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    try:
        # /check-me ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì„¸ì…˜ ìƒíƒœ í™•ì¸
        response = session.get(url, headers=headers, cookies=cookies)
        print("Request headers for check-me:", response.request.headers)

        if response.status_code == 200:
            print("Session check successful:", response.text)
            login_server_check = response.text
        else:
            print("Session check failed with status code:", response.status_code)
            print("Error message:", response.text)
    except Exception as e:
        print("An error occurred while checking session:", e)


# ì„¸ì…˜ ì‹¤ì‹œê°„ ìš”ì²­
def check_session_periodically(session, server_type="server"):
    while True:
        time.sleep(300)  # 5ë¶„ ëŒ€ê¸°
        check_session(session, server_type)  # ì„¸ì…˜ ìƒíƒœë¥¼ ì²´í¬


# ë¡œê·¸ì¸
def on_login():
    user_id = id_entry.get()
    user_pw = pw_entry.get()

    # ì„œë²„ ì„¸ì…˜ ê´€ë¦¬
    session = requests.Session()
    if login_to_server(user_id, user_pw, session):
        messagebox.showinfo("ë¡œê·¸ì¸ ì„±ê³µ", "ë¡œê·¸ì¸ ì„±ê³µ!")
        login_root.destroy()
        # ë¡œê·¸ì¸ ì„±ê³µ í›„, ì„¸ì…˜ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•˜ëŠ” ì“°ë ˆë“œ ì‹œì‘
        session_thread = threading.Thread(target=check_session_periodically, args=(session, "server"), daemon=True)
        session_thread.start()

        # ë¡œê·¸ì¸ í›„ ë„¤ì´ë²„ ë¡œê·¸ì¸ ì°½ì„ ë„ìš´ë‹¤
        naver_login_window()
    else:
        messagebox.showerror("ë¡œê·¸ì¸ ì‹¤íŒ¨", "ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")


# ë¡œê·¸ì¸ ì°½ ìƒì„±
def login_window():
    global login_root, id_entry, pw_entry

    login_root = tk.Tk()
    login_root.title("ë¡œê·¸ì¸")

    # ì°½ í¬ê¸° ì„¤ì •
    login_root.geometry("300x200")  # ì°½ í¬ê¸°
    screen_width = login_root.winfo_screenwidth()  # í™”ë©´ ë„ˆë¹„
    screen_height = login_root.winfo_screenheight()  # í™”ë©´ ë†’ì´
    window_width = 300  # ì°½ ë„ˆë¹„
    window_height = 200  # ì°½ ë†’ì´

    # ì°½ì„ í™”ë©´ì˜ ê°€ìš´ë°ë¡œ ë°°ì¹˜
    position_top = int(screen_height / 2 - window_height / 2)
    position_left = int(screen_width / 2 - window_width / 2)
    login_root.geometry(f'{window_width}x{window_height}+{position_left}+{position_top}')

    # ID ì…ë ¥
    id_label = tk.Label(login_root, text="ID:")
    id_label.pack(pady=10)
    id_entry = tk.Entry(login_root, width=20)
    id_entry.pack(pady=5)

    # PW ì…ë ¥
    pw_label = tk.Label(login_root, text="PW:")
    pw_label.pack(pady=10)
    pw_entry = tk.Entry(login_root, show="*", width=20)
    pw_entry.pack(pady=5)

    # ë¡œê·¸ì¸ ë²„íŠ¼
    login_button = tk.Button(login_root, text="ë¡œê·¸ì¸", command=on_login)
    login_button.pack(pady=10)

    login_root.mainloop()


# ë©”ì¸
if __name__ == "__main__":
    # login_window()  # ë¡œê·¸ì¸ ì°½ í˜¸ì¶œ
    start_app()