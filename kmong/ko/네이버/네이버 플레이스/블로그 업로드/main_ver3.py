import requests
from bs4 import BeautifulSoup
import json
import re
import time
import random
import os
import pandas as pd
import datetime
import tkinter as tk
from tkinter import ttk, messagebox
from datetime import timedelta
import threading


# ì „ì—­ ë³€ìˆ˜ ì¶”ê°€
stop_event = threading.Event()
search_thread = None
time_val = 5

def fetch_search_results(query, page):
    try:
        url = f"https://map.naver.com/p/api/search/allSearch?query={query}&type=all&searchCoord=&boundary=&page={page}"
        headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Cache-Control': 'max-age=0',
            'Priority': 'u=0, i',
            'Sec-Ch-Ua': '"Not/A)Brand";v="8", "Chromium";v="126", "Google Chrome";v="126"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Sec-Fetch-Dest': 'document',
            'referer': '',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch search results: {e}")
    return None


def download_image(image_url, save_path):
    try:
        img_data = requests.get(image_url).content
        with open(save_path, 'wb') as handler:
            handler.write(img_data)
    except Exception as e:
        print(f"Failed to download {image_url}: {e}")


def fetch_reviews(place_id):
    try:
        url = "https://api.place.naver.com/place/graphql"
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'ko-KR,ko;q=0.9',
            'Origin': f'https://m.place.naver.com',
            'Referer': f'https://m.place.naver.com/place/{place_id}/home'
        }

        payload = [
            {
                "operationName": "getVisitorReviews",
                "variables": {
                    "input": {
                        "businessId": place_id,
                        "businessType": "place",
                        "size": 7,
                        "page": 1,
                        "includeContent": True,
                        "cidList": ["222412", "222415", "222446", "1004920"]
                    }
                },
                "query": """
                query getVisitorReviews($input: VisitorReviewsInput) {
                  visitorReviews(input: $input) {
                    items {
                      id
                      rating
                      author {
                        nickname
                        imageUrl
                      }
                      body
                      created
                      tags
                      media {
                        type
                        thumbnail
                      }
                    }
                    total
                  }
                }"""
            },
            {
                "operationName": "getVisitorReviewStats",
                "variables": {
                    "businessType": "place",
                    "id": place_id
                },
                "query": """
                query getVisitorReviewStats($id: String, $businessType: String = "place") {
                  visitorReviewStats(input: {businessId: $id, businessType: $businessType}) {
                    id
                    name
                    review {
                      avgRating
                      totalCount
                    }
                    analysis {
                      votedKeyword {
                        totalCount
                        reviewCount
                        userCount
                        details {
                          code
                          iconUrl
                          displayName
                          count
                        }
                      }
                    }
                  }
                }"""
            }
        ]

        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()

        review_data = response.json()

        if review_data and len(review_data) > 1:
            visitor_reviews_data = review_data[0].get("data", {}).get("visitorReviews", {})
            visitor_reviews = visitor_reviews_data.get("items", []) if visitor_reviews_data else []

            analysis_data = review_data[1].get("data", {}).get("visitorReviewStats", {})
            voted_keyword_data = analysis_data.get("analysis", {}) if analysis_data else {}

            # ì—¬ê¸°ì„œ votedKeywordê°€ Noneì¼ ë•Œë¥¼ ì¶”ê°€ë¡œ ì²˜ë¦¬
            voted_keyword_details = (
                voted_keyword_data.get("votedKeyword", {}).get("details", [])
                if voted_keyword_data.get("votedKeyword") is not None
                else []
            )

            return {
                "reviews": visitor_reviews,
                "stats": voted_keyword_details
            }
        else:
            print(f"No review data available for Place ID: {place_id}")
            return {"reviews": [], "stats": []}

    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch reviews for Place ID: {place_id}. Error: {e}")
        return {"reviews": [], "stats": []}
    except Exception as e:
        print(f"Error while processing data for Place ID: {place_id}: {e}")
        return {"reviews": [], "stats": []}


def fetch_place_info(place_id):
    try:
        url = f"https://m.place.naver.com/place/{place_id}"

        headers = {
            'authority': 'm.place.naver.com',
            'method': 'GET',
            'scheme': 'https',
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'accept-encoding': 'gzip, deflate, br, zstd',
            'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'priority': 'u=0, i',
            'sec-ch-ua': '"Not/A)Brand";v="99", "Google Chrome";v="127", "Chromium";v="127"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-ch-ua-platform-version': '"10.0.0"',
            'sec-fetch-dest': 'document',
            'sec-fetch-mode': 'navigate',
            'sec-fetch-site': 'none',
            'sec-fetch-user': '?1',
            'upgrade-insecure-requests': '1',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'
        }

        response = requests.get(url, headers=headers)
        response.encoding = 'utf-8'

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', string=re.compile('window.__APOLLO_STATE__'))

            if script_tag:
                json_text = re.search(r'window\.__APOLLO_STATE__\s*=\s*(\{.*\});', script_tag.string)
                if json_text:
                    data = json.loads(json_text.group(1))

                    address = data.get(f"PlaceDetailBase:{place_id}", {}).get("roadAddress", "")
                    name = data.get(f"PlaceDetailBase:{place_id}", {}).get("name", "")
                    virtualPhone = data.get(f"PlaceDetailBase:{place_id}", {}).get("virtualPhone", "")

                    prices = []
                    for key, value in data.items():
                        if key.startswith(f"Menu:{place_id}"):
                            prices.append(value)

                    facilities = []
                    for key, value in data.items():
                        if key.startswith("InformationFacilities:"):
                            facilities.append(value)


                    root_query = data.get("ROOT_QUERY", {})
                    place_detail_key = f'placeDetail({{"input":{{"checkRedirect":true,"deviceType":"pc","id":"{place_id}","isNx":false}}}})'

                    information = root_query.get(place_detail_key, {}).get('description({"source":["shopWindow","jto"]})', "")

                    business_hours = root_query.get(place_detail_key, {}).get('businessHours({"source":["tpirates","jto","shopWindow"]})', [])

                    new_business_hours = root_query.get(place_detail_key, {}).get('newBusinessHours', [])

                    url = f"https://m.place.naver.com/place/{place_id}/home"
                    map_url = f"https://map.naver.com/p/entry/place/{place_id}"

                    result = {
                        "ì•„ì´ë””": place_id,
                        "ì´ë¦„": name,
                        "ì£¼ì†Œ": address,
                        "ê°€ìƒë²ˆí˜¸": virtualPhone,
                        "ê¸ˆì•¡": prices,
                        "í¸ì˜": facilities,
                        "ì˜ì—…ì‹œê°„": business_hours,
                        "ìƒˆë¡œìš´ ì˜ì—…ì‹œê°„": new_business_hours,
                        "ì •ë³´": information,
                        "URL": url,
                        "ì§€ë„": map_url
                    }

                    return result

    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch data for Place ID: {place_id}. Error: {e}")
    except Exception as e:
        print(f"Error processing data for Place ID: {place_id}: {e}")
    return None


def fetch_photos(place_id):
    url = "https://api.place.naver.com/graphql"
    headers = {
        'Content-Type': 'application/json',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate, br, zstd',
        'Accept-Language': 'ko-KR,ko;q=0.9',
        'Origin': 'https://m.place.naver.com',
        'Referer': f'https://m.place.naver.com/place/{place_id}/home'
    }
    payload = [
        {
            "operationName": "getPhotoViewerItems",
            "variables": {
                "input": {
                    "businessId": place_id,
                    "businessType": "restaurant",
                    "cursors": [
                        {"id": "biz"},
                        {"id": "cp0"},
                        {"id": "visitorReview"},
                        {"id": "clip"},
                        {"id": "imgSas"}
                    ],
                    "excludeAuthorIds": [],
                    "excludeSection": [],
                    "excludeClipIds": [],
                    "dateRange": ""
                }
            },
            "query": """
            query getPhotoViewerItems($input: PhotoViewerInput) {
              photoViewer(input: $input) {
                cursors {
                  id
                  startIndex
                  hasNext
                  lastCursor
                  __typename
                }
                photos {
                  viewId
                  originalUrl
                  width
                  height
                  title
                  text
                  desc
                  link
                  date
                  photoType
                  mediaType
                  option {
                    channelName
                    dateString
                    playCount
                    likeCount
                    __typename
                  }
                  to
                  relation
                  logId
                  author {
                    id
                    nickname
                    from
                    imageUrl
                    objectId
                    url
                    borderImageUrl
                    __typename
                  }
                  votedKeywords {
                    code
                    iconUrl
                    iconCode
                    displayName
                    __typename
                  }
                  visitCount
                  originType
                  isFollowing
                  businessName
                  rating
                  externalLink {
                    title
                    url
                    __typename
                  }
                  sourceTitle
                  moment {
                    channelId
                    contentId
                    momentId
                    gdid
                    blogRelation
                    statAllowYn
                    category
                    docNo
                    __typename
                  }
                  video {
                    videoId
                    videoUrl
                    trailerUrl
                    __typename
                  }
                  music {
                    artists
                    title
                    __typename
                  }
                  clip {
                    viewerHash
                    __typename
                  }
                  __typename
                }
                __typename
              }
            }
            """
        }
    ]
    image_urls = []
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        data = response.json()

        # ì›í•˜ëŠ” ë°ì´í„° ì¶”ì¶œ ì˜ˆì‹œ (originalUrlë§Œ ì¶”ì¶œ)
        photos = data[0].get('data', {}).get('photoViewer', {}).get('photos', [])
        for photo in photos:
            image_urls.append(photo.get('originalUrl'))

        return image_urls[:5]

    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
        return image_urls


def extract_information(information):
    try:
        return f"â„¹ï¸ {information}".strip() if information else ""
    except Exception:
        return ""


def format_address(address):
    try:
        return f"ğŸ“ {address}".strip() if address else ""
    except Exception:
        return ""


def format_phone_number(virtual_number, name=''):
    try:
        if virtual_number:
            formatted_phone = (f"ğŸ“ ì „í™”ë²ˆí˜¸\n"
                               f"{virtual_number}\n"
                               f"â€˜{name}â€™(ìœ¼)ë¡œ ì—°ê²°ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ì½œ ë²ˆí˜¸ì…ë‹ˆë‹¤.\n"
                               f"ì—…ì²´ ì „í™”ë²ˆí˜¸ {virtual_number}".strip())
            return formatted_phone
        return ""
    except Exception:
        return ""


def format_price(prices):
    formatted_prices = []
    try:
        for price_info in prices:
            name = price_info.get('name', '')
            price = price_info.get('price', '')
            if name and price:
                try:
                    formatted_price = f"{int(price):,}ì›"
                    formatted_prices.append(f"- {name} {formatted_price}")
                except ValueError:
                    continue
    except Exception:
        return ""
    return "ğŸ’µ ê¸ˆì•¡\n" + '\n'.join(formatted_prices).strip() if formatted_prices else ""


def format_facilities(facilities):
    try:
        facility_names = [facility.get('name', '') for facility in facilities]
        return "ğŸ·ï¸ í¸ì˜\n" + ', '.join(facility_names).strip() if facility_names else ""
    except Exception:
        return ""


def format_business_hours(business_hours):
    formatted_hours = []
    try:
        for hour in business_hours:
            day = hour.get('day', '')
            start_time = hour.get('startTime', '')
            end_time = hour.get('endTime', '')
            if day and start_time and end_time:
                formatted_hours.append(f"{day} {start_time} - {end_time}")
    except Exception:
        return ""
    return "â° ì˜ì—…ì‹œê°„\n" + '\n'.join(formatted_hours).strip() if formatted_hours else ""


def format_new_business_hours(new_business_hours):
    formatted_hours = []
    try:
        if new_business_hours:
            for item in new_business_hours:
                status_description = item.get('businessStatusDescription', {})
                status = status_description.get('status', '')
                description = status_description.get('description', '')

                if status:
                    formatted_hours.append(status)
                if description:
                    formatted_hours.append(description)

                for info in item.get('businessHours', []):
                    day = info.get('day', '')
                    business_hours = info.get('businessHours', {})
                    start_time = business_hours.get('start', '')
                    end_time = business_hours.get('end', '')

                    break_hours = info.get('breakHours', [])
                    break_times = [f"{bh.get('start', '')} - {bh.get('end', '')}" for bh in break_hours]
                    break_times_str = ', '.join(break_times) + ' ë¸Œë ˆì´í¬íƒ€ì„' if break_times else ''

                    if day:
                        formatted_hours.append(day)
                    if start_time and end_time:
                        formatted_hours.append(f"{start_time} - {end_time}")
                    if break_times_str:
                        formatted_hours.append(break_times_str)
    except Exception:
        return ""
    return "â° ì˜ì—…ì‹œê°„\n" + '\n'.join(formatted_hours).strip() if formatted_hours else ""


def format_review_analysis(review_analysis):
    formatted_items = []
    try:
        top_items = review_analysis[:7]
        for item in top_items:
            count = item.get('count', 0)
            display_name = item.get('displayName', '')
            if count and display_name:
                if count == 1:
                    formatted_items.append(f"- 1ëª…ì˜ ë°©ë¬¸ìê°€ \"{display_name}\"ë¼ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.")
                else:
                    formatted_items.append(f"- {count}ëª…ì˜ ë°©ë¬¸ìë¶„ë“¤ì´ \"{display_name}\"ë¼ê³  ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.")
    except Exception:
        return ""
    return "â­ ë°©ë¬¸ì í›„ê¸°\n" + '\n'.join(formatted_items).strip() if formatted_items else ""


def print_place_info(place_info):
    try:
        # ê° í•­ëª©ì„ í¬ë§·
        formatted_address = format_address(place_info.get("ì£¼ì†Œ", ""))
        formatted_phone = format_phone_number(place_info.get("ê°€ìƒë²ˆí˜¸", ""), place_info.get("ì´ë¦„", ""))
        formatted_price = format_price(place_info.get("ê¸ˆì•¡", []))
        formatted_facilities = format_facilities(place_info.get("í¸ì˜", []))
        # formatted_business_hours = format_business_hours(place_info.get("ì˜ì—…ì‹œê°„", []))
        formatted_new_business_hours = format_new_business_hours(place_info.get("ìƒˆë¡œìš´ ì˜ì—…ì‹œê°„", []))
        formatted_information = extract_information(place_info.get("ì •ë³´", []))
        formatted_reviews = format_review_analysis(place_info.get("ë¦¬ë·° ë¶„ì„", []))
        map_url = place_info.get("ì§€ë„", "")

        # ìœ íš¨í•œ í•­ëª©ë§Œì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        sections = [
            formatted_address,
            formatted_new_business_hours,
            # formatted_business_hours,
            formatted_phone,
            formatted_price,
            formatted_facilities,
            formatted_information,
            formatted_reviews,
            f"ğŸ—ºï¸ ì§€ë„\n{formatted_address}" if formatted_address else ""
        ]

        # ìœ íš¨í•œ í•­ëª©ì„ í•©ì¹˜ê³ , ê° í•­ëª© ì‚¬ì´ì— 3ê°œì˜ ì—”í„°ë¥¼ ì¶”ê°€
        content = "\n\n\n\n".join(section for section in sections if section)

        return content.strip()  # ì•ë’¤ ê³µë°± ì œê±°
    except Exception:
        return ""


def new_print(text, level="INFO"):
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    formatted_text = f"[{timestamp}] [{level}] {text}"
    print(formatted_text)
    log_text_widget.insert(tk.END, f"{formatted_text}\n")
    log_text_widget.see(tk.END)


def main(query, total_queries, current_query_index):
    try:
        page = 1
        results = []
        all_ids = set()
        all_ids_list = []
        total_count = 0

        new_print(f"í¬ë¡¤ë§ ì‹œì‘")
        while True:
            if stop_event.is_set():
                return

            result = fetch_search_results(query, page)
            if not result:
                break

            place_list = result.get("result", {}).get("place", {}).get("list", [])
            ids_this_page = [place.get("id") for place in place_list if place.get("id")]

            new_print(f"í˜ì´ì§€ : {page}, ëª©ë¡ : {ids_this_page}")

            if not ids_this_page:
                break

            all_ids.update(ids_this_page)
            page += 1
            time.sleep(random.uniform(1, 2))

        if not stop_event.is_set():
            all_ids_list = list(all_ids)
            total_count = len(all_ids_list)
            new_print(f"ì „ì²´ ë§¤ë¬¼ ìˆ˜ : {total_count}")

            progress['maximum'] = total_count
            progress['value'] = 0
            set_progress(query, total_queries, current_query_index)

        for idx, place_id in enumerate(all_ids_list, start=1):
            if stop_event.is_set():
                return

            place_info = fetch_place_info(place_id)
            if place_info:
                reviews_info = fetch_reviews(place_id)
                place_info["ë¦¬ë·°"] = reviews_info.get("reviews", [])
                place_info["ë¦¬ë·° ë¶„ì„"] = reviews_info.get("stats", [])

                name = place_info["ì´ë¦„"]
                image_urls = fetch_photos(place_id)
                os.makedirs(f'images/{query}/{idx}. {name}', exist_ok=True)
                for i, image_url in enumerate(image_urls, start=1):
                    download_image(image_url, f'images/{query}/{idx}. {name}/{name}_{i}.jpg')
                place_info['ì´ë¯¸ì§€ URLs'] = image_urls
                results.append(place_info)

                new_print(f"ë²ˆí˜¸ : {idx}, ì´ë¦„ : {place_info['ì´ë¦„']}")
                time.sleep(random.uniform(1, 2))

                if not stop_event.is_set():
                    progress['value'] += 1
                    set_progress(query, total_queries, current_query_index)

        if not stop_event.is_set():
            progress['maximum'] = total_count
            progress['value'] = total_count
            set_progress(query, total_queries, current_query_index)
            query_no_spaces = query.replace(" ", "")
            save_to_excel(results, query_no_spaces)

    except Exception as e:
        print(f"Unexpected error: {e}")


def set_progress(query, total_queries, current_query_index):
    # ê°œë³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    progress_label.config(text=f"[{query}] ì§„í–‰ë¥ : {progress['value'] / progress['maximum'] * 100:.2f}% ({progress['value']}/{progress['maximum']})")
    remaining_time = (progress['maximum'] - progress['value']) * time_val
    eta = str(timedelta(seconds=remaining_time)).split(".")[0]  # ì†Œìˆ˜ì  ì œê±°
    eta_label.config(text=f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: {eta}")
    progress.update_idletasks()

    # ì „ì²´ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    overall_progress_percentage = ((current_query_index + progress['value'] / progress['maximum']) / total_queries) * 100
    overall_progress_label.config(text=f"ì „ì²´ ì§„í–‰ë¥ : {overall_progress_percentage:.2f}%")
    overall_progress['value'] = overall_progress_percentage
    overall_progress.update_idletasks()


def save_to_excel(results, query_no_spaces, mode='w'):
    new_print(f"ì—‘ì…€ ì €ì¥ ì‹œì‘...")
    blogs = []
    for result in results:
        blog = {}
        blog["ì•„ì´ë””"] = result["ì•„ì´ë””"]
        blog["ì´ë¦„"] = result["ì´ë¦„"]
        blog["ë¸”ë¡œê·¸ ì œëª©"] = f"{query_no_spaces} / {result['ì´ë¦„']} / ìš´ì˜ì‹œê°„ ê°€ê²© ì£¼ì°¨ë¦¬ë·°"
        blog["ë¸”ë¡œê·¸ ê²Œì‹œê¸€"] = print_place_info(result)
        # ì´ë¯¸ì§€ ë§í¬ì™€ ë¸”ë¡œê·¸ ê²Œì‹œê¸€ ìƒì„±
        image_urls = result.get("ì´ë¯¸ì§€ URLs", [])
        image_links = "\n".join(image_urls[:5])
        blog["ì£¼ì†Œ"] = result["ì£¼ì†Œ"]
        blog["ì´ë¯¸ì§€"] = image_links
        blog["ì •ë³´ URL"] = result["URL"]
        blog["ì§€ë„ URL"] = result["ì§€ë„"]
        print(blog["ë¸”ë¡œê·¸ ê²Œì‹œê¸€"])
        blogs.append(blog)

    # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ êµ¬í•˜ê¸°
    now = datetime.datetime.now()
    timestamp = now.strftime("%Y%m%d%H%M")

    # íŒŒì¼ ì´ë¦„ì— í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ ì¶”ê°€, íŒŒì¼ ì´ë¦„ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    file_name = sanitize_filename(f'{query_no_spaces}_{timestamp}.xlsx')
    try:
        if mode == 'a':
            existing_df = pd.read_excel(file_name)
            new_df = pd.DataFrame(blogs)
            df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            df = pd.DataFrame(blogs)
        df.to_excel(file_name, index=False)
    except FileNotFoundError:
        df = pd.DataFrame(blogs)
        df.to_excel(file_name, index=False)

    new_print(f"ì—‘ì…€ ì €ì¥ {file_name}")
    # ë©”ì‹œì§€ë°•ìŠ¤ í‘œì‹œ


def sanitize_filename(name):
    # íŒŒì¼ ì´ë¦„ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.
    return re.sub(r'[\\/*?:"<>|]', "", name)


def start_app():
    global root, search_entry, search_button, log_text_widget, progress, progress_label, eta_label, overall_progress_label, overall_progress

    root = tk.Tk()
    root.title("ë„¤ì´ë²„ ë¸”ë¡œê·¸ í”„ë¡œê·¸ë¨")
    root.geometry("700x750")  # í¬ê¸° ì¡°ì •

    font_large = ('Helvetica', 10)  # í°íŠ¸ í¬ê¸°

    # ì˜µì…˜ í”„ë ˆì„
    option_frame = tk.Frame(root)
    option_frame.pack(fill=tk.X, padx=10, pady=10)

    # ê²€ìƒ‰ì–´ ì…ë ¥ í”„ë ˆì„
    search_frame = tk.Frame(root)
    search_frame.pack(pady=20)

    # ê²€ìƒ‰ì–´ ë ˆì´ë¸”
    search_label = tk.Label(search_frame, text="ê²€ìƒ‰ì–´:", font=font_large)
    search_label.grid(row=0, column=0, padx=5, pady=5, sticky='w')

    # ê²€ìƒ‰ì–´ ì…ë ¥ í•„ë“œ
    search_entry = tk.Entry(search_frame, font=font_large, width=25)
    search_entry.grid(row=0, column=1, padx=5, pady=5, sticky='ew')

    # ê²€ìƒ‰ ë²„íŠ¼
    search_button = tk.Button(search_frame, text="ê²€ìƒ‰", font=font_large, bg="lightgreen", command=on_search)
    search_button.grid(row=0, column=2, padx=5, pady=5)

    # ì•ˆë‚´ ë¬¸êµ¬
    guide_label = tk.Label(search_frame, text="* ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš” *", font=font_large, fg="red")
    guide_label.grid(row=1, column=0, columnspan=3, padx=5, pady=5)

    # ê²€ìƒ‰ í”„ë ˆì„ì˜ ì—´ ë¹„ìœ¨ ì„¤ì •
    search_frame.columnconfigure(1, weight=1)

    # ë¡œê·¸ í™”ë©´
    log_label = tk.Label(root, text="ë¡œê·¸ í™”ë©´", font=font_large)
    log_label.pack(fill=tk.X, padx=10)

    log_frame = tk.Frame(root)
    log_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

    x_scrollbar = tk.Scrollbar(log_frame, orient=tk.HORIZONTAL)
    x_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)

    y_scrollbar = tk.Scrollbar(log_frame, orient=tk.VERTICAL)
    y_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

    log_text_widget = tk.Text(log_frame, wrap=tk.NONE, height=10, font=font_large, xscrollcommand=x_scrollbar.set, yscrollcommand=y_scrollbar.set)
    log_text_widget.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

    x_scrollbar.config(command=log_text_widget.xview)
    y_scrollbar.config(command=log_text_widget.yview)

    # ì§„í–‰ë¥ 
    progress_frame = tk.Frame(root)
    progress_frame.pack(fill=tk.X, padx=10, pady=10)

    # ê°œë³„ ì§„í–‰ë¥  í‘œì‹œ
    progress_label = tk.Label(progress_frame, text="ì§„í–‰ë¥ : 0%", font=font_large)
    progress_label.pack(side=tk.TOP, padx=5)

    # ì˜ˆìƒ ì†Œìš” ì‹œê°„
    eta_label = tk.Label(progress_frame, text="ì˜ˆìƒ ì†Œìš” ì‹œê°„: 00:00:00", font=font_large)
    eta_label.pack(side=tk.TOP, padx=5)


    # ê°œë³„ ì§„í–‰ë¥  ê²Œì´ì§€ ë°” (ì „ì²´ ì§„í–‰ë¥  ì•„ë˜ë¡œ ì´ë™)
    progress = ttk.Progressbar(progress_frame, orient="horizontal", mode="determinate", style="TProgressbar")
    progress.pack(fill=tk.X, padx=10, pady=(0, 10), expand=True)

    # ì „ì²´ ì§„í–‰ë¥  í‘œì‹œ (ìœ„ë¡œ ì´ë™)
    overall_progress_label = tk.Label(progress_frame, text="ì „ì²´ ì§„í–‰ë¥ : 0%", font=font_large)
    overall_progress_label.pack(side=tk.TOP, padx=5)

    # ì „ì²´ ì§„í–‰ë¥  ê²Œì´ì§€ ë°”
    overall_progress = ttk.Progressbar(progress_frame, orient="horizontal", mode="determinate", style="TProgressbar")
    overall_progress.pack(fill=tk.X, padx=10, pady=(0, 10), expand=True)

    root.mainloop()


def run_main(querys):
    try:
        query_list = [q.strip() for q in querys.split(",")]
        total_queries = len(query_list)
        for idx, query in enumerate(query_list):
            if stop_event.is_set():
                break
            new_print(f"ê²€ìƒ‰ì–´: {query} í¬ë¡¤ë§ ì‹œì‘", "INFO")
            progress_label.config(text=f"[{query}] ì§„í–‰ë¥ : 0%")
            main(query, total_queries, idx)

        if not stop_event.is_set():
            messagebox.showwarning("ê²½ê³ ", "í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            search_button.config(bg="lightgreen", fg="black", text="ê²€ìƒ‰")

    except Exception as e:
        new_print(f"Unexpected error in thread: {e}", "ERROR")


def on_search():
    global search_thread, stop_event
    query = search_entry.get().strip()
    if query:
        if search_thread and search_thread.is_alive():
            # ì¤‘ì§€ ë²„íŠ¼ì´ í´ë¦­ë˜ë©´ ì‘ì—… ì¤‘ì§€
            new_print("í¬ë¡¤ë§ ì¤‘ì§€")
            stop_event.set()  # ì´ë²¤íŠ¸ ì„¤ì •
            search_button.config(bg="lightgreen", fg="black", text="ê²€ìƒ‰")

            # ì§„í–‰ë¥  ê²Œì´ì§€ë°” ì´ˆê¸°í™”
            progress['value'] = 0
            overall_progress['value'] = 0
            progress_label.config(text="ì§„í–‰ë¥ : 0%")
            overall_progress_label.config(text="ì „ì²´ ì§„í–‰ë¥ : 0%")
            eta_label.config(text="ì˜ˆìƒ ì†Œìš” ì‹œê°„: 00:00:00")
            messagebox.showwarning("ê²½ê³ ", "í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            # ì‹œì‘ ë²„íŠ¼ í´ë¦­ ì‹œ ëª¨ë“  ì§„í–‰ë¥  ì´ˆê¸°í™”
            stop_event.clear()  # ì´ë²¤íŠ¸ ì´ˆê¸°í™”
            log_text_widget.delete('1.0', tk.END)  # ë¡œê·¸ ì´ˆê¸°í™”
            progress['value'] = 0  # ê°œë³„ ì§„í–‰ë¥  ì´ˆê¸°í™”
            overall_progress['value'] = 0  # ì „ì²´ ì§„í–‰ë¥  ì´ˆê¸°í™”
            progress_label.config(text="ì§„í–‰ë¥ : 0%")
            overall_progress_label.config(text="ì „ì²´ ì§„í–‰ë¥ : 0%")
            eta_label.config(text="ì˜ˆìƒ ì†Œìš” ì‹œê°„: 00:00:00")
            search_button.config(bg="red", fg="white", text="ì¤‘ì§€")
            search_thread = threading.Thread(target=run_main, args=(query,))
            search_thread.start()
    else:
        messagebox.showwarning("ê²½ê³ ", "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ì—¬ê¸°ì— main í•¨ìˆ˜ì™€ ê¸°íƒ€ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ í¬í•¨ì‹œí‚¤ì„¸ìš”.

if __name__ == "__main__":
    start_app()
