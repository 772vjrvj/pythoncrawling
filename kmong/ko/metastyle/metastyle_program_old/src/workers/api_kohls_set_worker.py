import os
import re
import ssl
import time
from datetime import datetime
import json

import pandas as pd
import psutil
import requests
from PyQt5.QtCore import QThread, pyqtSignal
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.common.exceptions import WebDriverException
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

from src.utils.time_utils import get_current_yyyymmddhhmmss, get_current_formatted_datetime

ssl._create_default_https_context = ssl._create_unverified_context

image_folder = 'images'
image_main_directory = 'oldnavy_images'
company_name = 'kohls'
site_name = 'KOHLS'
excel_filename = ''
baseUrl = "https://www.kohls.com/"
db_folder = 'DB'
file_path = os.path.join(db_folder, site_name)

# API
class ApiKohlsSetLoadWorker(QThread):
    log_signal = pyqtSignal(str)         # Î°úÍ∑∏ Î©îÏãúÏßÄÎ•º Ï†ÑÎã¨ÌïòÎäî ÏãúÍ∑∏ÎÑê
    progress_signal = pyqtSignal(float, float)  # ÏßÑÌñâÎ•† ÏóÖÎç∞Ïù¥Ìä∏Î•º Ï†ÑÎã¨ÌïòÎäî ÏãúÍ∑∏ÎÑê
    progress_end_signal = pyqtSignal()   # Ï¢ÖÎ£å ÏãúÍ∑∏ÎÑê


    # Ï¥àÍ∏∞Ìôî
    def __init__(self, checked_list):
        super().__init__()
        self.baseUrl = baseUrl
        self.sess = requests.Session()
        self.checked_list = checked_list

        self.running = True  # Ïã§Ìñâ ÏÉÅÌÉú ÌîåÎûòÍ∑∏ Ï∂îÍ∞Ä
        self.driver = None

        self.checked_model_list = []
        self.main_model = None
        self.product_info_list = []
        self.csv_product_list = []
        self.product_list = []
        self.total_cnt = 0
        self.total_pages = 0
        self.current_page = 0
        self.current_cnt = 0
        self.before_pro_value = 0

        self.columns = [
            'category_name', 'category_url',
            'product_id', 'product_name', 'product_url', 'product_title',
            'product_sub_title', 'product_features', 'product_fabric_care',
            'product_img_1', 'product_img_2', 'product_img_3', 'product_img_4',
            'data_success', 'img_success', 'img_path', 'success', 'error', 'reg_date',
        ]

    # ÌîÑÎ°úÍ∑∏Îû® Ïã§Ìñâ
    def run(self):
        global image_main_directory, company_name, site_name, excel_filename, baseUrl, file_path

        self.log_signal.emit("ÌÅ¨Î°§ÎßÅ ÏãúÏûë")

        if self.checked_list:
            self.log_signal.emit("ÌÅ¨Î°§ÎßÅ ÏÇ¨Ïù¥Ìä∏ ÎìúÎùºÏù¥Î≤Ñ ÏÑ∏ÌåÖÏ§ëÏûÖÎãàÎã§. Ïû†ÏãúÎßå Í∏∞Îã§Î†§Ï£ºÏÑ∏Ïöî.")
            self._set_driver()
            self.log_signal.emit("ÌÅ¨Î°§ÎßÅ ÏÇ¨Ïù¥Ìä∏ ÎìúÎùºÏù¥Î≤Ñ ÏÑ∏ÌåÖÏóê ÏÑ±Í≥µÌñàÏäµÎãàÎã§.")

            self.log_signal.emit(f"Ï†ÑÏ≤¥ ÏÉÅÌíàÏàò Í≥ÑÏÇ∞ÏùÑ ÏãúÏûëÌï©ÎãàÎã§. Ïû†ÏãúÎßå Í∏∞Îã§Î†§Ï£ºÏÑ∏Ïöî.")
            self.total_cnt_cal()
            self.total_cnt = sum(int(obj['total_product_cnt']) for obj in self.checked_list)
            self.total_pages = sum(int(obj['total_page_cnt']) for obj in self.checked_list)

            self.log_signal.emit(f"Ï†ÑÏ≤¥ Ìï≠Î™©Ïàò {len(self.checked_list)}Í∞ú")
            self.log_signal.emit(f"Ï†ÑÏ≤¥ ÏÉÅÌíàÏàò {self.total_cnt} Í∞ú")
            self.log_signal.emit(f"Ï†ÑÏ≤¥ ÌéòÏù¥ÏßÄÏàò {self.total_pages} Í∞ú")

            for index, checked_model in enumerate(self.checked_list, start=1):
                if not self.running:  # Ïã§Ìñâ ÏÉÅÌÉú ÌôïÏù∏
                    self.log_signal.emit("ÌÅ¨Î°§ÎßÅÏù¥ Ï§ëÏßÄÎêòÏóàÏäµÎãàÎã§.")
                    break

                file_path = checked_model['file_path']
                self.csv_product_list = self.load_products(file_path)

                self.current_cnt = (int(checked_model['start_page']) - 1) * 48
                self.current_page = int(checked_model['start_page'])
                base_url = checked_model['url']

                for indx, page in enumerate(range(int(checked_model['start_page']) - 1, int(checked_model['end_page'])), start=1):
                    if not self.running:
                        break

                    time.sleep(0.5)
                    self.log_signal.emit(f'{checked_model["name"]}({index}/{len(self.checked_list)})  TotalPage({self.current_page}/{self.total_pages})')
                    
                    ws_value = page * 48
                    page_url = f"{base_url}&WS={ws_value}"
                    rs = self.get_products_from_page(page_url, checked_model)
                    if not rs:
                        break
                    self.current_page = self.current_page + 1

        self.progress_signal.emit(self.before_pro_value, 1000000)
        self.log_signal.emit("=============== ÌÅ¨Î°§ÎßÅ Ï¢ÖÎ£åÏ§ë...")
        time.sleep(5)
        self.log_signal.emit("=============== ÌÅ¨Î°§ÎßÅ Ï¢ÖÎ£å")
        self.progress_end_signal.emit()


    # Ïù¥ÎØ∏ÏßÄ Îã§Ïö¥Î°úÎìú Ìï®Ïàò
    def download_images(self, product):
        if product['img_success'] == 'N':
            product_id = product['product_id']
            category_path = os.path.join(image_folder, site_name, product['category_name'].replace("‚Äô", "").replace(" / ", "_").strip())
            os.makedirs(category_path, exist_ok=True)

            img_urls = [product['product_img_1'], product['product_img_2'], product['product_img_3'], product['product_img_4']]
            img_paths = []

            for idx, img_url in enumerate(img_urls, start=1):
                if img_url:
                    img_filename = f"{product_id}_{idx}.jpg"
                    img_filepath = os.path.join(category_path, img_filename)

                    try:
                        response = requests.get(img_url, stream=True)
                        if response.status_code == 200:
                            with open(img_filepath, 'wb') as f:
                                for chunk in response.iter_content(1024):
                                    f.write(chunk)
                            img_paths.append(img_filepath)
                        else:
                            self.log_signal.emit(f"Ïù¥ÎØ∏ÏßÄ Îã§Ïö¥Î°úÎìú Ïã§Ìå®: {img_url}")
                    except Exception as e:
                        self.log_signal.emit(f"Ïù¥ÎØ∏ÏßÄ Îã§Ïö¥Î°úÎìú Ïò§Î•ò: {e}")

            product['img_path'] = img_paths
            if len(img_paths) >= 1:
                product['img_success'] = 'Y'

        return product


    # CSVÏóê ÏÉàÎ°úÏö¥ Ìñâ Ï∂îÍ∞ÄÌïòÎäî Ìï®Ïàò
    def append_to_csv(self, new_rows):
        # CSV ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎ©¥ Î°úÎìú, Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏúºÎ©¥ Îπà DataFrame ÏÉùÏÑ±
        if os.path.exists(file_path):
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        else:
            df = pd.DataFrame(columns=self.columns)

        # new_rowsÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò
        new_df = pd.DataFrame(new_rows)  # Í∞ùÏ≤¥ Î∞∞Ïó¥ÏùÑ DataFrameÏúºÎ°ú Î≥ÄÌôò

        for _, row in new_df.iterrows():  # Í∞Å ÌñâÏùÑ ÏàúÌöåÌïòÎ©∞ ÏóÖÎç∞Ïù¥Ìä∏ ÎòêÎäî Ï∂îÍ∞Ä
            product_id = row["product_id"]

            if product_id in df["product_id"].values:
                # product_idÍ∞Ä Ï°¥Ïû¨ÌïòÎ©¥ Ìï¥Îãπ Ìñâ ÏóÖÎç∞Ïù¥Ìä∏
                df.loc[df["product_id"] == product_id, :] = row
            else:
                # Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏúºÎ©¥ ÏÉàÎ°úÏö¥ Ìñâ Ï∂îÍ∞Ä
                df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)

        # ÏµúÏ¢Ö Í≤∞Í≥ºÎ•º CSV ÌååÏùºÏóê Ï†ÄÏû• (ÎçÆÏñ¥Ïì∞Í∏∞)
        df.to_csv(file_path, index=False, encoding="utf-8-sig")


    # ÌîÑÎ°úÍ∑∏Îû® Ï§ëÎã®
    def stop(self):
        """Ïä§Î†àÎìú Ï§ëÏßÄÎ•º ÏöîÏ≤≠ÌïòÎäî Î©îÏÑúÎìú"""
        self.running = False

    # ÌÅ¨Î°¨ ÎÅÑÍ∏∞
    def _close_chrome_processes(self):
        """Î™®Îì† Chrome ÌîÑÎ°úÏÑ∏Ïä§Î•º Ï¢ÖÎ£åÌï©ÎãàÎã§."""
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                if 'chrome' in proc.info['name'].lower():
                    proc.kill()  # Chrome ÌîÑÎ°úÏÑ∏Ïä§Î•º Ï¢ÖÎ£å
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass

    # ÏÖÄÎ†àÎãàÏõÄ ÎìúÎùºÏù¥Î≤Ñ ÏÑ∏ÌåÖ
    def _set_driver(self):
        try:
            self._close_chrome_processes()

            chrome_options = Options()
            user_data_dir = f"C:\\Users\\{os.getlogin()}\\AppData\\Local\\Google\\Chrome\\User Data"
            profile = "Default"

            chrome_options.add_argument(f"user-data-dir={user_data_dir}")
            chrome_options.add_argument(f"profile-directory={profile}")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-software-rasterizer")
            chrome_options.add_argument("--start-maximized")
            # chrome_options.add_argument("--headless")  # Headless Î™®Îìú Ï∂îÍ∞Ä

            user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            chrome_options.add_argument(f'user-agent={user_agent}')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)

            download_dir = os.path.abspath("downloads")
            os.makedirs(download_dir, exist_ok=True)

            chrome_options.add_experimental_option('prefs', {
                "download.default_directory": download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True
            })

            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

            script = '''
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                window.navigator.chrome = { runtime: {} };
                Object.defineProperty(navigator, 'languages', { get: () => ['en-US', 'en'] });
                Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });
                Object.defineProperty(navigator, 'userAgent', { get: () => 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36' });
            '''
            driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {'source': script})

            self.driver = driver
        except WebDriverException as e:
            print(f"Error setting up the WebDriver: {e}")
            self.driver = None

    # ÏÖÄÎ†àÎãàÏõÄ ÎìúÎùºÏù¥Î≤Ñ ÏÑ∏ÌåÖ
    def set_driver(self):
        webdriver_options = webdriver.ChromeOptions()

        # Ïù¥ ÏòµÏÖòÏùÄ ChromeÏù¥ ÏûêÎèôÌôî ÎèÑÍµ¨(Ïòà: Selenium)Ïóê ÏùòÌï¥ Ï†úÏñ¥ÎêòÍ≥† ÏûàÎã§Îäî Í≤ÉÏùÑ Í∞êÏßÄÌïòÏßÄ ÏïäÎèÑÎ°ù ÎßåÎì≠ÎãàÎã§.
        # AutomationControlled Í∏∞Îä•ÏùÑ ÎπÑÌôúÏÑ±ÌôîÌïòÏó¨ webdriverÍ∞Ä Î∏åÎùºÏö∞Ï†ÄÎ•º ÏûêÎèôÏúºÎ°ú Ï†úÏñ¥ÌïòÎäî Í≤ÉÏùÑ Ïà®ÍπÅÎãàÎã§.
        # Ïù¥Îäî ÏùºÎ∂Ä ÏõπÏÇ¨Ïù¥Ìä∏ÏóêÏÑú ÏûêÎèôÌôî ÎèÑÍµ¨Í∞Ä Í∞êÏßÄÎêòÎäî Í≤ÉÏùÑ Î∞©ÏßÄÌïòÎäî Îç∞ Ïú†Ïö©Ìï©ÎãàÎã§.
        ###### ÏûêÎèô Ï†úÏñ¥ Í∞êÏßÄ Î∞©ÏßÄ #####
        webdriver_options.add_argument('--disable-blink-features=AutomationControlled')

        # Chrome Î∏åÎùºÏö∞Ï†ÄÎ•º Ïã§ÌñâÌï† Îïå ÏûêÎèôÏúºÎ°ú Î∏åÎùºÏö∞Ï†ÄÎ•º ÏµúÎåÄÌôî ÏÉÅÌÉúÎ°ú ÏãúÏûëÌï©ÎãàÎã§.
        # Ïù¥ ÏòµÏÖòÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä Î∏åÎùºÏö∞Ï†ÄÎ•º Ï≤òÏùå Ïã§ÌñâÌï† Îïå ÌÅ¨Í∏∞Í∞Ä ÏûêÎèôÏúºÎ°ú ÏµúÎåÄÎ°ú ÏÑ§Ï†ïÎêòÎèÑÎ°ù Ìï©ÎãàÎã§.
        ##### ÌôîÎ©¥ ÏµúÎåÄ #####
        webdriver_options.add_argument("--start-maximized")

        # headless Î™®ÎìúÎ°ú ChromeÏùÑ Ïã§ÌñâÌï©ÎãàÎã§.
        # Ïù¥Îäî ÌôîÎ©¥ÏùÑ ÌëúÏãúÌïòÏßÄ ÏïäÍ≥† Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú Î∏åÎùºÏö∞Ï†ÄÎ•º Ïã§ÌñâÌïòÍ≤å Îê©ÎãàÎã§.
        # Î∏åÎùºÏö∞Ï†Ä UI ÏóÜÏù¥ ÏûëÏóÖÏùÑ ÏàòÌñâÌï† Îïå ÏÇ¨Ïö©ÌïòÎ©∞, ÏÑúÎ≤Ñ ÌôòÍ≤ΩÏóêÏÑú Ïú†Ïö©Ìï©ÎãàÎã§.
        ##### ÌôîÎ©¥Ïù¥ ÏïàÎ≥¥Ïù¥Í≤å Ìï® #####
        # webdriver_options.add_argument("--headless")

        #Ïù¥ ÏÑ§Ï†ïÏùÄ ChromeÏùò ÏûêÎèôÌôî Í∏∞Îä•ÏùÑ ÎπÑÌôúÏÑ±ÌôîÌïòÎäî Îç∞ ÏÇ¨Ïö©Îê©ÎãàÎã§.
        #Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ChromeÏùÄ ÏûêÎèôÌôîÍ∞Ä ÌôúÏÑ±ÌôîÎêú Í≤ΩÏö∞ Î∏åÎùºÏö∞Ï†ÄÏùò ÏΩòÏÜîÏóê Í≤ΩÍ≥† Î©îÏãúÏßÄÎ•º ÌëúÏãúÌï©ÎãàÎã§.
        #Ïù¥ ÏòµÏÖòÏùÑ ÏÑ§Ï†ïÌïòÎ©¥ Ïù¥Îü¨Ìïú Í≤ΩÍ≥† Î©îÏãúÏßÄÍ∞Ä ÎÇòÌÉÄÎÇòÏßÄ ÏïäÎèÑÎ°ù Ìï† Ïàò ÏûàÏäµÎãàÎã§.
        ##### ÏûêÎèô Í≤ΩÍ≥† Ï†úÍ±∞ #####
        webdriver_options.add_experimental_option('useAutomationExtension', False)

        # Ïù¥ ÏòµÏÖòÏùÄ Î∏åÎùºÏö∞Ï†ÄÏùò Î°úÍπÖÏùÑ ÎπÑÌôúÏÑ±ÌôîÌï©ÎãàÎã§.
        # enable-loggingÏùÑ Ï†úÏô∏ÏãúÌÇ§Î©¥, ChromeÏùò Î°úÍπÖ Í∏∞Îä•Ïù¥ ÌôúÏÑ±ÌôîÎêòÏßÄ ÏïäÏïÑ Î∂àÌïÑÏöîÌïú Î°úÍ∑∏ Î©îÏãúÏßÄÍ∞Ä Ï∂úÎ†•ÎêòÏßÄ ÏïäÎèÑÎ°ù Ìï† Ïàò ÏûàÏäµÎãàÎã§.
        ##### Î°úÍπÖ ÎπÑÌôúÏÑ±Ìôî #####
        webdriver_options.add_experimental_option('excludeSwitches', ['enable-logging'])

        # Ïù¥ ÏòµÏÖòÏùÄ enable-automation Ïä§ÏúÑÏπòÎ•º Ï†úÏô∏ÏãúÌÇµÎãàÎã§.
        # enable-automation Ïä§ÏúÑÏπòÍ∞Ä ÌôúÏÑ±ÌôîÎêòÎ©¥,
        # ÏûêÎèôÌôî ÎèÑÍµ¨Î•º ÏÇ¨Ïö© Ï§ëÏûÑÏùÑ ÏïåÎ¶¨Îäî Î©îÏãúÏßÄÍ∞Ä Î∏åÎùºÏö∞Ï†ÄÏóê ÌëúÏãúÎê©ÎãàÎã§.
        # Ïù¥Î•º Ï†úÏô∏ÌïòÎ©¥ ÏûêÎèôÌôî ÎèÑÍµ¨Ïùò ÏÇ¨Ïö©Ïù¥ Í∞êÏßÄÎêòÏßÄ ÏïäÏäµÎãàÎã§.
        ##### ÏûêÎèôÌôî ÎèÑÍµ¨ ÏÇ¨Ïö© Í∞êÏßÄ Ï†úÍ±∞ #####
        webdriver_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.driver = webdriver.Chrome(options=webdriver_options)
        self.driver.get(self.baseUrl)

    # Ï†ÑÏ≤¥ Í∞ØÏàò Í∞ÄÏ†∏Ïò§Í∏∞
    def get_total_count(self, url):
        self.driver.get(url)
        time.sleep(3)
        count_element = self.driver.find_element(By.CSS_SELECTOR, "span.result_count")
        total_cnt = int(re.sub(r'[^0-9]', '', count_element.text)) if count_element else 0
        return total_cnt

    # Ï†ÑÏ≤¥ Í∞ØÏàò Ï°∞Ìöå
    def total_cnt_cal(self):
        check_obj_list = []
        for index, checked_obj in enumerate(self.checked_list, start=1):
            name = checked_obj['name']

            checked_obj['file_path'] = f'{file_path}_{name.replace("‚Äô", "").replace(" / ", "_").strip()}.csv'

            url = self.get_url(name)

            total_cnt = self.get_total_count(url)
            total_pages = (total_cnt // 48) + (1 if total_cnt % 48 > 0 else 0)

            checked_obj['url'] = url
            checked_obj['total_page_cnt'] = total_pages
            checked_obj['total_product_cnt'] = total_cnt
            check_obj_list.append(checked_obj)
            time.sleep(0.5)

        self.log_signal.emit(f"check_obj_list : {check_obj_list}")


    def get_product_details(self, product_url):
        self.driver.get(product_url)

        # ÌéòÏù¥ÏßÄ Î°úÎî© ÎåÄÍ∏∞
        time.sleep(3)

        # ÌòÑÏû¨ ÌéòÏù¥ÏßÄÏùò HTMLÏùÑ Í∞ÄÏ†∏ÏôÄÏÑú BeautifulSoupÏúºÎ°ú ÌååÏã±
        soup = BeautifulSoup(self.driver.page_source, 'html.parser')

        product_details = {}

        # üîπ Ï†úÌíàÎ™Ö Ï∂îÏ∂ú
        product_title_tag = soup.select_one("h1.product-title")
        product_details['product_title'] = product_title_tag.text.strip() if product_title_tag else ""

        # üîπ ÏÑúÎ∏å Ï†úÌíàÎ™Ö Ï∂îÏ∂ú
        product_sub_title_tag = soup.select_one("div.sub-product-title a")
        product_details['product_sub_title'] = product_sub_title_tag.text.strip() if product_sub_title_tag else ""

        # üîπ See More Î≤ÑÌäº ÌÅ¥Î¶≠ (ÏÖÄÎ†àÎãàÏõÄ ÏÇ¨Ïö©)
        try:
            see_more_button = self.driver.find_element(By.CSS_SELECTOR, ".seemoreParentDiv button")
            self.driver.execute_script("arguments[0].click();", see_more_button)
            time.sleep(2)  # ÌéòÏù¥ÏßÄ Í∞±Ïã† ÎåÄÍ∏∞ ÌõÑ Îã§Ïãú BeautifulSoupÏúºÎ°ú ÌååÏã±
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
        except Exception as e:
            self.log_signal.emit(f"See More Î≤ÑÌäº ÌÅ¥Î¶≠ Ïã§Ìå®: {e}")

        # FEATURES ÏÑπÏÖò ÌÉêÏÉâ Î∞è Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
        product_features = []

        features_sections = [
            "FEATURES",
            "PRODUCT FEATURES",
            "SHORTS FEATURES",
            "TECHNOLOGIES & FEATURES"
        ]

        for section_name in features_sections:
            features_section = soup.find("p", text=section_name)
            if features_section:
                ul = features_section.find_next_sibling("ul")
                if ul:
                    product_features = [li.text.strip() for li in ul.find_all("li")]
                    break  # Ï≤´ Î≤àÏß∏Î°ú Ï∞æÏùÄ Ìï≠Î™©ÏùÑ Ï†ÄÏû•ÌïòÍ≥† Î£®ÌîÑ Ï¢ÖÎ£å

        # product_featuresÎ•º JSON ÏßÅÎ†¨ÌôîÌïòÏó¨ Ï†ÄÏû•
        product_details['product_features'] = json.dumps(product_features, ensure_ascii=False) if product_features else "[]"

        # üîπ ÎåÄÌëú Ïù¥ÎØ∏ÏßÄ (Í≥†Ìï¥ÏÉÅÎèÑ srcsetÏóêÏÑú Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ Í∞ÄÏ†∏Ïò§Í∏∞)
        product_details['product_img_1'] = ""
        product_details['product_img_2'] = ""
        product_details['product_img_3'] = ""
        product_details['product_img_4'] = ""

        main_image = soup.select_one(".pdp-large-hero-image img")
        if main_image:
            srcset = main_image.get("srcset")
            if srcset:
                first_img = srcset.split(",")[0].strip().split(" ")[0]  # Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ URL Ï∂îÏ∂ú
                product_details['product_img_1'] = first_img
            else:
                product_details['product_img_1'] = main_image.get("src", "")

        # üîπ Ï∂îÍ∞Ä Ïù¥ÎØ∏ÏßÄ (ÏµúÎåÄ 3Í∞ú)
        image_elements = soup.select(".pdp-large-alt-images .large-alt-image:not(.video) img")
        for idx, img in enumerate(image_elements[:3]):
            product_details[f'product_img_{idx + 2}'] = img.get("src", "")

        return product_details

    # ÏÉÅÏÑ∏Ï†ïÎ≥¥
    def _get_product_details(self, product_url):
        self.driver.get(product_url)

        # ÌéòÏù¥ÏßÄ Î°úÎî© ÎåÄÍ∏∞
        time.sleep(3)

        product_details = {}

        # üîπ Ï†úÌíàÎ™Ö Ï∂îÏ∂ú
        try:
            product_details['product_title'] = self.driver.find_element(
                By.CSS_SELECTOR, "h1.product-title"
            ).text.strip()
        except:
            product_details['product_title'] = ""

        # üîπ ÏÑúÎ∏å Ï†úÌíàÎ™Ö Ï∂îÏ∂ú
        try:
            product_details['product_sub_title'] = self.driver.find_element(
                By.CSS_SELECTOR, "div.sub-product-title a"
            ).text.strip()
        except:
            product_details['product_sub_title'] = ""

        try:
            see_more_button = self.driver.find_element(By.CSS_SELECTOR, ".seemoreParentDiv button")
            self.driver.execute_script("arguments[0].click();", see_more_button)
            time.sleep(2)  # ÌéòÏù¥ÏßÄÍ∞Ä Í∞±Ïã†Îê† ÏãúÍ∞ÑÏùÑ ÌôïÎ≥¥
        except Exception as e:
            self.log_signal.emit(f"See More Î≤ÑÌäº ÌÅ¥Î¶≠ Ïã§Ìå®: {e}")

        # üîπ FEATURES Î™©Î°ù Ï∂îÏ∂ú
        try:
            features_section = self.driver.find_element(By.XPATH, "//p[text()='FEATURES']/following-sibling::ul")
            product_details['product_features'] = [li.text.strip() for li in features_section.find_elements(By.TAG_NAME, "li")]
        except:
            product_details['product_features'] = []

        # üîπ FABRIC & CARE Î™©Î°ù Ï∂îÏ∂ú
        try:
            fabric_care_section = self.driver.find_element(By.XPATH, "//p[text()='FABRIC & CARE']/following-sibling::ul")
            product_details['product_fabric_care'] = [li.text.strip() for li in fabric_care_section.find_elements(By.TAG_NAME, "li")]
        except:
            product_details['product_fabric_care'] = []

        # üîπ ÎåÄÌëú Ïù¥ÎØ∏ÏßÄ (Í≥†Ìï¥ÏÉÅÎèÑ srcsetÏóêÏÑú Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ Í∞ÄÏ†∏Ïò§Í∏∞)
        try:
            main_image = self.driver.find_element(By.CSS_SELECTOR, ".pdp-large-hero-image img")
            srcset = main_image.get_attribute("srcset")

            if srcset:
                # srcsetÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò ÌõÑ Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ ÏÑ†ÌÉù
                first_img = srcset.split(",")[0].strip().split(" ")[0]  # Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÏùò URLÎßå Ï∂îÏ∂ú
                product_details['product_img_1'] = first_img
            else:
                # srcsetÏù¥ ÏóÜÏúºÎ©¥ ÏùºÎ∞ò src ÏÇ¨Ïö©
                product_details['product_img_1'] = main_image.get_attribute("src")

        except Exception as e:
            self.log_signal.emit(f"ÎåÄÌëú Ïù¥ÎØ∏ÏßÄ Í∞ÄÏ†∏Ïò§Í∏∞ Ïã§Ìå®: {e}")
            product_details['product_img_1'] = ""

        # üîπ Ï∂îÍ∞Ä Ïù¥ÎØ∏ÏßÄ (ÏµúÎåÄ 3Í∞ú)
        product_details['product_img_2'] = ""
        product_details['product_img_3'] = ""
        product_details['product_img_4'] = ""

        try:
            image_elements = self.driver.find_elements(By.CSS_SELECTOR, ".pdp-large-alt-images .large-alt-image:not(.video) img")
            for idx, img in enumerate(image_elements[:3]):
                product_details[f'product_img_{idx + 2}'] = img.get_attribute("src")
        except:
            pass

        return product_details


    def load_products(self, file_path):
        if not os.path.exists(file_path):
            self.log_signal.emit(f"ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {file_path}")
            return []

        df = pd.read_csv(file_path, dtype=str)  # Î™®Îì† Îç∞Ïù¥ÌÑ∞Î•º Î¨∏ÏûêÏó¥Î°ú ÏùΩÏùå
        products = []
        for _, row in df.iterrows():
            product = {
                'product_id': row.get('product_id', ''),
                'product_name': row.get('product_name', ''),
                'product_url': row.get('product_url', ''),
                'product_title': row.get('product_title', ''),
                'product_sub_title': row.get('product_sub_title', ''),
                'product_features': row.get('product_features', []),  # Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú Î≥ÄÌôò
                'product_fabric_care': row.get('product_fabric_care', []),  # Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú Î≥ÄÌôò
                'product_img_1': row.get('product_img_1', ''),
                'product_img_2': row.get('product_img_2', ''),
                'product_img_3': row.get('product_img_3', ''),
                'product_img_4': row.get('product_img_4', ''),
                'data_success': row.get('data_success', 'N'),  # ÏÑ±Í≥µ Ïó¨Î∂Ä Ï∂îÍ∞Ä
                'img_success': row.get('img_success', 'N'),  # ÏÑ±Í≥µ Ïó¨Î∂Ä Ï∂îÍ∞Ä
                'img_path': row.get('img_path', []),  # ÏÑ±Í≥µ Ïó¨Î∂Ä Ï∂îÍ∞Ä
                'success': row.get('success', 'N'),  # ÏÑ±Í≥µ Ïó¨Î∂Ä Ï∂îÍ∞Ä
                'error': row.get('error', '')  # ÏÑ±Í≥µ Ïó¨Î∂Ä Ï∂îÍ∞Ä
            }
            products.append(product)

        return products


    def skip_products(self, new_product_id):

        if 'c' in new_product_id:
            return True

        for product in self.csv_product_list:
            if product['product_id'] == new_product_id:
                self.log_signal.emit(f'{product['product_id']} Ïä§ÌÇµ!!!')
                return product['success'] == 'Y'
        return False  # Í∏∞Î≥∏Ï†ÅÏúºÎ°ú NÏúºÎ°ú Í∞ÑÏ£º


    def get_old_data(self, new_product_id):
        for product in self.csv_product_list:
            if product['product_id'] == new_product_id and product['data_success'] == 'Y':
                return product
        return None

    def get_old_img(self, new_product_id):
        for product in self.csv_product_list:
            if product['product_id'] == new_product_id and product['img_success'] == 'Y':
                return product
        return None


    def get_products_from_page(self, url, checked_model):
        self.driver.get(url)
        time.sleep(3)  # ÌéòÏù¥ÏßÄÍ∞Ä ÏôÑÏ†ÑÌûà Î°úÎìúÎê† ÏãúÍ∞ÑÏùÑ ÌôïÎ≥¥

        # üîπ ÌéòÏù¥ÏßÄ ÎÅùÍπåÏßÄ Ïä§ÌÅ¨Î°§ Îã§Ïö¥ (Lazy Loading Ï≤òÎ¶¨)
        self.scroll_to_bottom()
        time.sleep(2)  # Ïä§ÌÅ¨Î°§ Ïù¥ÌõÑ ÌéòÏù¥ÏßÄ Î°úÎî© ÎåÄÍ∏∞

        # üîπ ÌòÑÏû¨ ÌéòÏù¥ÏßÄÏùò HTMLÏùÑ Í∞ÄÏ†∏ÏôÄÏÑú BeautifulSoupÏúºÎ°ú ÌååÏã±
        page_source = self.driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')

        find_match_txt = soup.select_one("h1.findMatchTxt")

        last_txt = find_match_txt.text.strip() if find_match_txt else ""

        if last_txt:
            return False

        # üîπ ÏÉÅÌíà Î™©Î°ù Í∞ÄÏ†∏Ïò§Í∏∞
        product_elements = soup.select("#productsContainer > li")

        for product in product_elements:
            self.current_cnt += 1
            try:
                # üîπ Ï†úÌíà ID Í∞ÄÏ†∏Ïò§Í∏∞
                product_id = product.get("data-id")
                product_element_id = product.get("id")
                self.log_signal.emit(product_element_id)

                skip = self.skip_products(product_id)

                if skip or not product_element_id or "scroll_id_" not in product_element_id:
                    continue

                # üîπ Ï†úÌíàÎ™Ö Í∞ÄÏ†∏Ïò§Í∏∞
                product_name = product.select_one(".products-container-right .prod_nameBlock p")
                product_name = product_name.text.strip() if product_name else ""

                # üîπ Ï†úÌíà ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄ URL Í∞ÄÏ†∏Ïò§Í∏∞
                product_link_element = product.select_one(".prod_img_block > a")
                product_url = product_link_element["href"] if product_link_element else ""

                if product_url and not product_url.startswith("https://www.kohls.com"):
                    product_url = "https://www.kohls.com" + product_url

                product_data = self.get_old_data(product_id)

                if not product_data:

                    # üîπ Ï†úÌíà ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
                    product_details = self.get_product_details(product_url)

                    product_data = {
                        "category_name": checked_model['name'],
                        "category_url": checked_model['url'],
                        "product_id": product_id,
                        "product_name": product_name,
                        "img_success": "N",
                        "data_success": "N",
                        "success": "N",
                        "product_url": product_url,
                        **product_details
                    }

                    if all([
                        product_data['product_id'],
                        product_data['product_name'],
                        product_data['product_url'],
                        product_data['product_sub_title'],
                        product_data['product_features'],
                        product_data['product_img_1']
                    ]):
                        product_data['data_success'] = 'Y'

                product_img_data = self.get_old_img(product_id)

                if not product_img_data:
                    product_data = self.download_images(product_data)
                else:
                    product_data['product_img_1'] = product_img_data['product_img_1']
                    product_data['product_img_2'] = product_img_data['product_img_2']
                    product_data['product_img_3'] = product_img_data['product_img_3']
                    product_data['product_img_4'] = product_img_data['product_img_4']
                    product_data['img_path']      = product_img_data['img_path']
                    product_data['img_success']   = product_img_data['img_success']


                if product_data['data_success'] == 'Y' and product_data['img_success'] == 'Y':
                    product_data['success'] = 'Y'
                    product_data['reg_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                self.append_to_csv([product_data])
                self.log_signal.emit(f'{product_data}')
                self.product_list.append(product_data)

                pro_value = (self.current_cnt / self.total_cnt) * 1000000
                self.progress_signal.emit(self.before_pro_value, pro_value)
                self.before_pro_value = pro_value
                self.log_signal.emit(f'{checked_model["name"]} TotalProduct({self.current_cnt}/{self.total_cnt})')

            except Exception as e:
                self.log_signal.emit(f"Error processing product: {e}")
                continue

        return True

    def scroll_to_bottom(self):
        """ ÌéòÏù¥ÏßÄÏùò ÎÅùÍπåÏßÄ Ïä§ÌÅ¨Î°§ÌïòÏó¨ Î™®Îì† Ï†úÌíàÏùÑ Î°úÎî© """
        last_height = self.driver.execute_script("return document.body.scrollHeight")

        while True:
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)  # Î°úÎî© ÎåÄÍ∏∞
            new_height = self.driver.execute_script("return document.body.scrollHeight")

            if new_height == last_height:
                break
            last_height = new_height

    # URL Í∞ÄÏ†∏Ïò§Í∏∞
    def get_url(self, name):
        url = ""
        if name:
            if name == 'Women / Bottoms / Pants':
                url = "https://www.kohls.com/catalog/womens-pants-bottoms-clothing.jsp?CN=Gender:Womens+Product:Pants+Category:Bottoms+Department:Clothing&cc=wms-TN3.0-S-pants&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Women / Bottoms / Skirts & Skorts':
                url = "https://www.kohls.com/catalog/womens-skirts-skorts-bottoms-clothing.jsp?CN=Gender:Womens+Product:Skirts%20%26%20Skorts+Category:Bottoms+Department:Clothing&cc=wms-TN3.0-S-skirtsskorts&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Women / Bottoms / Shorts':
                url = "https://www.kohls.com/catalog/womens-shorts-bottoms-clothing.jsp?CN=Gender:Womens+Product:Shorts+Category:Bottoms+Department:Clothing&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Women / Dresses & Jumpsuits':
                url = "https://www.kohls.com/catalog/womens-dresses-clothing.jsp?CN=Gender:Womens+Category:Dresses+Department:Clothing&cc=wms-TN2.0-S-dressesjumpsuits&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Men / Mes‚Äôs Tops / Button-Down Shirts':
                url = "https://www.kohls.com/catalog/mens-button-down-shirts-tops-clothing.jsp?CN=Gender:Mens+Silhouette:Button-Down%20Shirts+Category:Tops+Department:Clothing&cc=mens-TN3.0-S-buttondownshirts&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Men / Mes‚Äôs Bottoms / Casual Pants':
                url = "https://www.kohls.com/catalog/mens-casual-pants-bottoms-clothing.jsp?CN=Gender:Mens+Occasion:Casual+Product:Pants+Category:Bottoms+Department:Clothing&cc=mens-TN3.0-S-casualpants&kls_sbp=05864698454350754950882754362888169186"
            elif name == 'Men / Mes‚Äôs Bottoms / Shorts':
                url = "https://www.kohls.com/catalog/mens-shorts-bottoms-clothing.jsp?CN=Gender:Mens+Product:Shorts+Category:Bottoms+Department:Clothing&cc=mens-TN3.0-S-shorts&kls_sbp=05864698454350754950882754362888169186"
        return url