import json
import os
import random
import re
import ssl
import sys
import time
import traceback
from pathlib import Path

import pandas as pd
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
from selenium import webdriver
from tqdm import tqdm
import logging
from datetime import datetime
import builtins


# í˜„ì¬ ë””ë ‰í„°ë¦¬ì— ìˆëŠ” ë‹¤ë¥¸ íŒŒì¼ì„ importí•˜ë ¤ë©´ sys.path.append("./")ë¥¼ ì¶”ê°€í•´ì•¼ í•´ë‹¹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
sys.path.append("./")

# SSL ì¸ì¦ì„œ ê²€ì¦ì„ ê±´ë„ˆëœ€
ssl._create_default_https_context = ssl._create_unverified_context


# âœ… ê¸€ë¡œë²Œ ì˜ì—­ì— ë°±ì—…
original_print = builtins.print


def init_logger():
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)

    today = datetime.now().strftime("%Y-%m-%d")
    log_file = os.path.join(log_dir, f"{today}.log")

    # âœ… ì½˜ì†” ì¶œë ¥ì„ ì¤‘ë³µ ë°©ì§€í•˜ê¸° ìœ„í•´ StreamHandler ì œê±°
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(filename)s:%(lineno)d - %(funcName)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8")
        ]
    )

    # âœ… print()ë¥¼ logging.info() + ì½˜ì†” ì¶œë ¥ìœ¼ë¡œ ë®ê¸°
    def dual_print(*args, **kwargs):
        msg = " ".join(str(arg) for arg in args)
        logging.info(msg, stacklevel=2)  # ğŸ‘ˆ í˜¸ì¶œì ê¸°ì¤€ ë¼ì¸ìœ¼ë¡œ ê¸°ë¡
        original_print(*args, **kwargs)
    builtins.print = dual_print

    # âœ… original_printë¥¼ ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ì „ì—­ ë“±ë¡
    globals()["original_print"] = original_print

# === ì‹ ê·œ === None ë°©ì–´ìš© í…ìŠ¤íŠ¸ ìœ í‹¸
def safe_text(el, default=""):
    return el.get_text(strip=True) if el else default

# === ì‹ ê·œ === soup.find() ê²°ê³¼ None ë°©ì–´
def safe_find_text(soup, tag, class_=None, default=""):
    el = soup.find(tag, class_=class_)
    return safe_text(el, default=default)


class ARTVEE:
    def __init__(self) -> None:
        self.baseUrl = "https://artvee.com/"
        self.sess = requests.Session()

    def login(self)->dict:
        webdriver_options = webdriver.ChromeOptions()
        webdriver_options.add_argument('--disable-blink-features=AutomationControlled')
        webdriver_options.add_argument("--start-maximized")
        webdriver_options.add_argument("headless")
        webdriver_options.add_experimental_option('useAutomationExtension', False)
        webdriver_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        webdriver_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.driver = webdriver.Chrome(options=webdriver_options)
        self.driver.set_page_load_timeout(120)
        self.driver.get("https://artvee.com/")
        cookies = self.driver.get_cookies()
        for cookie in cookies:
            self.sess.cookies.set(cookie['name'], cookie['value'])
        self.version = self.driver.capabilities["browserVersion"]
        self.headers = {
            "User-Agent": f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{self.version}"
        }
        self.driver.quit()
        return self.headers

    def getArtistsUrlList(self) -> list[dict]:
        artistsUrlList:list[dict] = []
        totalCount = 1
        i = 1
        while 1:
            url:str = f"{self.baseUrl}artists/page/{i}/"
            res:requests.Response = self.sess.get(url,headers=self.headers)
            time.sleep(random.uniform(0.3, 0.5))
            i += 1
            if res.status_code == 200:
                soup = BeautifulSoup(res.content,"html.parser")
                allArtist = soup.find_all("div",class_="wrapp-catti")
                if len(allArtist) ==0:
                    break
                for artistInfo in allArtist:
                    artistUrl = artistInfo.find("a")["href"]
                    artistcount = artistInfo.find("mark", class_="count").text.strip()
                    artistsUrlList.append({"artistUrl":artistUrl,"artistcount":artistcount,"page":(i-1),"totalCount":totalCount})
                    totalCount+=1
        return artistsUrlList

    def getExcelArtistsUrlList(self, file_path) -> list[dict]:
        artistsUrlList: list[dict] = []

        # ì—‘ì…€ íŒŒì¼ ì½ê¸°
        df = pd.read_excel(file_path)

        # 'artist_list' ì»¬ëŸ¼ì—ì„œ URLë“¤ì„ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        url_list = df['artist_list'].tolist()
        print(f'artist_list : {url_list}')

        # URL ëª©ë¡ì„ artistsUrlListì— ì¶”ê°€
        totalCount = 1
        for i, artistUrl in enumerate(url_list, start=1):
            artistsUrlList.append({
                "artistUrl": artistUrl,
                "artistcount": '0',  # ì—‘ì…€ íŒŒì¼ì— 'artistcount' ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ì„ì‹œë¡œ 'N/A'ë¥¼ ì„¤ì •
                "page": 0,  # í˜ì´ì§€ ë²ˆí˜¸ëŠ” URL ìˆœì„œëŒ€ë¡œ ì„¤ì •
                "totalCount": totalCount
            })
            totalCount += 1

        return artistsUrlList

    def extractCollectionExcelInfo(self,df:pd.DataFrame,df_data:pd.DataFrame,collectionUrl:str,category:str) -> list[pd.DataFrame]:
        i = 1
        totalCount = 1
        totalImageInfoList:list[dict] = []
        artist_count_dict = {}
        while 1:
            url = f"{collectionUrl}page/{i}?&per_page=70"
            try:
                res = requests.get(url,headers=self.headers)
            except:
                time.sleep(10)
                print(f"ì‚¬ì´íŠ¸ ì˜¤ë¥˜ë¡œ ì¸í•œ ë„˜ê¹€ : {url}")
                i+=1
                continue
            if res.status_code != 200:
                break

            time.sleep(random.uniform(0.45, 0.55))
            soup = BeautifulSoup(res.content,"html.parser")
            if soup.find("div",class_="entry-content") != None or str(soup).find("Sorry, we can't seem to find the page you're looking for") != -1:
                break
            i += 1
            collectionName = soup.find("h1",class_="entry-title").text.strip()
            titlwrap = soup.find('div', class_='titlwrap')
            artistDescription = ""
            if titlwrap:
                containers = titlwrap.find_all('div', class_='container')
                for container in containers:
                    p = container.find('p')
                    if p:
                        artistDescription = p.get_text(strip=True)
                        break  # ì²« ë²ˆì§¸ <p> í…ìŠ¤íŠ¸ë§Œ ì›í•  ê²½ìš°

            infoList = soup.find_all("div",class_="pbm")

            total = soup.find("p",class_="woocommerce-result-count").text.replace("items","").strip()


            for index, infoData in enumerate(infoList, start=1):
                brand_div = infoData.find('div', class_='woodmart-product-brands-links')
                country = ""
                artistName = ""
                country_years = ""
                if brand_div:
                    match = re.search(r'\(([^)]+)\)', brand_div.text)
                    if match:
                        country_years = match.group(1)  # 'Norwegian, 1911 - 1992'
                        country = country_years.split(',')[0].strip()  # 'Norwegian'

                    a_tag = brand_div.find('a')
                    if a_tag:
                        artistName = a_tag.get_text(strip=True)

                key = artistName if artistName else "ì‘ê°€ëª… ì—†ìŒ"
                artist_count_dict[key] = artist_count_dict.get(key, 0) + 1


                div = infoData.find("div", class_="woodmart-product-cats")
                field = div.text.strip() if div else ""
                data = infoData.find("div")
                idData = data["data-id"].strip()
                sizeData = json.loads(data["data-sk"])
                imgInfo = sizeData["sk"]
                try:
                    standard = sizeData["sdlimagesize"].split("px")[0].split("x")
                    standardX = standard[0].strip()
                    standardY = standard[1].strip()
                except:
                    standardX = ""
                    standardY = ""
                try:
                    max = sizeData["hdlimagesize"].split("px")[0].split("x")
                    maxX = max[0].strip()
                    maxY = max[1].strip()
                except:
                    maxX = ""
                    maxY = ""
                pieceUrl = str(infoData.find("a")["href"])
                pieceInfo = infoData.find("h3",class_="product-title").text.strip()
                title = pieceInfo.split("(")[0].strip()
                if len(pieceInfo.split("(")) == 1:
                    birth = ""
                elif len(pieceInfo.split("(")) == 2:
                    birth = pieceInfo.split("(")[1].split(")")[0].strip()
                elif len(pieceInfo.split("(")) == 3:
                    birth = pieceInfo.split("(")[2].split(")")[0].strip()
                try:
                    int(birth)
                except:
                    birth = ""
                if title == "":
                    title = "("+pieceInfo.split("(")[1].split("(")[0].strip()
                df_info = pd.DataFrame.from_dict([{
                    "í˜ì´ì§€":i-1,
                    "ID":idData,
                    "ì‘ê°€ëª…":key,
                    "ì‘í’ˆëª…":title,
                    "ì‘í’ˆëª…í’€ë„¤ì„":pieceInfo,
                    "êµ­ê°€":country,
                    "êµ­ì ë°ìƒëª°ë…„ë„":country_years,
                    "ì¥ë¥´":category,
                    "ì‘í’ˆë…„ë„":birth,
                    "Px-ê°€ë¡œ":standardX,
                    "Px-ì„¸ë¡œ":standardY,
                    "MaxPx-ê°€ë¡œ":maxX,
                    "MaxPx-ì„¸ë¡œ":maxY,
                    "url":pieceUrl,
                    "skdata":imgInfo,
                    "ì´ë¯¸ì§€ ëª…": "",
                    "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€": "",
                    "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€": ""
                }])
                print({
                    "í˜ì´ì§€":i-1,
                    "ID":idData,
                    "ì‘ê°€ëª…":key,
                    "ì‘í’ˆëª…":title,
                    "ì‘í’ˆëª…í’€ë„¤ì„":pieceInfo,
                    "êµ­ê°€":country,
                    "êµ­ì ë°ìƒëª°ë…„ë„":country_years,
                    "ì¥ë¥´":category,
                    "ì‘í’ˆë…„ë„":birth,
                    "Px-ê°€ë¡œ":standardX,
                    "Px-ì„¸ë¡œ":standardY,
                    "MaxPx-ê°€ë¡œ":maxX,
                    "MaxPx-ì„¸ë¡œ":maxY,
                    "url":pieceUrl,
                    "skdata":imgInfo
                })
                df = pd.concat([df,df_info])
                totalCount+=1

        # ìµœì¢… ì‘ê°€ë³„ ìˆ˜ëŸ‰ DataFrame ìƒì„±
        # ì‘ê°€ëª… ì—†ìŒì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
        rows = []

        for name, count in artist_count_dict.items():
            if name != "ì‘ê°€ëª… ì—†ìŒ":
                rows.append({"ì‘ê°€ëª…": name, "ìˆ˜ëŸ‰": count})

        # ë§ˆì§€ë§‰ì— "ì‘ê°€ëª… ì—†ìŒ" ì¶”ê°€
        if "ì‘ê°€ëª… ì—†ìŒ" in artist_count_dict:
            rows.append({"ì‘ê°€ëª…": "ì‘ê°€ëª… ì—†ìŒ", "ìˆ˜ëŸ‰": artist_count_dict["ì‘ê°€ëª… ì—†ìŒ"]})

        df_data = pd.DataFrame(rows)


        return [df,df_data,totalImageInfoList]

    def extractArtistExcelInfo(self,df:pd.DataFrame,df_data:pd.DataFrame,artistUrl:str,artistcount:str,page:int,artistTotalCount:int) -> list[pd.DataFrame]:
        i = 1
        totalCount = 1
        totalImageInfoList:list[dict] = []
        while 1:
            url = f"{artistUrl}page/{i}?&per_page=70"
            try:
                # === ì‹ ê·œ === ì¿ í‚¤ ìœ ì§€(sess)ë¡œ ìš”ì²­ (requests.get -> self.sess.get)
                res = self.sess.get(url,headers=self.headers,timeout=30)
            except:
                time.sleep(10)
                print(f"ì‚¬ì´íŠ¸ ì˜¤ë¥˜ë¡œ ì¸í•œ ë„˜ê¹€ : {url}")
                i+=1
                continue
            if res.status_code != 200:
                break
            time.sleep(random.uniform(0.45, 0.55))
            soup = BeautifulSoup(res.content,"html.parser")
            if soup.find("div",class_="entry-content") != None or str(soup).find("Sorry, we can't seem to find the page you're looking for") != -1:
                break
            i += 1

            # === ì‹ ê·œ === NoneType ë°©ì–´ (íŠ¹ì • ì‘ê°€ í˜ì´ì§€ì—ì„œ ìš”ì†Œ ëˆ„ë½ë˜ëŠ” ì¼€ì´ìŠ¤)
            artistName = safe_find_text(soup, "h1", class_="entry-title", default="ì‘ê°€ëª… ì—†ìŒ")

            abdate_txt = safe_find_text(soup, "div", class_="abdate", default="")
            if abdate_txt:
                abdate = abdate_txt.strip().split(",")
                country = abdate[0].strip() if len(abdate) > 0 else ""
            else:
                country = ""

            artistDescription = safe_find_text(soup, "div", class_="term-description", default="")

            infoList = soup.find_all("div",class_="pbm")

            total_txt = safe_find_text(soup, "p", class_="woocommerce-result-count", default="")
            total = total_txt.replace("items","").strip() if total_txt else ""

            # === ì‹ ê·œ === ë¦¬ìŠ¤íŠ¸ ìì²´ê°€ ë¹„ì—ˆìœ¼ë©´(ì°¨ë‹¨/êµ¬ì¡° ë³€ê²½/ë¹„ì •ìƒ) ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ê¹€
            if not infoList:
                print(f"infoList ì—†ìŒ(ì°¨ë‹¨/êµ¬ì¡°ë³€ê²½ ê°€ëŠ¥) : {url}")
                continue

            for infoData in infoList:
                # === ì‹ ê·œ === woodmart-product-cats ì—†ì„ ìˆ˜ ìˆìŒ
                field = safe_text(infoData.find("div",class_="woodmart-product-cats"), default="").strip()

                data = infoData.find("div")
                # === ì‹ ê·œ === data-id / data-sk ëˆ„ë½ ë°©ì–´
                if data is None or data.get("data-id") is None or data.get("data-sk") is None:
                    print(f"data-id ë˜ëŠ” data-sk ëˆ„ë½ : {url}")
                    continue

                idData = data["data-id"].strip()

                # === ì‹ ê·œ === JSON íŒŒì‹± ì‹¤íŒ¨ ë°©ì–´
                try:
                    sizeData = json.loads(data["data-sk"])
                except:
                    print(f"data-sk JSON íŒŒì‹± ì‹¤íŒ¨ : {url} / id={idData}")
                    continue

                imgInfo = sizeData.get("sk", "")

                try:
                    standard = sizeData["sdlimagesize"].split("px")[0].split("x")
                    standardX = standard[0].strip()
                    standardY = standard[1].strip()
                except:
                    standardX = "ì •ë³´ì—†ìŒ"
                    standardY = "ì •ë³´ì—†ìŒ"
                try:
                    max = sizeData["hdlimagesize"].split("px")[0].split("x")
                    maxX = max[0].strip()
                    maxY = max[1].strip()
                except:
                    maxX = "ì •ë³´ì—†ìŒ"
                    maxY = "ì •ë³´ì—†ìŒ"

                # === ì‹ ê·œ === a íƒœê·¸ ëˆ„ë½ ë°©ì–´
                a_tag = infoData.find("a")
                pieceUrl = str(a_tag["href"]) if a_tag and a_tag.get("href") else ""

                pieceInfo = safe_text(infoData.find("h3",class_="product-title"), default="").strip()
                if pieceInfo == "":
                    # === ì‹ ê·œ === ì œëª© ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    continue

                title = pieceInfo.split("(")[0].strip()
                if len(pieceInfo.split("(")) == 1:
                    birth = "ì—†ìŒ"
                elif len(pieceInfo.split("(")) == 2:
                    birth = pieceInfo.split("(")[1].split(")")[0].strip()
                elif len(pieceInfo.split("(")) == 3:
                    birth = pieceInfo.split("(")[2].split(")")[0].strip()
                try:
                    int(birth)
                except:
                    birth = "ì—†ìŒ"
                if title == "":
                    title = "("+pieceInfo.split("(")[1].split("(")[0].strip()

                df_info = pd.DataFrame.from_dict([{
                    "í˜ì´ì§€":page,
                    "ì‘ê°€ìˆœì„œ":artistTotalCount,
                    "ê·¸ë¦¼ìˆœì„œ":totalCount,
                    "ID":idData,
                    "ì‘ê°€ëª…":artistName,
                    "ì‘í’ˆëª…":title,
                    "ì‘í’ˆëª…í’€ë„¤ì„":pieceInfo,
                    "êµ­ê°€":country,
                    "ì¥ë¥´":field,
                    "ì‘í’ˆë…„ë„":birth,
                    "ìˆ˜ëŸ‰":total,
                    "Px-ê°€ë¡œ":standardX,
                    "Px-ì„¸ë¡œ":standardY,
                    "MaxPx-ê°€ë¡œ":maxX,
                    "MaxPx-ì„¸ë¡œ":maxY,
                    "url":pieceUrl,
                    "skdata":imgInfo
                }])
                df = pd.concat([df,df_info])
                totalCount+=1

        df_data_info =pd.DataFrame.from_dict([{
            "í˜ì´ì§€":page,
            "ì‘ê°€ëª…":artistName,
            "êµ­ê°€":country,
            "ìˆ˜ëŸ‰":total,
            "ì‘ê°€ë‚´ìš©":artistDescription
        }])
        df_data = pd.concat([df_data,df_data_info])
        return [df,df_data,totalImageInfoList]




def main()->None:
    currentPath = os.getcwd().replace("\\","/")
    excelCheck = input("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1.ì˜ˆ 2. ì•„ë‹ˆì˜¤ : ").strip()
    downloadCheck = input("1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ / 2. ë‹¤ìš´ì•ˆëœ ì´ë¯¸ì§€ ì¬ ë‹¤ìš´ë¡œë“œ : ")
    if downloadCheck == "1":
        startPage = input("ì¶”ì¶œ í˜ì´ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì—”í„°ì‹œ ì²˜ìŒë¶€í„°): ").strip()
        selectArtistName:str = input("ì¶”ì¶œ ì‘ê°€ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì—”í„°ì‹œ ì²˜ìŒë¶€í„°): ").strip()
    firstSheetColumn = ["í˜ì´ì§€","ì‘ê°€ìˆœì„œ","ê·¸ë¦¼ìˆœì„œ","ID","ì‘ê°€ëª…","ì‘í’ˆëª…","ì‘í’ˆëª…í’€ë„¤ì„","êµ­ê°€","ì¥ë¥´","ì‘í’ˆë…„ë„","ìˆ˜ëŸ‰","Px-ê°€ë¡œ","Px-ì„¸ë¡œ","MaxPx-ê°€ë¡œ","MaxPx-ì„¸ë¡œ","url","skdata","ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"]
    secondSheetColumn = ["","í˜ì´ì§€","ì‘ê°€ëª…","êµ­ê°€","ìˆ˜ëŸ‰","ì‘ê°€ë‚´ìš©"]
    totalImageInfoList:list[dict] = []
    excelIndex = 1
    artvee = ARTVEE()
    headers=artvee.login()
    if excelCheck == "1":
        print("ì „ì²´ ì˜ˆìˆ ê°€ ëª©ë¡ í™•ì¸ì¤‘ ..... ")
        artistUrlList:list[dict] = artvee.getArtistsUrlList()
        print("ì „ì²´ ì˜ˆìˆ ê°€ ëª©ë¡ í™•ì¸ ì™„ë£Œ!")
        print("ì˜ˆìˆ ê°€ ì •ë³´ ì—‘ì…€ ì¶”ì¶œ ì‹œì‘!")
        df = pd.DataFrame(columns=firstSheetColumn)
        df_data = pd.DataFrame(columns=secondSheetColumn)
        beforePage = 1
        for artistInfoForExcel in tqdm(artistUrlList):
            artistUrl=artistInfoForExcel["artistUrl"]
            artistcount=artistInfoForExcel["artistcount"]
            artistPage = artistInfoForExcel["page"]
            artistTotalCount = artistInfoForExcel["totalCount"]
            ################################################
            # url = f"{artistUrl}"
            # res = requests.get(url)
            # soup = BeautifulSoup(res.content,"html.parser")
            # try:
            #     imgUrl = soup.find("img",class_="imspanc")["src"]
            # except:
            #     print(url)
            #     beforePage+=1
            #     continue
            # imgName = soup.find("h1",class_="entry-title").text.strip()
            # number = f"0000{beforePage}"
            # imgName = number[-4:]+" "+imgName
            # imageInfo = requests.get(imgUrl)
            # f = open(f"./result/image/{imgName}.jpg",'wb')
            # f.write(imageInfo.content)
            # f.close()
            # beforePage+=1
            ####################################################
            if len(df["ì‘í’ˆëª…"].tolist()) > 15000 and artistPage != beforePage:
                with pd.ExcelWriter(f"{currentPath}/result/excel/artvee_{excelIndex}.xlsx",engine='openpyxl') as writer: #xlsxwriter
                    df.to_excel(writer,sheet_name="1",index=False)
                    df_data.to_excel(writer,sheet_name="2",index=False)
                excelIndex += 1
                df = pd.DataFrame(columns=firstSheetColumn)
                df_data = pd.DataFrame(columns=secondSheetColumn)
            df_info = artvee.extractArtistExcelInfo(df=df,df_data=df_data,artistUrl=artistUrl,artistcount=artistcount,page=artistPage,artistTotalCount=artistTotalCount)
            df = df_info[0].reset_index(drop=True)
            df_data = df_info[1].reset_index(drop=True)
            totalImageInfoList+=df_info[2]
            beforePage = artistPage
        if (df["ì‘í’ˆëª…"].tolist()) != 0:
            with pd.ExcelWriter(f"{currentPath}/result/excel/artvee_{excelIndex}.xlsx",engine='openpyxl') as writer: #xlsxwriter
                df.to_excel(writer,sheet_name="1",index=False)
                df_data.to_excel(writer,sheet_name="2",index=False)
        print("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ ì™„ë£Œ")
    excelPath = f"{currentPath}/result/excel"
    imagePath = f"{currentPath}/result/image"
    fileList = os.listdir(path=excelPath)

    for fileInfo in fileList:
        if fileInfo.find("~$") != -1:
            print("ì—‘ì…€íŒŒì¼ì„ ë‹«ì•„ì£¼ì„¸ìš”")
            continue
        try:
            df_excel = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="1")
            df_excel_data = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="2")
        except:
            print(f"{excelPath}/{fileInfo}ëŠ” ì—‘ì…€ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
            continue
        print(f"{fileInfo} ì´ë¯¸ì§€ ì¶”ì¶œì¤‘")
        for idx, dataInfo in enumerate(tqdm(df_excel["skdata"])):
            imageUrl = f"https://mdl.artvee.com/sdl/{dataInfo}sdl.jpg"
            pageInfo = str(df_excel.at[idx,"í˜ì´ì§€"])
            nameInfo = df_excel.at[idx,"ì‘ê°€ëª…"]
            pieceInfo = df_excel.at[idx,"ì‘í’ˆëª…"]
            artistNum = "0000"+str(df_excel.at[idx,"ì‘ê°€ìˆœì„œ"])
            artistNum = artistNum[-3:]
            pieceNumInfo = "0000"+str(df_excel.at[idx,"ê·¸ë¦¼ìˆœì„œ"])
            pieceNumInfo = pieceNumInfo[-4:]
            idInfo = df_excel.at[idx,"ID"]
            imageIs = df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"]
            if downloadCheck =="2" and imageIs != "X":
                continue

            if selectArtistName != "" and selectArtistName != nameInfo:
                continue
            if startPage != "" and startPage != pageInfo:
                continue
            filename = f"{pageInfo}_{artistNum}_{pieceNumInfo}_{nameInfo}_{pieceInfo}_{idInfo}"
            try:
                imageInfo = requests.get(imageUrl,headers=headers,timeout=30)
            except: # timeoutìœ¼ë¡œ ì¸í•œ ë„˜ê¹€
                print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                time.sleep(5)
                continue
            if imageInfo.status_code == 200:
                namePath = f"{imagePath}/{pageInfo}_{nameInfo}"
                if os.path.exists(namePath) == False:
                    os.makedirs(namePath)
                try:
                    f = open(f"{namePath}/{filename}.jpg",'wb')
                    f.write(imageInfo.content)
                    f.close()
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = ""
                except:
                    print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                    time.sleep(5)
            elif imageInfo.status_code == 404:
                soup = BeautifulSoup(imageInfo.content,"xml")
                errormsg = soup.find("Code").text
                if errormsg.find("NoSuchKey") != -1:
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                    continue
            else:
                print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                time.sleep(5)
            time.sleep(0.5)
        with pd.ExcelWriter(f"{excelPath}/{fileInfo}",engine='openpyxl') as writer: #xlsxwriter
            df_excel.to_excel(writer,sheet_name="1",index=False)
            df_excel_data.to_excel(writer,sheet_name="2",index=False)

def translatorFromExcel()->None:
    currentPath = os.getcwd().replace("\\","/")

    os.makedirs(f"{currentPath}/result/excel", exist_ok=True)
    os.makedirs(f"{currentPath}/result/image", exist_ok=True)

    excelPath = f"{currentPath}/result/excel"
    fileList = os.listdir(path=excelPath)
    translator = GoogleTranslator(source='auto', target='ko')
    for fileInfo in fileList:
        if fileInfo.find("~$") != -1:
            print("ì—‘ì…€íŒŒì¼ì„ ë‹«ì•„ì£¼ì„¸ìš”")
            continue
        try:
            df_excel = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="1")
            df_excel_data = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="2")
        except:
            traceback.print_exc()
            print(f"{fileInfo} ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨")
            continue
        for idx, data in enumerate(tqdm(df_excel["í˜ì´ì§€"])):
            try:
                pieceInfo = df_excel.at[idx,"ì‘í’ˆëª…"]
                pieceFullInfo = df_excel.at[idx,"ì‘í’ˆëª…í’€ë„¤ì„"]
                try:
                    pieceInfoTrans = translator.translate(pieceInfo)
                    pieceFullInfoTrans = translator.translate(pieceFullInfo)
                except:
                    try:
                        time.sleep(20)
                        pieceInfoTrans = translator.translate(pieceInfo)
                        pieceFullInfoTrans = translator.translate(pieceFullInfo)
                    except:
                        time.sleep(60)
                        pieceInfoTrans = translator.translate(pieceInfo)
                        pieceFullInfoTrans = translator.translate(pieceFullInfo)
                if idx !=0 and idx%1000==0:
                    with pd.ExcelWriter(f"{excelPath}/{fileInfo}",engine='openpyxl') as writer: #xlsxwriter
                        df_excel.to_excel(writer,sheet_name="1",index=False)
                        df_excel_data.to_excel(writer,sheet_name="2",index=False)
                time.sleep(0.3)
                df_excel.at[idx,"ë²ˆì—­-1(ê´„í˜¸í¬í•¨)"] = pieceFullInfoTrans
                df_excel.at[idx,"ë²ˆì—­-2(ê´„í˜¸ ë¯¸í¬í•¨)"] = pieceInfoTrans
            except:
                traceback.print_exc()
                print("í˜ì´ì§€ ë²ˆì—­ ë˜ëŠ” ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx,"ë²ˆì—­-1(ê´„í˜¸í¬í•¨)"] = "ë²ˆì—­ì‹¤íŒ¨"
                df_excel.at[idx,"ë²ˆì—­-2(ê´„í˜¸ ë¯¸í¬í•¨)"] = "ë²ˆì—­ì‹¤íŒ¨"
                time.sleep(30)
        with pd.ExcelWriter(f"{excelPath}/{fileInfo}",engine='openpyxl') as writer: #xlsxwriter
            df_excel.to_excel(writer,sheet_name="1",index=False)
            df_excel_data.to_excel(writer,sheet_name="2",index=False)


def sub_main()->None:
    currentPath = os.getcwd()  # í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬
    excelPath = f"{currentPath}/result"
    file_path = os.path.join(excelPath, "artvee_artist_list.xlsx")
    if not os.path.exists(file_path):
        print("artvee_artist_list.xlsx íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì•„ë˜ ì‘ì—…ì„ ì§„í–‰
    print("artvee_artist_list.xlsx íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    currentPath = os.getcwd().replace("\\","/")
    excelCheck = input("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1.ì˜ˆ 2. ì•„ë‹ˆì˜¤ : ").strip()
    downloadCheck = input("1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ / 2. ë‹¤ìš´ì•ˆëœ ì´ë¯¸ì§€ ì¬ ë‹¤ìš´ë¡œë“œ : ")
    firstSheetColumn = ["í˜ì´ì§€","ì‘ê°€ìˆœì„œ","ê·¸ë¦¼ìˆœì„œ","ID","ì‘ê°€ëª…","ì‘í’ˆëª…","ì‘í’ˆëª…í’€ë„¤ì„","êµ­ê°€","ì¥ë¥´","ì‘í’ˆë…„ë„","ìˆ˜ëŸ‰","Px-ê°€ë¡œ","Px-ì„¸ë¡œ","MaxPx-ê°€ë¡œ","MaxPx-ì„¸ë¡œ","url","skdata","ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€", "ì—ëŸ¬ë‚´ìš©"]
    secondSheetColumn = ["","í˜ì´ì§€","ì‘ê°€ëª…","êµ­ê°€","ìˆ˜ëŸ‰","ì‘ê°€ë‚´ìš©"]
    totalImageInfoList:list[dict] = []
    excelIndex = 1
    artvee = ARTVEE()
    headers=artvee.login()
    if excelCheck == "1":
        print("ì¶”ê°€ ì˜ˆìˆ ê°€ ëª©ë¡ í™•ì¸ì¤‘ ..... ")
        artistUrlList:list[dict] = artvee.getExcelArtistsUrlList(file_path)
        print("ì¶”ê°€ ì˜ˆìˆ ê°€ ëª©ë¡ í™•ì¸ ì™„ë£Œ!")
        print("ì˜ˆìˆ ê°€ ì •ë³´ ì—‘ì…€ ì¶”ì¶œ ì‹œì‘!")
        df = pd.DataFrame(columns=firstSheetColumn)
        df_data = pd.DataFrame(columns=secondSheetColumn)
        beforePage = 1
        for artistInfoForExcel in tqdm(artistUrlList):
            artistUrl=artistInfoForExcel["artistUrl"]
            artistcount=artistInfoForExcel["artistcount"]
            artistPage = artistInfoForExcel["page"]
            artistTotalCount = artistInfoForExcel["totalCount"]
            ################################################
            # url = f"{artistUrl}"
            # res = requests.get(url)
            # soup = BeautifulSoup(res.content,"html.parser")
            # try:
            #     imgUrl = soup.find("img",class_="imspanc")["src"]
            # except:
            #     print(url)
            #     beforePage+=1
            #     continue
            # imgName = soup.find("h1",class_="entry-title").text.strip()
            # number = f"0000{beforePage}"
            # imgName = number[-4:]+" "+imgName
            # imageInfo = requests.get(imgUrl)
            # f = open(f"./result/image/{imgName}.jpg",'wb')
            # f.write(imageInfo.content)
            # f.close()
            # beforePage+=1
            ####################################################
            if len(df["ì‘í’ˆëª…"].tolist()) > 15000 and artistPage != beforePage:
                with pd.ExcelWriter(f"{currentPath}/result/excel/artvee_artist_{excelIndex}.xlsx",engine='openpyxl') as writer: #xlsxwriter
                    df.to_excel(writer,sheet_name="1",index=False)
                    df_data.to_excel(writer,sheet_name="2",index=False)
                excelIndex += 1
                df = pd.DataFrame(columns=firstSheetColumn)
                df_data = pd.DataFrame(columns=secondSheetColumn)
            df_info = artvee.extractArtistExcelInfo(df=df,df_data=df_data,artistUrl=artistUrl,artistcount=artistcount,page=artistPage,artistTotalCount=artistTotalCount)
            df = df_info[0].reset_index(drop=True)
            df_data = df_info[1].reset_index(drop=True)
            totalImageInfoList+=df_info[2]
            beforePage = artistPage
        if (df["ì‘í’ˆëª…"].tolist()) != 0:

            with pd.ExcelWriter(f"{currentPath}/result/excel/artvee_artist_{excelIndex}.xlsx",engine='openpyxl') as writer: #xlsxwriter
                df.to_excel(writer,sheet_name="1",index=False)
                df_data.to_excel(writer,sheet_name="2",index=False)
        print("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ ì™„ë£Œ")
    excelPath = f"{currentPath}/result/excel"
    imagePath = f"{currentPath}/result/image"
    fileList = os.listdir(path=excelPath)

    for fileInfo in fileList:
        if fileInfo.find("~$") != -1:
            print("ì—‘ì…€íŒŒì¼ì„ ë‹«ì•„ì£¼ì„¸ìš”")
            continue
        try:
            df_excel = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="1")
            df_excel_data = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="2")
        except:
            print(f"{excelPath}/{fileInfo}ëŠ” ì—‘ì…€ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
            continue
        print(f"{fileInfo} ì´ë¯¸ì§€ ì¶”ì¶œì¤‘")
        for idx, dataInfo in enumerate(tqdm(df_excel["skdata"])):
            imageUrl = f"https://mdl.artvee.com/sdl/{dataInfo}sdl.jpg"
            pageInfo = str(df_excel.at[idx,"í˜ì´ì§€"])
            nameInfo = df_excel.at[idx,"ì‘ê°€ëª…"]
            pieceInfo = df_excel.at[idx,"ì‘í’ˆëª…"]
            artistNum = "0000"+str(df_excel.at[idx,"ì‘ê°€ìˆœì„œ"])
            artistNum = artistNum[-3:]
            pieceNumInfo = "0000"+str(df_excel.at[idx,"ê·¸ë¦¼ìˆœì„œ"])
            pieceNumInfo = pieceNumInfo[-4:]
            idInfo = df_excel.at[idx,"ID"]
            imageIs = df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"]
            if downloadCheck =="2" and imageIs != "X":
                continue
            filename = f"{pageInfo}_{artistNum}_{pieceNumInfo}_{nameInfo}_{pieceInfo}_{idInfo}"
            try:
                imageInfo = requests.get(imageUrl,headers=headers,timeout=30)
            except: # timeoutìœ¼ë¡œ ì¸í•œ ë„˜ê¹€
                print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                time.sleep(5)
                continue
            if imageInfo.status_code == 200:
                namePath = f"{imagePath}/{pageInfo}_{nameInfo}"
                if os.path.exists(namePath) == False:
                    os.makedirs(namePath)
                try:
                    f = open(f"{namePath}/{filename}.jpg",'wb')
                    f.write(imageInfo.content)
                    f.close()
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = ""
                except:
                    print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                    time.sleep(5)
            elif imageInfo.status_code == 404:
                soup = BeautifulSoup(imageInfo.content,"xml")
                errormsg = soup.find("Code").text
                if errormsg.find("NoSuchKey") != -1:
                    df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "ì—†ìŒ"
                    continue
            else:
                print(f"{filename} ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx,"ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                time.sleep(5)
            time.sleep(0.5)
        with pd.ExcelWriter(f"{excelPath}/{fileInfo}",engine='openpyxl') as writer: #xlsxwriter
            df_excel.to_excel(writer,sheet_name="1",index=False)
            df_excel_data.to_excel(writer,sheet_name="2",index=False)


def collection_filter()-> tuple[str, str]:
    excelCheck = input("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 1.ì˜ˆ 2. ì•„ë‹ˆì˜¤ : ").strip()
    downloadCheck = input("1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ / 2. ë‹¤ìš´ì•ˆëœ ì´ë¯¸ì§€ ì¬ ë‹¤ìš´ë¡œë“œ : ")
    return excelCheck, downloadCheck


def collection_main(category, excelCheck, downloadCheck) -> None:
    currentPath = os.getcwd().replace("\\", "/")
    excelPath = f"{currentPath}/result/excel/collection"
    os.makedirs(excelPath, exist_ok=True)

    file_path = os.path.join(excelPath, f"artvee_{category}.xlsx")
    firstSheetColumn = ["í˜ì´ì§€", "ID", "ì‘ê°€ëª…", "ì‘í’ˆëª…", "ì‘í’ˆëª…í’€ë„¤ì„", "êµ­ê°€", "êµ­ì ë°ìƒëª°ë…„ë„", "ì¥ë¥´", "ì‘í’ˆë…„ë„",
                        "Px-ê°€ë¡œ", "Px-ì„¸ë¡œ", "MaxPx-ê°€ë¡œ", "MaxPx-ì„¸ë¡œ", "url", "skdata", "ì´ë¯¸ì§€ ëª…", "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€", "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€", "ì—ëŸ¬ë‚´ìš©"]
    secondSheetColumn = ["ì‘ê°€ëª…", "ìˆ˜ëŸ‰"]

    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(file_path):
        print(f"âœ… artvee_{category}.xlsx íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        df1 = pd.DataFrame(columns=firstSheetColumn)
        df2 = pd.DataFrame(columns=secondSheetColumn)
        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
            df1.to_excel(writer, sheet_name="1", index=False)
            df2.to_excel(writer, sheet_name="2", index=False)
    else:
        print(f"ğŸ“‚ artvee_{category}.xlsx íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")

    # ì—‘ì…€ ë¡œë”© í›„ ì‘ì—… ì§„í–‰
    totalImageInfoList: list[dict] = []
    artvee = ARTVEE()
    headers = artvee.login()

    collectionUrl = f"https://artvee.com/c/{category}/"
    collectionCount = "0"

    if excelCheck == "1":
        print(f"{category} ì •ë³´ ì—‘ì…€ ì¶”ì¶œ ì‹œì‘!")
        df = pd.DataFrame(columns=firstSheetColumn)
        df_data = pd.DataFrame(columns=secondSheetColumn)
        df_info = artvee.extractCollectionExcelInfo(df=df,df_data=df_data,collectionUrl=collectionUrl,category=category)
        df = df_info[0].reset_index(drop=True)
        df_data = df_info[1].reset_index(drop=True)
        totalImageInfoList+=df_info[2]
        if (df["ì‘í’ˆëª…"].tolist()) != 0:
            with pd.ExcelWriter(f"{currentPath}/result/excel/collection/artvee_{category}.xlsx",engine='openpyxl') as writer: #xlsxwriter
                df.to_excel(writer,sheet_name="1",index=False)
                df_data.to_excel(writer,sheet_name="2",index=False)
            print("ì „ì²´ ì—‘ì…€ ì¶”ì¶œ ì™„ë£Œ")

    file_name = f"artvee_{category}.xlsx"
    excelPath = f"{currentPath}/result/excel/collection"
    imageCategoryPath = f"{currentPath}/result/image/collection/{category}/category"
    imageArtistPath = f"{currentPath}/result/image/collection/{category}/artist"
    file_path = os.path.join(excelPath, file_name)

    if not os.path.exists(file_path):
        print(f"{file_name} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    fileInfo = file_name  # forë¬¸ ì—†ì´ ë³€ìˆ˜ë§Œ ì§€ì •

    if fileInfo.find("~$") != -1:
        print("ì—‘ì…€íŒŒì¼ì„ ë‹«ì•„ì£¼ì„¸ìš”")
        return
    try:
        df_excel = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="1")
        df_excel_data = pd.read_excel(f"{excelPath}/{fileInfo}",sheet_name="2")
    except:
        print(f"{excelPath}/{fileInfo}ëŠ” ì—‘ì…€ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return
    print(f"{fileInfo} ì´ë¯¸ì§€ ì¶”ì¶œì¤‘")


    MAX_PATH_LENGTH = 260  # Windows ì œí•œ
    ext = ".jpg"

    # ğŸ”§ ê²½ê³  ë°©ì§€: ë¬¸ìì—´ íƒ€ì… ëª…ì‹œ
    df_excel["ì´ë¯¸ì§€ ëª…"] = df_excel["ì´ë¯¸ì§€ ëª…"].astype(str)
    df_excel["ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = df_excel["ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"].astype(str)
    df_excel["ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = df_excel["ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"].astype(str)
    df_excel["ì—ëŸ¬ë‚´ìš©"] = df_excel["ì—ëŸ¬ë‚´ìš©"].astype(str)

    # ë©”ì¸ ë‹¤ìš´ë¡œë“œ ë£¨í”„

    total_records = len(df_excel["skdata"])
    print(f"ğŸ”¢ ì´ ë ˆì½”ë“œ ìˆ˜: {total_records}")

    for idx, dataInfo in enumerate(tqdm(df_excel["skdata"], desc="ì´ë¯¸ì§€ ì €ì¥ ì¤‘", total=total_records)):
        imageUrl = f"https://mdl.artvee.com/sdl/{dataInfo}sdl.jpg"
        nameInfo = df_excel.at[idx, "ì‘ê°€ëª…"]
        pieceInfo = df_excel.at[idx, "ì‘í’ˆëª…"]
        idInfo = df_excel.at[idx, "ID"]
        imageIs = df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"]

        if downloadCheck == "2" and imageIs != "X":
            print(f"â­ï¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µë¨ - idx: {idx}, ID: {idInfo}, ì €ì¥ì—¬ë¶€: {imageIs}")
            # ğŸ”§ NaN ê°’ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬ (3ê°œ ì»¬ëŸ¼)
            for col in ["ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€", "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€", "ì—ëŸ¬ë‚´ìš©"]:
                val = df_excel.at[idx, col]
                if pd.isna(val) or str(val).strip().lower() == "nan":
                    df_excel.at[idx, col] = ""
            continue

        original_filename = f"{nameInfo}_{pieceInfo}_{idInfo}"
        safe_filename = sanitize_filename(original_filename)

        df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "O"
        df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
        df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
        df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = ""

        try:
            imageInfo = requests.get(imageUrl, headers=headers, timeout=30)
        except Exception as e:
            print(f'e :{e}')
            print(f"{safe_filename} ì €ì¥ ì‹¤íŒ¨")
            df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
            df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
            df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
            df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = f"{e}"
            time.sleep(5)
            continue

        if imageInfo.status_code == 200:
            try:
                # âœ… (1) category ì €ì¥
                os.makedirs(imageCategoryPath, exist_ok=True)
                filename_category, omitted_cat = shorten_filename(Path(imageCategoryPath), safe_filename)
                with open(Path(imageCategoryPath) / f"{filename_category}{ext}", 'wb') as f:
                    f.write(imageInfo.content)

                # âœ… (2) ì‘ê°€ë³„ í´ë” ì €ì¥
                safe_artist_name = sanitize_filename(nameInfo)
                artist_dir = Path(imageArtistPath) / safe_artist_name
                artist_dir.mkdir(parents=True, exist_ok=True)

                filename_artist, omitted_art = shorten_filename(artist_dir, safe_filename)
                image_path = artist_dir / f"{filename_artist}{ext}"
                with open(image_path, 'wb') as f:
                    f.write(imageInfo.content)

                print(f"{idx + 1} : {filename_artist}{ext} ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ")

                # âœ… ì—‘ì…€ ì—…ë°ì´íŠ¸
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = f"{filename_artist}{ext}"
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = "O" if "O" in [omitted_cat, omitted_art] else ""
                df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "O"
                df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = ""

            except Exception as e:
                print(f'e :{e}')
                print(f"{safe_filename} ì €ì¥ ì‹¤íŒ¨")
                df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
                df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = f"{e}"
                time.sleep(5)

        elif imageInfo.status_code == 404:
            try:
                soup = BeautifulSoup(imageInfo.content, "xml")
                errormsg = soup.find("Code").text
                print(f"{safe_filename} {errormsg} ì €ì¥ ì‹¤íŒ¨")
                if "NoSuchKey" in errormsg:
                    df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                    df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
                    df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
                    df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = "Download í™•ì¸ NoSuchKey"
            except Exception as e:
                df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
                df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
                df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = "404 ì²˜ë¦¬ì¤‘ ì—ëŸ¬"
        else:
            print(f"{safe_filename} ì €ì¥ ì‹¤íŒ¨")
            df_excel.at[idx, "ì´ë¯¸ì§€ ì €ì¥ì—¬ë¶€"] = "X"
            df_excel.at[idx, "ì´ë¯¸ì§€ ëª…"] = ""
            df_excel.at[idx, "ì´ë¯¸ì§€ ëª… ìƒëµì—¬ë¶€"] = ""
            df_excel.at[idx, "ì—ëŸ¬ë‚´ìš©"] = "ê¸°íƒ€ì—ëŸ¬"
            time.sleep(5)

        time.sleep(0.5)

    # âœ… ì—‘ì…€ ì €ì¥
    with pd.ExcelWriter(f"{excelPath}/{fileInfo}", engine='openpyxl') as writer:
        df_excel.to_excel(writer, sheet_name="1", index=False)
        df_excel_data.to_excel(writer, sheet_name="2", index=False)


# ğŸ”§ íŒŒì¼ëª… ì•ˆì „í™” í•¨ìˆ˜
def sanitize_filename(filename: str) -> str:
    filename = filename.replace("/", "_").replace("\\", "_")
    filename = re.sub(r'[<>:"|?*\u2018\u2019\u201C\u201D]', '', filename)  # â€˜â€™, â€œâ€, íŠ¹ìˆ˜ ë”°ì˜´í‘œ ì œê±°
    return filename.strip()


# ğŸ”§ ê²½ë¡œì— ë§ì¶° íŒŒì¼ëª… ìë¥´ê¸° í•¨ìˆ˜
def shorten_filename(base_path: Path, filename: str) -> (str, str):
    MAX_PATH_LENGTH = 250  # Windows ì œí•œ
    ext = ".jpg"
    safe_name = sanitize_filename(filename)
    max_len = MAX_PATH_LENGTH - len(str(base_path.resolve())) - 1 - len(ext)
    if len(safe_name) > max_len:
        return safe_name[:max_len], "O"
    return safe_name, "X"


def count_images_in_folder(folder_path):
    """ì£¼ì–´ì§„ í´ë”ì—ì„œ .jpg íŒŒì¼ì˜ ê°œìˆ˜ë¥¼ ì…ˆ"""
    image_count = 0
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(".jpg"):
                image_count += 1
    return image_count


if __name__ == "__main__":
    init_logger()  # ë¡œê·¸ ì´ˆê¸°í™”
    mode = input("1. artvee ë‹¤ìš´ / 2. ì—‘ì…€ ë²ˆì—­ : / 3. artvee artist ë‹¤ìš´ : / 4. collection by category ì„ íƒ : / 5. ì´ë¯¸ì§€ ìˆ˜ í™•ì¸" )
    if mode == "1":
        try:
            main()
        except Exception as e:
            print(f"{str(e)} ì˜¤ë¥˜ë¡œ ì¸í•œ ì¢…ë£Œ")
            traceback.print_exc()
    elif mode == "2":
        try:
            translatorFromExcel()
        except Exception as e:
            print(f"{str(e)} ì˜¤ë¥˜ë¡œ ì¸í•œ ì¢…ë£Œ")
            traceback.print_exc()
    elif mode == "3":
        try:
            sub_main()
        except Exception as e:
            print(f"{str(e)} ì˜¤ë¥˜ë¡œ ì¸í•œ ì¢…ë£Œ")
            traceback.print_exc()
    elif mode == "4":
        print("\n")
        print("-------------------------------------------------------------------------------------")
        print("\n")
        print("1. Abstract / 2. Figurative / 3. Landscape / 4. Posters / 5. Illustration")
        print("6. Religion / 7. Drawings / 8. Mythology / 9. Botanical / 10. Asian Art / 11. Animals")

        selected = input("ë‹¤ìš´ë°›ì„ ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,3,5): ")

        # ë²ˆí˜¸ì™€ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        category_map = {
            1: "abstract",
            2: "figurative",
            3: "landscape",
            4: "posters",
            5: "illustration",
            6: "religion",
            7: "drawings",
            8: "mythology",
            9: "botanical",
            10: "asian-art",
            11: "animals"
        }

        try:
            category_numbers = [int(num.strip()) for num in selected.split(",") if num.strip().isdigit()]
            selected_categories = [category_map[num] for num in category_numbers if num in category_map]
            print(f"ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ì´ë¦„: {selected_categories}")

            # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ collection_mainì— ë„˜ê¹€

            excelCheck, downloadCheck = collection_filter()

            for category in selected_categories:
                collection_main(category, excelCheck, downloadCheck)

        except Exception as e:
            print(f"{str(e)} ì˜¤ë¥˜ë¡œ ì¸í•œ ì¢…ë£Œ")
            traceback.print_exc()

    elif mode == "5":
        # ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ì™€ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        category_map = {
            1: "abstract",
            2: "figurative",
            3: "landscape",
            4: "posters",
            5: "illustration",
            6: "religion",
            7: "drawings",
            8: "mythology",
            9: "botanical",
            10: "asian-art",
            11: "animals"
        }

        # ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ ì…ë ¥ ë°›ê¸°
        print("\n")
        print("-------------------------------------------------------------------------------------")
        print("\n")
        print("1. Abstract / 2. Figurative / 3. Landscape / 4. Posters / 5. Illustration")
        print("6. Religion / 7. Drawings / 8. Mythology / 9. Botanical / 10. Asian Art / 11. Animals")
        selected = input("ì´ë¯¸ì§€ìˆ˜ë¥¼ í™•ì¸í•  ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,3,5): ")

        selected_categories = [int(num.strip()) for num in selected.split(",")]

        for category_num in selected_categories:
            if category_num not in category_map:
                print(f"ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤: {category_num}")
                continue

            category_name = category_map[category_num]
            category_path = os.path.join("result", "image", "collection", category_name, "category")

            # category í´ë” ë‚´ ì´ë¯¸ì§€ ìˆ˜
            category_image_count = count_images_in_folder(category_path)
            print(f"{category_name} ì¹´í…Œê³ ë¦¬ 'category' í´ë” ë‚´ ì´ë¯¸ì§€ ìˆ˜: {category_image_count}ê°œ")

            # artist í´ë” ë‚´ ì´ë¯¸ì§€ ìˆ˜
            artist_folder_path = os.path.join("result", "image", "collection", category_name, "artist")
            artist_image_count = 0
            for artist_folder in os.listdir(artist_folder_path):
                artist_path = os.path.join(artist_folder_path, artist_folder)
                if os.path.isdir(artist_path):
                    artist_image_count += count_images_in_folder(artist_path)

            print(f"{category_name} ì¹´í…Œê³ ë¦¬ 'artist' í´ë” ë‚´ ì´ë¯¸ì§€ ìˆ˜: {artist_image_count}ê°œ")
            print("-------------------------------------------------------------------------------------")

    input("ì™„ë£Œ")