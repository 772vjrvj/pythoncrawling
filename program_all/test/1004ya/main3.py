# -*- coding: utf-8 -*-
"""
Naviya íŒŒì„œ ìµœì¢…íŒ
- clip_board_viewì˜ ëª¨ë“  <p> íƒœê·¸ í…ìŠ¤íŠ¸ë¥¼ ë°°ì—´ë¡œ: SHOP_INTRO_NEW_ONE
  * ê³µë°± pë„ ""ë¡œ ë³´ì¡´
- SHOP_INTRO_NEW_TWO: ìœ„ ë°°ì—´ì„ <br>ë¡œ ì´ì–´ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ (ë¹ˆ ìš”ì†Œë„ <br> ìƒì„±)
- BUSINESS_HOUR: píƒœê·¸ë§Œ ê¸°ì¤€ìœ¼ë¡œ 'ì˜ì—…ì‹œê°„' ì´í›„ ì‹œê° í† í°ì„ ì²˜ìŒ 2ê°œ ì°¾ì•„ 'HH:MM ~ HH:MM'
  * (ì˜¤ì „|ì˜¤í›„|ë‚®|ë°¤|ìƒˆë²½) + ì‹œ
  * '24ì‹œê°„ ì˜ì—…' / '24ì‹œê°„' / '24ì‹œ' / 'ì—°ì¤‘ë¬´íœ´' â†’ 00:00 ~ 24:00
  * 'ì˜¤ì‹œëŠ”ê¸¸/ê³µì§€/ê³µì§€ì•ˆë‚´/ê³µì§€ì‚¬í•­' pë¥¼ ë§Œë‚˜ë©´ íƒìƒ‰ ì¤‘ì§€
- PROGRAM: í•œ ì¤„ì— 'ë¶„'ê³¼ 'ë§Œ'ì´ í•¨ê»˜ ìˆëŠ” ì¤„ë§Œ íŒŒì‹±
  * ì œëª© ì—†ìœ¼ë©´ Aì½”ìŠ¤, ì‹œê°„ ì—†ìœ¼ë©´ 60ë¶„, ì—¬ëŸ¬ ê°€ê²©ì´ë©´ ë§ˆì§€ë§‰(í• ì¸ê°€), íƒ€ì´í‹€ë‹¹ ëŒ€í‘œ 1ê°œ
- ê²°ê³¼ë¥¼ CSV(result.csv)ë¡œ ì €ì¥ (UTF-8-SIG, Excel í˜¸í™˜):
  ì»¬ëŸ¼: SHOP_ID, BUSINESS_HOUR, CLOSED_DAY, PROGRAM(JSON), SHOP_INTRO_NEW_ONE(JSON), SHOP_INTRO_NEW_TWO
"""

import re
import json
import csv
import time
from typing import List, Dict, Optional, Tuple

import requests
from bs4 import BeautifulSoup

# ======================= ì„¤ì • =======================
BASE_URL = "https://www.naviya.net/bbs/board.php?bo_table=b49&wr_id={wr_id}"

WR_ID_LIST = [
    "10218", "11314", "11835", "12234", "12500", "13422", "13944",
    # í•„ìš” ì‹œ ë” ì¶”ê°€
]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120 Safari/537.36",
    "Accept-Language": "ko,en;q=0.8",
    "Referer": "https://www.naviya.net/",
}

REQUEST_TIMEOUT = 12
SLEEP_BETWEEN_REQ = 0.2
PRICE_PICK = "last"  # "last"=í• ì¸ê°€ ì„ íƒ, "first"=ì²« ê°€ê²© ì„ íƒ
RESULT_CSV = "result.csv"

# ============== ê³µí†µ ì •ê·œí™” ìœ í‹¸ ==============
# ì£¼ì˜: ~ ëŠ” ì ˆëŒ€ ì œê±°í•˜ì§€ ì•ŠìŒ (ì‹œê°„ êµ¬ë¶„ìë¡œ ì‚¬ìš©)
ARROWS_RE   = re.compile(r"[â™â›âââŸâ â¢â£â¤â¥â¦â§â¨â³âµâ¸â†’â‡’âŸ¶âŸ¹âŸ¿â”âšâ˜â™â¼â½â·âºâ»]+")
# []ëŠ” [A] ì¸ì‹ì— í•„ìš”. ~ ë„ ìœ ì§€.
DECOR_RE    = re.compile(r"[âœ¿âœ»â¥â–âœ£âœ±â‰â€¢Â·ï½¡â˜¾â˜½_=Â·\â€”â€“â”‚â”ƒâ–­â– â—†â—â–¶â–·â—€â—â–ââ€â˜…â˜†â™¡â™¥â—†â—‡â– â–¡ã€ˆã€‰â€œâ€\"'`ã€Â·â€¦Â·Â°â€¢Ëšâ€¢ğŸ„Œâ“â“‘â“’â“¥â€¢â–â•³Ã—]+")
DASHES_RE   = re.compile(r"[|ï½œ\-â”€â”ï¼¿_]+")
DUPSPACE_RE = re.compile(r"\s{2,}")

def _unify_tilde(s: str) -> str:
    return s.replace("âˆ¼", "~").replace("ã€œ", "~")

def normalize_line(s: str) -> str:
    """í”„ë¡œê·¸ë¨/ì˜ì—…ì‹œê°„ ë¼ì¸ íŒŒì‹±ìš©(ì¥ì‹ ì œê±°)"""
    if not s:
        return ""
    t = _unify_tilde(s)
    t = (t.replace("\xa0", " ")
         .replace("\u200b", "")
         .replace("\u200c", "")
         .replace("\u200d", "")
         .replace("\u2060", "")
         .strip())
    # ~ ëŠ” ìœ ì§€
    t = ARROWS_RE.sub(" ", t)
    t = DECOR_RE.sub(" ", t)
    t = DASHES_RE.sub(" ", t)
    # "0 60ë¶„" â†’ "060ë¶„"
    t = re.sub(r"(\d)\s+(\d)", r"\1\2", t)
    t = DUPSPACE_RE.sub(" ", t).strip()
    return t

def compact(s: str) -> str:
    """ê³µë°± ì œê±° ë¹„êµìš©"""
    return re.sub(r"\s+", "", s or "")

# ============== HTML ==============
def fetch_html(wr_id: str) -> Optional[str]:
    url = BASE_URL.format(wr_id=wr_id)
    try:
        r = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
        r.raise_for_status()
        if not r.encoding or r.encoding.lower() == "iso-8859-1":
            r.encoding = r.apparent_encoding or "utf-8"
        return r.text
    except Exception as e:
        print(f"[warn] ìš”ì²­ ì‹¤íŒ¨ wr_id={wr_id}: {e}")
        return None

def get_clip_root(html: str) -> Optional[BeautifulSoup]:
    soup = BeautifulSoup(html, "html.parser")
    return soup.select_one("#clip_board_view")

# ============== SHOP_INTRO (p ë°°ì—´/ë¬¸ìì—´) ==============
def p_text_array(root: BeautifulSoup) -> List[str]:
    """
    ëª¨ë“  p íƒœê·¸ì˜ 'ë³´ì´ëŠ” í…ìŠ¤íŠ¸'ë¥¼ ë°°ì—´ë¡œ.
    - strip=Trueë¡œ ì–‘ë ê³µë°± ì œê±° â†’ ê³µë°± pëŠ” ""ë¡œ ë“¤ì–´ê°
    - NBSP/ì œë¡œí­ë¬¸ìëŠ” ì œê±°
    - ì¥ì‹ë¬¸ì/í™”ì‚´í‘œëŠ” ì œê±°í•˜ì§€ ì•ŠìŒ(ì‹¤ì œ í™”ë©´ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸ ìµœëŒ€í•œ ë³´ì¡´)
    """
    arr: List[str] = []
    for p in root.find_all("p"):
        raw = p.get_text(separator=" ", strip=True)
        t = (raw.replace("\xa0", " ")
             .replace("\u200b", "")
             .replace("\u200c", "")
             .replace("\u200d", "")
             .replace("\u2060", ""))
        # ê·¸ëŒ€ë¡œ ë³´ì¡´ (ë¹ˆ pëŠ” "")
        arr.append(t)
    return arr

def intro_two_from_array(intros: List[str]) -> str:
    """
    ë°°ì—´ì„ HTML í‘œê¸°ì²˜ëŸ¼ '<br>'ë¡œ ì´ì–´ ë‹¨ì¼ ë¬¸ìì—´ ìƒì„±.
    ë¹ˆ ë¬¸ìì—´ë„ ê·¸ëŒ€ë¡œ ì´ì–´ì„œ ë¹ˆ ì¤„ ìœ ì§€.
    """
    return "<br>".join(intros)

# ============== ì˜ì—…ì‹œê°„ (p ì „ìš©, ì²« 2í† í°) ==============
STRICT_TIME_TOKEN_RE = re.compile(r"(ì˜¤ì „|ì˜¤í›„|ë‚®|ë°¤|ìƒˆë²½)\s*(\d{1,2})(?:\s*[:ì‹œ]\s*(\d{1,2}))?")

def _fmt_hm(h: int, m: int) -> str:
    return f"{h:02d}:{m:02d}"

def _kor_time_to_24h(period: Optional[str], hour: int, minute: int = 0) -> Tuple[int, int]:
    """
    í•œê¸€ ì‹œê° â†’ 24ì‹œê°„ì œ
    - ì˜¤ì „: 12â†’0
    - ì˜¤í›„: 1~11â†’+12, 12â†’12
    - ë‚® : 1~6â†’+12, 12â†’12
    - ë°¤ : 12â†’0, 1~6â†’ê·¸ëŒ€ë¡œ, 7~11â†’+12
    - ìƒˆë²½: 12â†’0, 1~11â†’ê·¸ëŒ€ë¡œ
    """
    p = (period or "").strip()
    h = max(0, min(24, hour))
    m = 0 if minute is None else max(0, min(59, minute))

    if p == "ì˜¤ì „":
        if h == 12: h = 0
    elif p == "ì˜¤í›„":
        if h != 12: h += 12
    elif p == "ë‚®":
        if h == 12: h = 12
        elif 1 <= h <= 6: h += 12
    elif p == "ë°¤":
        if h == 12: h = 0
        elif 1 <= h <= 6: h = h
        else: h += 12
    elif p == "ìƒˆë²½":
        if h == 12: h = 0
        else: h = h

    return max(0, min(24, h)), m

def is_24h_line(line: str) -> bool:
    """
    '24ì‹œê°„ ì˜ì—…', '24ì‹œê°„', '24ì‹œ', 'ì—°ì¤‘ë¬´íœ´' í¬í•¨ ì‹œ 24ì‹œê°„ìœ¼ë¡œ ê°„ì£¼.
    """
    c = compact(line)
    return ("24ì‹œê°„ì˜ì—…" in c) or ("24ì‹œê°„" in c) or ("24ì‹œ" in c) or ("ì—°ì¤‘ë¬´íœ´" in c)

def extract_business_hours_p_only(root: BeautifulSoup) -> Optional[str]:
    """
    p íƒœê·¸ë§Œ ë³´ê³ :
      - 'ì˜ì—…ì‹œê°„' í—¤ë” ì´í›„
      - (ì˜¤ì „|ì˜¤í›„|ë‚®|ë°¤|ìƒˆë²½)+ì‹œê° í† í°ì„ ê°€ì§„ pì—ì„œ í† í°ì„ ìˆœì„œëŒ€ë¡œ ìˆ˜ì§‘
      - ì²˜ìŒ 2ê°œì˜ í† í°ìœ¼ë¡œ 'HH:MM ~ HH:MM' ë°˜í™˜
      - '24ì‹œê°„/24ì‹œ/ì—°ì¤‘ë¬´íœ´' ë§Œë‚˜ë©´ ì¦‰ì‹œ '00:00 ~ 24:00'
      - 'ì˜¤ì‹œëŠ”ê¸¸/ê³µì§€/ê³µì§€ì•ˆë‚´/ê³µì§€ì‚¬í•­' ë§Œë‚˜ë©´ íƒìƒ‰ ì¤‘ë‹¨
    """
    if not root:
        return None

    seen_hours = False
    times: List[Tuple[int, int]] = []

    for p in root.find_all("p"):
        raw = p.get_text(separator=" ", strip=True)
        if raw is None:
            continue
        # introìš©ê³¼ ë‹¬ë¦¬, ì‹œê°„ íŒŒì‹±ì€ normalizeë¥¼ ì•½í•˜ê²Œë§Œ ì ìš©
        line = normalize_line(raw)
        c = compact(line)

        if not seen_hours:
            if "ì˜ì—…ì‹œê°„" in c:
                seen_hours = True
            else:
                continue

        if any(key in c for key in ("ì˜¤ì‹œëŠ”ê¸¸", "ê³µì§€ì•ˆë‚´", "ê³µì§€ì‚¬í•­", "ê³µì§€")):
            break

        if is_24h_line(line):
            return "00:00 ~ 24:00"

        for m in STRICT_TIME_TOKEN_RE.finditer(line):
            period = m.group(1)
            hour   = int(m.group(2))
            minute = int(m.group(3) or 0)
            h, mi  = _kor_time_to_24h(period, hour, minute)
            times.append((h, mi))
            if len(times) >= 2:
                return f"{_fmt_hm(*times[0])} ~ {_fmt_hm(*times[1])}"

    return None

# ============== PROGRAM íŒŒì‹± (ë¼ì¸ ê¸°ë°˜) ==============
def extract_prices(line: str) -> List[int]:
    nums = re.findall(r"(\d{1,3})\s*ë§Œ", line)
    return [int(n) * 10000 for n in nums] if nums else []

def extract_duration(line: str) -> Optional[str]:
    cands = re.findall(r"(\d{1,3})\s*ë¶„", line)
    if not cands:
        return None
    return f"{int(cands[-1])}ë¶„"  # ë§ˆì§€ë§‰ 'ë¶„'ì„ ì‹œê°„ìœ¼ë¡œ

def ensure_duration(line: str) -> str:
    d = extract_duration(line)
    return d if d else "60ë¶„"

def _ensure_kose(name: str) -> str:
    return name if name.endswith("ì½”ìŠ¤") else f"{name}ì½”ìŠ¤"

def extract_title(line: str) -> Optional[str]:
    # VIP / V
    if re.search(r"\bVIP\b", line, re.I) or re.search(r"\bV\b", line):
        return "VIPì½”ìŠ¤"
    # [A]
    m = re.search(r"\[\s*([A-Da-d])\s*\]", line)
    if m:
        return f"{m.group(1).upper()}ì½”ìŠ¤"
    # A. / A:
    m = re.search(r"\b([A-Da-d])\s*[.:]", line)
    if m:
        return f"{m.group(1).upper()}ì½”ìŠ¤"
    # A-1
    m = re.search(r"\b([A-Da-d])\s*-\s*\d+\b", line)
    if m:
        return f"{m.group(1).upper()}ì½”ìŠ¤"
    # A ì½”ìŠ¤ / Aì½”ìŠ¤
    m = re.search(r"\b([A-Da-d])\s*ì½”\s*ìŠ¤\b", line)
    if m:
        return f"{m.group(1).upper()}ì½”ìŠ¤"
    # ì¼ë°˜ëª… ì½”ìŠ¤ (ë‹¨ì¼ì½”ìŠ¤, íŒ¨í‚¤ì§€1 ë“±)
    m = re.search(r"([A-Za-zê°€-í£0-9]+)\s*ì½”\s*ìŠ¤\b", line)
    if m:
        name = m.group(1).strip()
        if len(name) == 1 and name.isalpha():
            return f"{name.upper()}ì½”ìŠ¤"
        return _ensure_kose(name)
    # duration ì•ì˜ í…ìŠ¤íŠ¸ë¥¼ ì œëª©ìœ¼ë¡œ
    d = re.search(r"\d{1,3}\s*ë¶„", line)
    if d:
        prefix = line[:d.start()].strip()
        prefix = re.sub(r"^[\(\[]|[\)\]]$", "", prefix).strip()
        if prefix and prefix not in ("ì£¼", "ì•¼", "ìƒë‹´ê°€ëŠ¥"):
            return _ensure_kose(prefix) if not prefix.endswith("ì½”ìŠ¤") else prefix
    return None

def decide_title(line: str) -> str:
    t = extract_title(line)
    return t if t else "Aì½”ìŠ¤"

def is_price_line(line: str) -> bool:
    return bool(re.search(r"\d{1,3}\s*ë§Œ", line))

def html_to_lines_for_program(root: BeautifulSoup) -> List[str]:
    """í”„ë¡œê·¸ë¨ íŒŒì‹±ìš© ë¼ì¸ ë°°ì—´ (#clip_board_view ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ)"""
    text_block = root.get_text("\n", strip=True)
    raw_lines = text_block.split("\n")
    lines = [normalize_line(ln) for ln in raw_lines if ln is not None]
    return [ln for ln in lines if ln]

def extract_program_items(root: BeautifulSoup) -> List[Dict]:
    lines = html_to_lines_for_program(root)
    results: List[Dict] = []
    taken = set()
    for line in lines:
        if not is_price_line(line):
            continue
        prices = extract_prices(line)
        if not prices:
            continue
        price = prices[-1] if PRICE_PICK == "last" else prices[0]
        title    = decide_title(line)
        duration = ensure_duration(line)
        if title in taken:
            continue
        results.append({
            "title": title,
            "duration": duration,
            "categories": "",
            "original_price": "",
            "discount_price": price,
        })
        taken.add(title)
    return results

# ============== CSV ì €ì¥ ==============
def save_to_csv(rows: List[Dict], path: str = RESULT_CSV):
    """
    rows: [{SHOP_ID, BUSINESS_HOUR, CLOSED_DAY, PROGRAM(list), SHOP_INTRO_NEW_ONE(list), SHOP_INTRO_NEW_TWO(str)}, ...]
    PROGRAM / SHOP_INTRO_NEW_ONE ì€ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”í•´ì„œ ì €ì¥
    """
    fieldnames = ["SHOP_ID", "BUSINESS_HOUR", "CLOSED_DAY", "PROGRAM", "SHOP_INTRO_NEW_ONE", "SHOP_INTRO_NEW_TWO"]
    with open(path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for r in rows:
            writer.writerow({
                "SHOP_ID": r.get("SHOP_ID", ""),
                "BUSINESS_HOUR": r.get("BUSINESS_HOUR", ""),
                "CLOSED_DAY": r.get("CLOSED_DAY", ""),
                "PROGRAM": json.dumps(r.get("PROGRAM", []), ensure_ascii=False),
                "SHOP_INTRO_NEW_ONE": json.dumps(r.get("SHOP_INTRO_NEW_ONE", []), ensure_ascii=False),
                "SHOP_INTRO_NEW_TWO": r.get("SHOP_INTRO_NEW_TWO", ""),
            })

# ============== ì‹¤í–‰ë¶€ ==============
def main():
    out_rows: List[Dict] = []

    for wr_id in WR_ID_LIST:
        html = fetch_html(wr_id)
        if not html:
            # ì‹¤íŒ¨ ì‹œì—ë„ ë¹ˆ êµ¬ì¡°ë¡œ ë¼ì¸ í™•ë³´
            out_rows.append({
                "SHOP_ID": f"N_{wr_id}",
                "BUSINESS_HOUR": "",
                "CLOSED_DAY": "ì—°ì¤‘ë¬´íœ´(ì „í™”ë¬¸ì˜)",
                "PROGRAM": [],
                "SHOP_INTRO_NEW_ONE": [],
                "SHOP_INTRO_NEW_TWO": "",
            })
            continue

        root = get_clip_root(html)
        if not root:
            out_rows.append({
                "SHOP_ID": f"N_{wr_id}",
                "BUSINESS_HOUR": "",
                "CLOSED_DAY": "ì—°ì¤‘ë¬´íœ´(ì „í™”ë¬¸ì˜)",
                "PROGRAM": [],
                "SHOP_INTRO_NEW_ONE": [],
                "SHOP_INTRO_NEW_TWO": "",
            })
            continue

        # SHOP_INTRO
        intro_one = p_text_array(root)                 # ëª¨ë“  p í…ìŠ¤íŠ¸ (ë¹ˆ pëŠ” "")
        intro_two = intro_two_from_array(intro_one)    # "<br>"ë¡œ ì´ì–´ì§„ ë¬¸ìì—´

        # BUSINESS_HOUR (p-only)
        business_hour = extract_business_hours_p_only(root) or ""

        # PROGRAM
        programs = extract_program_items(root)

        obj = {
            "SHOP_ID": f"N_{wr_id}",
            "BUSINESS_HOUR": business_hour,
            "CLOSED_DAY": "ì—°ì¤‘ë¬´íœ´(ì „í™”ë¬¸ì˜)",  # í•˜ë“œì½”ë”©
            "PROGRAM": programs,
            "SHOP_INTRO_NEW_ONE": intro_one,
            "SHOP_INTRO_NEW_TWO": intro_two,
        }
        out_rows.append(obj)

        # (ì›í•˜ë©´ ì½˜ì†” í™•ì¸)
        print(json.dumps(obj, ensure_ascii=False, indent=2))
        print()
        time.sleep(SLEEP_BETWEEN_REQ)

    save_to_csv(out_rows, RESULT_CSV)
    print(f"[ok] CSV ì €ì¥ ì™„ë£Œ: {RESULT_CSV}")

if __name__ == "__main__":
    main()
