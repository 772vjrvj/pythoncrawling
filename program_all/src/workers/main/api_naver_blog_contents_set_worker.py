import re
import time
import random

import pandas as pd
from bs4 import BeautifulSoup

from src.core.global_state import GlobalState
from src.utils.api_utils import APIClient
from src.utils.excel_utils import ExcelUtils
from src.utils.file_utils import FileUtils
from src.utils.selenium_utils import SeleniumUtils
from src.workers.api_base_worker import BaseApiWorker


class ApiNaverBlogContentsSetLoadWorker(BaseApiWorker):


    # ì´ˆê¸°í™”
    def __init__(self, setting):
        super().__init__()
        self.blog_id = None
        self.setting = setting
        self.category_list = None
        self.cookies = None
        self.keyword = None
        self.base_main_url   = "https://m.blog.naver.com"
        self.site_name = "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ì¡°íšŒ"

        self.running = True  # ì‹¤í–‰ ìƒíƒœ í”Œë˜ê·¸ ì¶”ê°€
        self.driver = None

        self.total_cnt = 0
        self.total_pages = 0
        self.current_cnt = 0

        self.file_driver = None
        self.selenium_driver = None
        self.excel_driver = None
        self.running = True
        self.driver = None
        self.base_url = None
        self.before_pro_value = 0
        self.api_client = APIClient(use_cache=False)

        self.driver_set(True)
        self.set_cookies()

    # ì´ˆê¸°í™”
    def init(self):
        self.log_signal_func(f"ì´ˆê¸°í™” ì‹¤í–‰ setting : {self.setting}")


    # í”„ë¡œê·¸ë¨ ì‹¤í–‰
    def main(self):
        try:
            st_page = int(self.get_setting_value(self.setting, "st_page"))
            ed_page = int(self.get_setting_value(self.setting, "ed_page"))
            category_no = int(self.get_setting_value(self.setting, "url_select"))

            self.total_pages = ed_page - st_page + 1
            self.total_cnt = self.total_pages * 24

            self.log_signal_func(f"ìš”ì²­ í˜ì´ì§€ ìˆ˜ {self.total_pages} ê°œ")
            self.log_signal_func(f"ìš”ì²­ í¬ìŠ¤íŠ¸ ìˆ˜ {self.total_cnt} ê°œ")

            excel_filename = self.file_driver.get_excel_filename(self.site_name)

            columns = ["ì œëª©", "ë‚´ìš©", "URL"]
            df = pd.DataFrame(columns=columns)
            df.to_excel(excel_filename, index=False)

            for page in range(1, self.total_pages + 1):
                if not self.running:  # ì‹¤í–‰ ìƒíƒœ í™•ì¸
                    self.log_signal_func("í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                pg = st_page + page - 1
                items = self.fetch_search_results(pg, category_no)
                self.fetch_search_detail_results(items, excel_filename, columns)
            return True
        except Exception as e:
            self.log_signal_func(f"ğŸš¨ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False


    def fetch_search_detail_results(self, items, excel_filename, columns):
        result_list = []

        headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "referer": f"https://m.blog.naver.com/{self.blog_id}",
            "sec-ch-ua": '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "none",
            "sec-fetch-user": "?1",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
        }

        for index, item in enumerate(items):
            if not self.running:  # ì‹¤í–‰ ìƒíƒœ í™•ì¸
                self.log_signal_func("í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            url = item["URL"]
            res = self.api_client.get(url=url, headers=headers)

            if res:
                soup = BeautifulSoup(res, "html.parser")
                content_area = soup.find("div", class_="se-main-container")
                if content_area:
                    # âŒ idê°€ 'ad-'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í•˜ìœ„ ìš”ì†Œ ì œê±°
                    for ad_div in content_area.find_all(id=lambda x: x and x.startswith("ad-")):
                        ad_div.decompose()

                    text = content_area.get_text(separator="\n", strip=True)
                    item["ë‚´ìš©"] = text
                else:
                    item["ë‚´ìš©"] = ""

                self.log_signal_func(f"item : {item}")

                result_list.append(item)

            if (index + 1) % 5 == 0:
                self.excel_driver.append_to_excel(excel_filename, result_list, columns)

            time.sleep(random.uniform(1, 1.5))

            self.current_cnt = self.current_cnt + 1
            pro_value = (self.current_cnt / self.total_cnt) * 1000000
            self.progress_signal.emit(self.before_pro_value, pro_value)
            self.before_pro_value = pro_value

        if result_list:
            self.excel_driver.append_to_excel(excel_filename, result_list, columns)


    # ë“œë¼ì´ë²„ ì„¸íŒ…
    def driver_set(self, headless):
        self.log_signal_func("ë“œë¼ì´ë²„ ì„¸íŒ… ========================================")

        # ì—‘ì…€ ê°ì²´ ì´ˆê¸°í™”
        self.excel_driver = ExcelUtils(self.log_signal_func)

        # íŒŒì¼ ê°ì²´ ì´ˆê¸°í™”
        self.file_driver = FileUtils(self.log_signal_func)

        # ì…€ë ˆë‹ˆì›€ ì´ˆê¸°í™”
        self.selenium_driver = SeleniumUtils(headless)

        state = GlobalState()
        user = state.get("user")
        self.driver = self.selenium_driver.start_driver(1200, user)

    # ë¡œê·¸ì¸ í™•ì¸
    def set_cookies(self):
        self.log_signal_func("ğŸ“¢ ì¿ í‚¤ ì„¸íŒ… ì‹œì‘")
        cookies = {cookie['name']: cookie['value'] for cookie in self.driver.get_cookies()}

        for name, value in cookies.items():
            self.api_client.cookie_set(name, value)
        self.log_signal_func("ğŸ“¢ ì¿ í‚¤ ì„¸íŒ… ì™„ë£Œ")
        time.sleep(2)  # ì˜ˆì œìš©

    # ë§ˆë¬´ë¦¬
    def destroy(self):
        self.progress_signal.emit(self.before_pro_value, 1000000)
        self.log_signal_func("=============== í¬ë¡¤ë§ ì¢…ë£Œì¤‘...")
        time.sleep(5)
        self.log_signal_func("=============== í¬ë¡¤ë§ ì¢…ë£Œ")
        self.progress_end_signal.emit()

    # ëª©ë¡ì¡°íšŒ
    def fetch_search_results(self, page, category_no):
        result_list = []

        url = f"https://m.blog.naver.com/api/blogs/{self.blog_id}/post-list"

        headers = {
            "accept": "application/json, text/plain, */*",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "referer": f"https://m.blog.naver.com/{self.blog_id}?categoryNo={category_no}&tab=1",
            "sec-ch-ua": '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
        }

        params = {
            "categoryNo": category_no,
            "itemCount": "24",
            "page": page
        }

        res = self.api_client.get(url=url, headers=headers, params=params)

        if res and res.get("isSuccess"):
            items = res.get("result", {}).get("items", [])

            for item in items:
                log_no = item.get("logNo")
                title = item.get("titleWithInspectMessage", "")
                if log_no:
                    result_list.append({
                        "no": log_no,
                        "ì œëª©": title,
                        "ë‚´ìš©": "",
                        "URL": f"https://m.blog.naver.com/PostView.naver?blogId={self.blog_id}&logNo={log_no}&navType=by"
                    })

        return result_list

    # ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ
    def get_list(self, blog_url):
        try:
            match = re.match(r"https?://blog\.naver\.com/([^/?#]+)", blog_url)
            if not match:
                raise ValueError("ë¸”ë¡œê·¸ URL í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.blog_id = match.group(1)

            url = f"https://m.blog.naver.com/api/blogs/{self.blog_id}/category-list"

            headers = {
                "accept": "application/json, text/plain, */*",
                "accept-encoding": "gzip, deflate, br, zstd",
                "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "referer": f"https://m.blog.naver.com/{self.blog_id}?tab=1",
                "sec-ch-ua": '"Google Chrome";v="137", "Chromium";v="137", "Not/A)Brand";v="24"',
                "sec-ch-ua-mobile": "?0",
                "sec-ch-ua-platform": '"Windows"',
                "sec-fetch-dest": "empty",
                "sec-fetch-mode": "cors",
                "sec-fetch-site": "same-origin",
                "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
            }

            res = self.api_client.get(url=url, headers=headers)
            if res and res.get("isSuccess") is True:
                self.category_list = res.get("result", {}).get("mylogCategoryList", [])
                return [
                    {"key": c["categoryName"], "value": c["categoryNo"]}
                    for c in self.category_list
                    if c.get("categoryName") != "êµ¬ë¶„ì„ "
                ]
            return []

        except Exception as e:
            self.log_signal_func(f"ë¸”ë¡œê·¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì—ëŸ¬: {e}")
            return []

    # ì¤‘ì§€
    def stop(self):
        self.running = False
        if self.driver:
            self.driver.quit()
